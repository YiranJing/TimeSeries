
@article{de_livera_forecasting_2011,
	title = {Forecasting {Time} {Series} {With} {Complex} {Seasonal} {Patterns} {Using} {Exponential} {Smoothing}},
	volume = {106},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm09771},
	doi = {10.1198/jasa.2011.tm09771},
	language = {en},
	number = {496},
	urldate = {2018-10-31TZ},
	journal = {Journal of the American Statistical Association},
	author = {De Livera, Alysha M. and Hyndman, Rob J. and Snyder, Ralph D.},
	month = dec,
	year = {2011},
	pages = {1513--1527}
}

@misc{noauthor_historical_2017,
	title = {Historical weather observations and statistics},
	url = {http://www.bom.gov.au/climate/data-services/station-data.shtml},
	publisher = {BOM},
	year = {2017}
}

@misc{noauthor_data_2018,
	title = {Data {Dashboard}},
	url = {https://www.aemo.com.au/Electricity/National-Electricity-Market-NEM/Data-dashboard\#aggregated-data},
	publisher = {AEMO},
	year = {2018}
}

@article{hobbs_analysis_1999,
	title = {Analysis of the {Value} for {Unit} {Commitment} of {Improved} {Load} {Forecasts}},
	volume = {14},
	doi = {10.1109/59.801894},
	number = {4},
	journal = {IEEE Transactions on Powcr System},
	author = {Hobbs, Benjamin F. and Jitprapaikulsarn, Suradet and Konda, Sreenivas and Chankong, Vira and Loparo, Kenneth A. and Maratukulam, Dominic J.},
	month = nov,
	year = {1999},
	pages = {1342--1348}
}

@article{noauthor_sa_2016,
	title = {{SA} blackout: {Why} and how?},
	shorttitle = {{SA} blackout},
	abstract = {A perfect storm of electricity supply?},
	language = {en-AU},
	urldate = {2018-10-25TZ},
	journal = {ABC News},
	month = sep,
	year = {2016}
}

@article{moller_econometric_2015,
	title = {An econometric analysis of electricity demand response to price changes at the intra-day horizon:  {The} case of manufacturing industry in {West} {Denmark}},
	shorttitle = {An econometric analysis of electricity demand response to price changes at the intra-day horizon},
	doi = {10.5278/ijsepm.2015.7.2},
	abstract = {The use of renewable energy implies a more variable supply of power. Market e¢ ciency may improve if demand can absorb some of this variability by being more ‡exible, e.g. by responding quickly to changes in the market price of power. To learn about this, in particular, whether demand responds already within the same day, we suggest an econometric model for hourly consumptionand price time series. This allows for multi-level seasonality and that information about dayahead prices does not arrive every hour but every 24th hour (as a vector of 24 prices). We confront the model with data from the manufacturing industry of West Denmark (2007-2011). The results clearly suggest a lack of response. The policy implication is that relying exclusively on hourly price response by consumers for integrating volatile renewable electricity production is questionable. Either hourly price variation has to increase considerably or demand response technologies be installed.},
	language = {en},
	urldate = {2018-10-25TZ},
	journal = {International Journal of Sustainable Energy Planning and Management, Vol 7 (2015)},
	author = {Moller, Niels Framroze and Andersen, Frits Møller},
	month = nov,
	year = {2015}
}

@article{griffiths_heatwave_2018,
	title = {Heatwave triggers ‘{Code} {Yellow}’},
	abstract = {A heatwave gripping southern Australia has put so much strain on the national power grid, some Victorian hospitals have been forced to issue a Code Yellow alert amid fears of blackouts.},
	urldate = {2018-10-25TZ},
	journal = {The Australian},
	author = {Griffiths, Luke},
	month = jan,
	year = {2018}
}

@techreport{sandberg_primer_2010,
	address = {Aerodynamics \& Flight Mechanics Research Group},
	title = {A {Primer} on {Direct} {Numerical} {Simulation} of {Turbulence} – {Methods}, {Procedures} and {Guidelines}},
	institution = {University of Southampton},
	author = {Sandberg, Richard D. and Coleman, Gary N.},
	month = mar,
	year = {2010}
}

@article{bunn_forecasting_2000,
	title = {Forecasting loads and prices in competitive power markets},
	volume = {88},
	issn = {0018-9219},
	doi = {10.1109/5.823996},
	abstract = {This paper provides a review of some of the main methodological issues and techniques which have become innovative in addressing the problem of forecasting daily loads and prices in the new competitive power markets. Particular emphasis is placed upon computationally intensive methods, including variable segmentation, multiple modeling, combinations, and neural networks for forecasting the demand side, and strategic simulation using artificial agents for the supply side.},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Bunn, D. W.},
	month = feb,
	year = {2000},
	keywords = {Computational modeling, Costs, Demand forecasting, Economic forecasting, Load forecasting, Monopoly, Power markets, Predictive models, Uncertainty, Weather forecasting, agent based simulation, artificial agents, combinations, competitive power markets, computationally intensive methods, costing, daily loads forecasting, demand side forecasting, electricity supply industry, load forecasting, multiple modeling, neural nets, neural networks, power system analysis computing, prices forecasting, strategic simulation, supply side, variable segmentation},
	pages = {163--169}
}

@article{turner_variability_2005,
	title = {Variability in the development, persistence and breakdown of thermal, oxygen and salt stratification on regulated rivers of southeastern {Australia}},
	volume = {21},
	copyright = {Copyright © 2005 John Wiley \& Sons, Ltd.},
	issn = {1535-1467},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rra.838},
	doi = {10.1002/rra.838},
	abstract = {Detailed depth profiles of temperature, dissolved oxygen, salinity and oxidation-reduction potential (ORP) at many sites over two to four years were made on three highly regulated rivers in southeastern Australia which have experienced large-scale streamflow reductions for urban water supply (Nepean River) or urban, stock and domestic supplies (Glenelg River) or hydropower generation (Snowy River). Well-developed oxygen stratification was detected on all rivers in summer and was associated with thermal stratification. Hypoxia or anoxia was often measured below the oxycline and reducing conditions (ORP up to −200 mv) were usually associated with such anoxia. Saline groundwater inflows were detected on both the Nepean and Glenelg rivers and produced salt stratification in addition to thermal and oxygen stratification. Density differences of up to 3.7 kg/m3 were determined across the oxycline with no salt stratification, but increased to 14.9 kg/m3 when salt stratification occurred in the upper estuary of the Snowy River. Sediment-bound phosphorus was released under reducing conditions with order of magnitude increases in total phosphorus concentrations being measured below the oxycline. Similarly, increases of at least 50\% and up to one order of magnitude in dissolved iron, aluminium, manganese and/or sulphur were also measured when anoxic and reducing conditions were recorded below the oxycline. Water depth exerted a significant control on thermocline development with depths of at least 5 m, but usually 6 m, being required for thermal stratification in pools. Deep natural scour pools stratify on all three rivers but dredging of weir pools on the Nepean River has increased the extent of stratification. Anoxic and/or hypoxic conditions below the oxycline greatly reduce the amount of aquatic habitat available for aerobic organisms, especially benthic fish. Winds of 50 km/h generated sufficient shear to completely overturn the stratified Cobbitty weir pool on the Nepean River and winds of 28–44 km/h completely mixed epilimnetic waters in Rocklands Reservoir, breaking down temporary thermoclines. Trial environmental streamflows of 21.7 to 40.7 m3/s generated epilimnetic flow velocities that caused sufficient turbulence to effect mixing by gradual entrainment on the Nepean River. However, these flows would need to persist for more than 5 days to break down stratification in the deepest pools. Stratification rapidly redeveloped, even on the recession of the releases. Copyright © 2005 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {2-3},
	urldate = {2018-10-25TZ},
	journal = {River Research and Applications},
	author = {Turner, Lisa and Erskine, Wayne D.},
	month = feb,
	year = {2005},
	keywords = {anoxia, halocline, hypoxia, mixing, oxycline, pycnocline, rivers, thermal gradient, thermocline},
	pages = {151--168}
}

@techreport{saddler_past_2013,
	title = {The past and future of electricity consumption in {Australia}},
	language = {en},
	institution = {Pitt \& Sherry},
	author = {Saddler, Hugh},
	year = {2013},
	pages = {7}
}

@article{bernal_interrupted_2017,
	title = {Interrupted time series regression for the evaluation of public health interventions: a tutorial},
	volume = {46},
	issn = {0300-5771},
	shorttitle = {Interrupted time series regression for the evaluation of public health interventions},
	url = {https://academic.oup.com/ije/article/46/1/348/2622842},
	doi = {10.1093/ije/dyw098},
	abstract = {Abstract.  Interrupted time series (ITS) analysis is a valuable study design for evaluating the effectiveness of population-level health interventions that have},
	language = {en},
	number = {1},
	urldate = {2018-10-25TZ},
	journal = {International Journal of Epidemiology},
	author = {Bernal, James Lopez and Cummins, Steven and Gasparrini, Antonio},
	month = feb,
	year = {2017},
	pages = {348--355}
}

@article{hippert_neural_2001,
	title = {Neural networks for short-term load forecasting: a review and evaluation},
	volume = {16},
	issn = {0885-8950},
	shorttitle = {Neural networks for short-term load forecasting},
	doi = {10.1109/59.910780},
	abstract = {Load forecasting has become one of the major areas of research in electrical engineering, and most traditional forecasting models and artificial intelligence techniques have been tried out in this task. Artificial neural networks (NNs) have lately received much attention, and a great number of papers have reported successful experiments and practical tests with them. Nevertheless, some authors remain skeptical, and believe that the advantages of using NNs in forecasting have not been systematically proved yet. In order to investigate the reasons for such skepticism, this review examines a collection of papers (published between 1991 and 1999) that report the application of NNs to short-term load forecasting. Our aim is to help to clarify the issue, by critically evaluating the ways in which the NNs proposed in these papers were designed and tested.},
	number = {1},
	journal = {IEEE Transactions on Power Systems},
	author = {Hippert, H. S. and Pedreira, C. E. and Souza, R. C.},
	month = feb,
	year = {2001},
	keywords = {Artificial neural networks, Costs, Economic forecasting, Electrical engineering, Electricity supply industry, Load forecasting, Multi-layer neural network, Neural networks, Predictive models, Testing, artificial intelligence techniques, artificial neural networks, load forecasting, multilayer perceptrons, neural nets, neural networks, overfitting, power system analysis computing, short-term load forecasting},
	pages = {44--55}
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore-ieee-org.ezproxy1.library.usyd.edu.au/stamp/stamp.jsp?arnumber=823996},
	urldate = {2018-10-25TZ}
}

@inproceedings{sood_electricity_2010,
	title = {Electricity load forecasting based on autocorrelation analysis},
	doi = {10.1109/IJCNN.2010.5596877},
	abstract = {We present new approaches for 5-minute ahead electricity load forecasting. They were evaluated on data from the Australian electricity market operator for 2006-2008. After examining the load characteristics using autocorrelation analysis with 4-week sliding window, we selected 51 features. Using this feature set with linear regression and support vector regression we achieved an improvement of 7.56\% in the Mean Absolute Percentage Error (MAPE) over the industry model which uses backpropagation neural network. We then investigated the application of a number of methods for further feature subset selection. Using a subset of 38 and 14 of these features with the same algorithms we were able to achieve an improvement of 6.53\% and 4.81\% in MAPE, respectively, over the industry model.},
	booktitle = {The 2010 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Sood, R. and Koprinska, I. and Agelidis, V. G.},
	month = jul,
	year = {2010},
	keywords = {Algorithm design and analysis, Australian electricity market operator, Least squares approximation, Variable speed drives, autocorrelation analysis, backpropagation, backpropagation neural network, electricity load forecasting, load forecasting, mean absolute percentage error, neural nets, power engineering computing, power markets, regression analysis, support vector regression, with linear regression},
	pages = {1--8}
}

@inproceedings{kotillova_statistical_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Statistical and {Machine} {Learning} {Methods} for {Electricity} {Demand} {Prediction}},
	isbn = {978-3-642-34481-7},
	abstract = {We evaluate statistical and machine learning methods for half-hourly 1-step-ahead electricity demand prediction using Australian electricity data. We show that the machine learning methods, that use autocorrelation feature selection and Backpropagation Neural Networks, Linear Regression and Support Vector Regression as prediction algorithms, outperform the statistical methods Exponential Smoothing and ARIMA and also a number of baselines. We analyse the effect of the day time on the prediction error and show that there are time intervals associated with higher and lower errors and that the prediction methods also differ in their accuracy during the different time intervals. This analysis provides the foundation for a hybrid prediction model that achieved a prediction error MAPE of 0.51\%.},
	language = {en},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kotillova, Alexandra and Koprinska, Irena and Rana, Mashud},
	editor = {Huang, Tingwen and Zeng, Zhigang and Li, Chuandong and Leung, Chi Sing},
	year = {2012},
	keywords = {ARIMA, autocorrelation analysis, backpropagation neural networks, exponential smoothing, half-hourly electricity demand prediction, linear regression, support vector regression},
	pages = {535--542}
}

@inproceedings{uitenbogaard_measurement_1988,
	address = {Tokyo},
	title = {Measurement of turbulent fluxes in a steady, stratified mixing layer},
	booktitle = {3rd {Int}. {Symp}. on {Refined} {Flow} {Modelling} and {Turbulence} {Measurement}},
	author = {Uitenbogaard, R.E.},
	year = {1988}
}

@inproceedings{mcguirk_buoyant_1985,
	address = {Cornell University},
	title = {Buoyant surface layers under fully entraining and internal hydraulic jump conditions},
	booktitle = {5th {Symp}. on {Turbulent} {Shear} {Flows}, {Cornell} {University}},
	author = {McGuirk, J.J. and Papadimitriou, C.},
	year = {1985},
	pages = {22 -- 41}
}

@misc{ahrens_paraview:_2005,
	title = {{ParaView}: {An} {End}-{User} {Tool} for {Large} {Data} {Visualization}},
	author = {Ahrens, James and Geveci, Berk and Law, Charles},
	year = {2005}
}

@article{claesen_hyperparameter_2015,
	title = {Hyperparameter {Search} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1502.02127},
	abstract = {We describe the hyperparameter search problem in the ﬁeld of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can signiﬁcantly affect the resulting model’s performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.},
	language = {en},
	urldate = {2018-10-13TZ},
	journal = {arXiv:1502.02127 [cs, stat]},
	author = {Claesen, Marc and De Moor, Bart},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.02127},
	keywords = {Computer Science - Machine Learning, G.1.6, I.2.6, I.2.8, I.5, Statistics - Machine Learning}
}

@article{sola_importance_1997,
	title = {Importance of input data normalization for the application of neural networks to complex industrial problems - {IEEE} {Journals} \& {Magazine}},
	volume = {44},
	url = {https://ieeexplore-ieee-org.ezproxy1.library.usyd.edu.au/document/589532},
	doi = {10.1109/23.589532},
	number = {3},
	urldate = {2018-10-13TZ},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Sola, J. and Sevilla, J.},
	month = jun,
	year = {1997},
	pages = {1464 -- 1468}
}

@misc{noauthor_data_nodate,
	title = {Data {Normalization} to {Accelerate} {Training} for {Linear} {Neural} {Net} to {Predict} {Tropical} {Cyclone} {Tracks}},
	url = {https://www.hindawi.com/journals/mpe/2015/931629/},
	urldate = {2018-10-13TZ}
}

@article{xu_empirical_2015,
	title = {Empirical {Evaluation} of {Rectified} {Activations} in {Convolutional} {Network}},
	url = {http://arxiv.org/abs/1505.00853},
	abstract = {In this paper we investigate the performance of diﬀerent types of rectiﬁed activation functions in convolutional neural network: standard rectiﬁed linear unit (ReLU), leaky rectiﬁed linear unit (Leaky ReLU), parametric rectiﬁed linear unit (PReLU) and a new randomized leaky rectiﬁed linear units (RReLU). We evaluate these activation function on standard image classiﬁcation task. Our experiments suggest that incorporating a nonzero slope for negative part in rectiﬁed activation units could consistently improve the results. Thus our ﬁndings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overﬁtting. They are not as eﬀective as using their randomized counterpart. By using RReLU, we achieved 75.68\% accuracy on CIFAR-100 test set without multiple test or ensemble.},
	language = {en},
	urldate = {2018-10-13TZ},
	journal = {arXiv:1505.00853 [cs, stat]},
	author = {Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
	month = may,
	year = {2015},
	note = {arXiv: 1505.00853},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_using_nodate,
	title = {Using {Deep} {Learning} to {Predict} {Complex} {Systems}: {A} {Case} {Study} in {Wind} {Farm} {Generation}},
	url = {https://www.hindawi.com/journals/complexity/2018/9327536/},
	urldate = {2018-10-13TZ}
}

@article{schaer_optimized_2016,
	title = {Optimized {Distributed} {Hyperparameter} {Search} and {Simulation} for {Lung} {Texture} {Classification} in {CT} {Using} {Hadoop}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2313-433X/2/2/19},
	doi = {10.3390/jimaging2020019},
	abstract = {Many medical image analysis tasks require complex learning strategies to reach a quality of image-based decision support that is sufficient in clinical practice. The analysis of medical texture in tomographic images, for example of lung tissue, is no exception. Via a learning framework, very good classification accuracy can be obtained, but several parameters need to be optimized. This article describes a practical framework for efficient distributed parameter optimization. The proposed solutions are applicable for many research groups with heterogeneous computing infrastructures and for various machine learning algorithms. These infrastructures can easily be connected via distributed computation frameworks. We use the Hadoop framework to run and distribute both grid and random search strategies for hyperparameter optimization and cross-validations on a cluster of 21 nodes composed of desktop computers and servers. We show that significant speedups of up to 364× compared to a serial execution can be achieved using our in-house Hadoop cluster by distributing the computation and automatically pruning the search space while still identifying the best-performing parameter combinations. To the best of our knowledge, this is the first article presenting practical results in detail for complex data analysis tasks on such a heterogeneous infrastructure together with a linked simulation framework that allows for computing resource planning. The results are directly applicable in many scenarios and allow implementing an efficient and effective strategy for medical (image) data analysis and related learning approaches.},
	language = {en},
	number = {2},
	urldate = {2018-10-11TZ},
	journal = {Journal of Imaging},
	author = {Schaer, Roger and Müller, Henning and Depeursinge, Adrien and Schaer, Roger and Müller, Henning and Depeursinge, Adrien},
	month = jun,
	year = {2016},
	keywords = {distributed computing, grid search, hyperparameter optimization, image analysis, random forests, random search, support vector machines},
	pages = {19}
}

@misc{noauthor_j._nodate,
	title = {J. {Imaging} {\textbar} {Free} {Full}-{Text} {\textbar} {Optimized} {Distributed} {Hyperparameter} {Search} and {Simulation} for {Lung} {Texture} {Classification} in {CT} {Using} {Hadoop} {\textbar} {HTML}},
	url = {https://www.mdpi.com/2313-433X/2/2/19/htm},
	urldate = {2018-10-11TZ}
}

@article{bergstra_random_2012,
	title = {Random {Search} for {Hyper}-parameter {Optimization}},
	volume = {13},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=2188385.2188395},
	abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
	urldate = {2018-10-11TZ},
	journal = {J. Mach. Learn. Res.},
	author = {Bergstra, James and Bengio, Yoshua},
	month = feb,
	year = {2012},
	keywords = {deep learning, global optimization, model selection, neural networks, response surface modeling},
	pages = {281--305}
}

@article{ponce_shallow_1977,
	title = {Shallow {Wave} {Propagation} in {Open} {Channel} {Flow}},
	volume = {103},
	url = {http://cedb.asce.org/CEDBsearch/record.jsp?dockey=0007750},
	abstract = {{\textless}p{\textgreater}The propagation characteristics of various types of shallow water waves in open channel flow are calculated on the basis of linear stability theory. The celerity and attenuation functions of kinematic, diffusion, convective dynamic, dynamic and gravity waves, are derived. For the most general case, i.e., the dynamic wave model, the propagation characteristics are expressed as a function of the steady uniform flow Froude number and the dimensionless wave number of the unsteady component of the motion. For the dynamic model, the wave number spectrum is divided into three bands: 1)A gravity band corresponding to large wave number, where the wave celerity is the gravity wave celerity; 2)a kinematic band corresponding to a small wave number where the wave celerity is the kinematic wave celerity; and 3)a dynamic band corresponding to mid-spectrum values of the wave number, where the wave celerity falls between the gravity and kinematic celerity values.{\textless}/p{\textgreater}},
	language = {eng},
	number = {12},
	urldate = {2018-10-11TZ},
	journal = {Journal of the Hydraulics Division},
	author = {Ponce, Victor Miguel and Simons, Daryl B.},
	year = {1977},
	pages = {1461--1476}
}

@inproceedings{t._swean_turbulence_1991,
	address = {Reno,NV,U.S.A.},
	title = {Turbulence modeling near the free surface in an open channel flow},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.1991-613},
	abstract = {The velocity data from a direct numerical simulation of low Reynolds number turbulence in an open channel have been used to compute the terms in the budget equations for the turbulence kinetic energy, the dissipation of turbulence kinetic energy and the Reynolds stresses. The budget data show that the dissipation rates of the horizontal components of the turbulence are reduced near the surface while the dissipation of the vertical component remains approximately constant. The data also show that the pressure-strain term is the dominant producing term for the spanwise component of energy in the near surface region. A model for this behavior valid for flows exhibiting homogeneity in the spanwise and streamwise directions is proposed and tested against the data. In general the model is found to work well but wider testing is necessary.},
	urldate = {2018-10-11TZ},
	booktitle = {29th {Aerospace} {Sciences} {Meeting}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {T. Swean, JR. and Leighton, R. and Handler, R. and Swearingen, J.},
	year = {1991},
	doi = {10.2514/6.1991-613}
}

@article{faure_3-d_2004,
	title = {3-{D} {Modeling} of unsteady free-surface flow in open channel},
	volume = {42},
	issn = {0022-1686},
	url = {https://doi.org/10.1080/00221686.2004.9728391},
	doi = {10.1080/00221686.2004.9728391},
	abstract = {We present the hydrodynamic part of a three-dimensional model for pollutant dispersion in turbulent free-surface flow in open channels. It does not require any strong assumption such as hydrostatic pressure and is able to simulate an unsteady free-surface flow as flood waves or discharge over a weir. Our main objective was to model the moving free-surface and the boundary conditions under two constraints. The first constraint was to keep a point of view as close as possible to that of the 1-D modeling generally used in river engineering, especially relative to the upstream and downstream boundary conditions. The second one was that our model had to be sufficiently flexible to be implemented in a general computational fluid dynamics package. After describing our model, we present some numerical tests and comparisons with 1-D simulations from a hydrodynamic point of view.},
	number = {3},
	urldate = {2018-10-11TZ},
	journal = {Journal of Hydraulic Research},
	author = {Faure, J.-B. and Buil, N. and Gay, B.},
	month = jan,
	year = {2004},
	keywords = {3-D modeling, Free-surface flow, Navier-Stokes equations, river flow, shallow-water equations},
	pages = {263--272}
}

@article{nakayama_modeling_2003,
	title = {Modeling {Free}-{Surface} {Fluctuation} {Effects} for {Calculation} of {Turbulent} {Open}-{Channel} {Flows}},
	volume = {3},
	issn = {1573-1510},
	url = {https://doi.org/10.1023/A:1021136912983},
	doi = {10.1023/A:1021136912983},
	abstract = {A new method of introducing the free-surface effects in the calculation of turbulent open-channel flows using the amplitude of the free-surface fluctuation is proposed along with a modeling method of the equation for the free-surface fluctuation. It can be incorporated in two-equation models like k-εor k-ωtype models by introducing the damping factor to represent the interaction of the eddies with the fluctuating free-surface. Test calculations for fully developed flows and those over backward-facing step indicate good agreement with direct numerical simulation results as well as experimental results.},
	language = {en},
	number = {1},
	urldate = {2018-10-11TZ},
	journal = {Environmental Fluid Mechanics},
	author = {Nakayama, Akihiko and Yokojima, Satoshi},
	month = mar,
	year = {2003},
	keywords = {free-surface fluctuation, numerical calculation, open-channel flow, turbulence model},
	pages = {1--21}
}

@article{dong_direct_2005,
	title = {Direct numerical simulation of stably and unstably stratified turbulent open channel flows},
	volume = {177},
	issn = {1619-6937},
	url = {https://doi.org/10.1007/s00707-005-0229-z},
	doi = {10.1007/s00707-005-0229-z},
	abstract = {SummaryDirect numerical simulation of stably and unstably stratified turbulent open channel flow is performed. The three-dimensional Navier-Stokes and energy equations under the Boussinesq approximation are numerically solved using a fractional-step method based on high-order accurate spatial schemes. The objective of this study is to reveal the effects of thermally stable and unstable stratification on the characteristics of turbulent flow and heat transfer and on turbulence structures near the free surface of open channel flow. Here, fully developed weakly stratified turbulent open channel flows are calculated for the Richardson number ranging from 20 (stably stratified flow) to 0 (unstratified flow) and to −10 (unstably stratified flow), the Reynolds number 180 based on the wall friction velocity and the channel depth, and the Prandtl number 1. To elucidate the turbulent flow and heat transfer behaviors, typical quantities including the mean velocity, temperature and their fluctuations, turbulent heat fluxes, and the structures of velocity and temperature fluctuations are analyzed.},
	language = {en},
	number = {1},
	urldate = {2018-10-11TZ},
	journal = {Acta Mechanica},
	author = {Dong, Y. -H. and Lu, X. -Y.},
	month = jul,
	year = {2005},
	keywords = {Direct Numerical Simulation, Heat Flux, Heat Transfer, Prandtl Number, Reynolds Number},
	pages = {115--136}
}

@article{taylor_large_2005,
	title = {Large eddy simulation of stably stratified open channel flow},
	volume = {17},
	issn = {1070-6631, 1089-7666},
	url = {http://aip.scitation.org/doi/10.1063/1.2130747},
	doi = {10.1063/1.2130747},
	language = {en},
	number = {11},
	urldate = {2018-10-11TZ},
	journal = {Physics of Fluids},
	author = {Taylor, John R. and Sarkar, Sutanu and Armenio, Vincenzo},
	month = nov,
	year = {2005},
	pages = {116602}
}

@article{deusebio_direct_2011,
	title = {Direct numerical simulations of stratified open channel flows},
	volume = {318},
	issn = {1742-6596},
	url = {http://stacks.iop.org/1742-6596/318/i=2/a=022009},
	doi = {10.1088/1742-6596/318/2/022009},
	abstract = {We carry out numerical simulations of wall-bounded stably stratified flows. We mainly focus on how stratification affects the near-wall turbulence at moderate Reynolds numbers, i.e. Re τ = 360. A set of fully-resolved open channel flow simulations is performed, where a stable stratification has been introduced through a negative heat flux at the lower wall. In agreement with previous studies, it is found that turbulence cannot be sustained for h/L values higher than 1.2, where L is the so-called Monin-Obukhov length and h is the height of the open channel. For smaller values, buoyancy does not re-laminarize the flow, but nevertheless affects the wall turbulence. Near-wall streaks are weakly affected by stratification, whereas the outer modes are increasingly damped as we move away from the wall. A decomposition of the wall-normal velocity is proposed in order to separate the gravity wave and turbulent flow fields. This method has been tested both for open channel and full channel flows. Gravity waves are likely to develop and to dominate close to the upper boundary (centerline for full channel). However, their intensity is weaker in the open channel, possibly due to the upper boundary condition. Moreover, the presence of internal gravity waves can also be deduced from a correlation analysis, which reveals (together with spanwise spectra) a narrowing of the outer structures as the stratification is increased.},
	language = {en},
	number = {2},
	urldate = {2018-10-11TZ},
	journal = {Journal of Physics: Conference Series},
	author = {Deusebio, E. and Schlatter, P. and Brethouwer, G. and Lindborg, E.},
	year = {2011},
	pages = {022009}
}

@article{komori_turbulence_1983,
	title = {Turbulence structure in stably stratified open-channel flow},
	volume = {130},
	issn = {1469-7645, 0022-1120},
	url = {http://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/turbulence-structure-in-stably-stratified-openchannel-flow/74C716F46BB78899BC053ED6A0046F61#},
	doi = {10.1017/S0022112083000944},
	abstract = {The effects of stable stratification on turbulence structure have been experimentally investigated in stratified open-channel flow and a theoretical spectral-equation model has been applied to the stably stratified flow. The measurements were made in the outer layer of open-channel flow with strongly stable density gradient, where the wall effect was small. Velocity and temperature fluctuations were simultaneously measured by a laser-Doppler velocimeter and a cold-film probe. Measurements include turbulent intensities, correlation coefficients of turbulent fluxes and coherence–phase relationships. These turbulent quantities were correlated with the local gradient Richardson number and compared with the values calculated using a spectral-equation model and with other laboratory measurements. In stable conditions, turbulent motions approach wavelike motions, and negative heat and momentum transfer against the mean temperature and velocity gradient occurs in strongly stable stratification.},
	language = {en},
	urldate = {2018-10-11TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Komori, Satoru and Ueda, Hiromasa and Ogino, Fumimaru and Mizushina, Tokuro},
	month = may,
	year = {1983},
	pages = {13--26}
}

@inproceedings{zeman_buoyancy_1979,
	title = {Buoyancy {Effects} in {Entraining} {Turbulent} {Boundary} {Layers}: a {Second}-{Order} {Closure} {Study}},
	isbn = {978-3-642-46395-2},
	shorttitle = {Buoyancy {Effects} in {Entraining} {Turbulent} {Boundary} {Layers}},
	abstract = {A second-order modeling technique is used to investigate the structure of turbulent boundary layers under stable, neutral, and unstable conditions. Special attention is paid to the evening transition from a convective to a stable regime of an atmospheric entraining boundary layer capped by an inversion.The second-order closure scheme utilizes the turbulent transport model which incorporates buoyancy effects (Zeman and Lumley [4]). The importance of the buoyancy contributions in the turbulent transport model for the process of entrainment and for the turbulence decay during the evening transition is assessed, and the realizability of the model equations under conditions of strong stable stratification is discussed.},
	language = {en},
	booktitle = {Turbulent {Shear} {Flows} {I}},
	publisher = {Springer Berlin Heidelberg},
	author = {Zeman, O. and Lumley, J. L.},
	editor = {Durst, Franz and Launder, Brian E. and Schmidt, Frank W. and Whitelaw, James H.},
	year = {1979},
	keywords = {Atmospheric Boundary Layer, Planetary Boundary Layer, Reynolds Stress Model, Surface Heat Flux, Turbulent Boundary Layer},
	pages = {295--306}
}

@incollection{zeman_buoyancy_1979-1,
	title = {Buoyancy effects in entraining turbulent boundary layers: a second order closure study},
	isbn = {978-3-540-09041-0},
	shorttitle = {Buoyancy effects in entraining turbulent boundary layers},
	author = {Zeman, O. and Lumley, J. L.},
	month = jan,
	year = {1979}
}

@article{craft_recent_1996,
	series = {Stratified flows},
	title = {Recent developments in second-moment closure for buoyancy-affected flows},
	volume = {23},
	issn = {0377-0265},
	url = {http://www.sciencedirect.com/science/article/pii/0377026595004246},
	doi = {10.1016/0377-0265(95)00424-6},
	abstract = {The paper summarizes a new type of second-moment closure, more elaborate in form than earlier versions but designed to satisfy the two-component limit to which turbulence reduces at a wall or at a sharp density interface. Because they are intrinsically realizable, closures of this type are believed to offer the prospects of a wider range of applicability than earlier schemes. They may also be expected to display better numerical stability. Several illustrative applications are provided including the downward directed warm jet, the stratified mixing layer and buoyancy affected grid-turbulence decay. Extension of the scheme to near wall flows appears possible without introducing empirical ‘wall-reflection’ terms, at least in flows parallel to walls.},
	number = {1},
	urldate = {2018-10-10TZ},
	journal = {Dynamics of Atmospheres and Oceans},
	author = {Craft, T. J. and Ince, N. Z. and Launder, B. E.},
	month = jan,
	year = {1996},
	pages = {99--114}
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	year = {2011},
	pages = {2825--2830}
}

@article{cheng_wide_2016,
	title = {Wide \& {Deep} {Learning} for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1606.07792},
	abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide \& Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide \& Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
	urldate = {2018-10-03TZ},
	journal = {arXiv:1606.07792 [cs, stat]},
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.07792},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@inproceedings{pandey_go_nodate,
	title = {To go deep or wide in learning?},
	abstract = {To achieve acceptable performance for AI tasks, one can either use sophisticated feature extraction methods as the ﬁrst layer in a twolayered supervised learning model, or learn the features directly using a deep (multilayered) model. While the ﬁrst approach is very problem-speciﬁc, the second approach has computational overheads in learning multiple layers and ﬁne-tuning of the model. In this paper, we propose an approach called wide learning based on arc-cosine kernels, that learns a single layer of inﬁnite width. We propose exact and inexact learning strategies for wide learning and show that wide learning with single layer outperforms single layer as well as deep architectures of ﬁnite width for some benchmark datasets.},
	language = {en},
	author = {Pandey, Gaurav and Dukkipati, Ambedkar},
	pages = {9}
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {https://arxiv.org/abs/1502.03167},
	language = {en},
	urldate = {2018-10-03TZ},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = feb,
	year = {2015}
}

@misc{noauthor_[1502.03167]_nodate,
	title = {[1502.03167] {Batch} {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	url = {https://arxiv.org/abs/1502.03167},
	urldate = {2018-10-03TZ}
}

@article{friedman_greedy_2001,
	title = {Greedy function approximation: {A} gradient boosting machine.},
	volume = {29},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Greedy function approximation},
	url = {https://projecteuclid.org/euclid.aos/1013203451},
	doi = {10.1214/aos/1013203451},
	abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent “boosting” paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such “TreeBoost” models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
	language = {en},
	number = {5},
	urldate = {2018-09-13TZ},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome H.},
	year = {2001},
	mrnumber = {MR1873328},
	zmnumber = {1043.62034},
	keywords = {Function estimation, boosting, decision trees, robust nonparametric regression},
	pages = {1189--1232}
}

@article{perianez_churn_2016,
	title = {Churn {Prediction} in {Mobile} {Social} {Games}: {Towards} a {Complete} {Assessment} {Using} {Survival} {Ensembles}},
	shorttitle = {Churn {Prediction} in {Mobile} {Social} {Games}},
	url = {http://arxiv.org/abs/1710.02264},
	doi = {10.1109/DSAA.2016.84},
	abstract = {Reducing user attrition, i.e. churn, is a broad challenge faced by several industries. In mobile social games, decreasing churn is decisive to increase player retention and rise revenues. Churn prediction models allow to understand player loyalty and to anticipate when they will stop playing a game. Thanks to these predictions, several initiatives can be taken to retain those players who are more likely to churn. Survival analysis focuses on predicting the time of occurrence of a certain event, churn in our case. Classical methods, like regressions, could be applied only when all players have left the game. The challenge arises for datasets with incomplete churning information for all players, as most of them still connect to the game. This is called a censored data problem and is in the nature of churn. Censoring is commonly dealt with survival analysis techniques, but due to the inflexibility of the survival statistical algorithms, the accuracy achieved is often poor. In contrast, novel ensemble learning techniques, increasingly popular in a variety of scientific fields, provide high-class prediction results. In this work, we develop, for the first time in the social games domain, a survival ensemble model which provides a comprehensive analysis together with an accurate prediction of churn. For each player, we predict the probability of churning as function of time, which permits to distinguish various levels of loyalty profiles. Additionally, we assess the risk factors that explain the predicted player survival times. Our results show that churn prediction by survival ensembles significantly improves the accuracy and robustness of traditional analyses, like Cox regression.},
	urldate = {2018-09-13TZ},
	journal = {2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
	author = {Periáñez, África and Saas, Alain and Guitart, Anna and Magne, Colin},
	month = oct,
	year = {2016},
	note = {arXiv: 1710.02264},
	keywords = {Statistics - Machine Learning},
	pages = {564--573}
}

@misc{noauthor_handling_nodate,
	title = {Handling class imbalance in customer churn prediction - {ScienceDirect}},
	url = {https://www-sciencedirect-com.ezproxy1.library.usyd.edu.au/science/article/pii/S0957417408002121},
	urldate = {2018-09-13TZ}
}
@article{lemmens_bagging_2006,
	title = {Bagging and boosting classification trees to predict churn},
	abstract = {TO PREDICT CHURN In this paper, bagging and boosting techniques are proposed as performing tools for churn prediction. These methods consist of sequentially applying a classification algorithm to resampled or reweigthed versions of the data set. We apply these algorithms on a customer database of an anonymous U.S. wireless telecom company. Bagging is easy to put in practice and, as well as boosting, leads to a significant increase of the classification performance when applied to the customer database. Furthermore, we compare bagged and boosted classifiers computed, respectively, from a balanced versus a proportional sample to predict a rare event (here, churn), and propose a simple correction method for classifiers constructed from balanced training samples.},
	journal = {Journal of Marketing Research},
	author = {Lemmens, Aurélie and Croux, Christophe},
	year = {2006},
	pages = {276--286}
}

@article{cui_prediction_2005,
	title = {Prediction in {Marketing} {Using} the {Support} {Vector} {Machine}},
	volume = {24},
	issn = {0732-2399},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mksc.1050.0123},
	doi = {10.1287/mksc.1050.0123},
	abstract = {Many marketing problems require accurately predicting the outcome of a process or the future state of a system. In this paper, we investigate the ability of the support vector machine to predict outcomes in emerging environments in marketing, such as automated modeling, mass-produced models, intelligent software agents, and data mining. The support vector machine (SVM) is a semiparametric technique with origins in the machine-learning literature of computer science. Its approach to prediction differs markedly from that of standard parametric models. We explore these differences and benchmark the SVM's prediction hit-rates against those from the multinomial logit model. Because there are few applications of the SVM in marketing, we develop a framework to position it against current modeling techniques and to assess its weaknesses as well as its strengths.},
	number = {4},
	urldate = {2018-09-13TZ},
	journal = {Marketing Science},
	author = {Cui, Dapeng and Curry, David},
	month = nov,
	year = {2005},
	pages = {595--615}
}

@article{farquad_churn_2014,
	title = {Churn prediction using comprehensible support vector machine: {An} analytical {CRM} application},
	volume = {19},
	issn = {1568-4946},
	shorttitle = {Churn prediction using comprehensible support vector machine},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494614000507},
	doi = {10.1016/j.asoc.2014.01.031},
	abstract = {Support vector machine (SVM) is currently state-of-the-art for classification tasks due to its ability to model nonlinearities. However, the main drawback of SVM is that it generates “black box” model, i.e. it does not reveal the knowledge learnt during training in human comprehensible form. The process of converting such opaque models into a transparent model is often regarded as rule extraction. In this paper we proposed a hybrid approach for extracting rules from SVM for customer relationship management (CRM) purposes. The proposed hybrid approach consists of three phases. (i) During first phase; SVM-RFE (SVM-recursive feature elimination) is employed to reduce the feature set. (ii) Dataset with reduced features is then used in the second phase to obtain SVM model and support vectors are extracted. (iii) Rules are then generated using Naive Bayes Tree (NBTree) in the final phase. The dataset analyzed in this research study is about Churn prediction in bank credit card customer (Business Intelligence Cup 2004) and it is highly unbalanced with 93.24\% loyal and 6.76\% churned customers. Further we employed various standard balancing approaches to balance the data and extracted rules. It is observed from the empirical results that the proposed hybrid outperformed all other techniques tested. As the reduced feature dataset is used, it is also observed that the proposed approach extracts smaller length rules, thereby improving the comprehensibility of the system. The generated rules act as an early warning expert system to the bank management.},
	urldate = {2018-09-13TZ},
	journal = {Applied Soft Computing},
	author = {Farquad, M. A. H. and Ravi, Vadlamani and Raju, S. Bapi},
	month = jun,
	year = {2014},
	keywords = {Churn prediction, Machine learning and customer relationship management, Naive Bayes Tree, Rule extraction, Support vector machine},
	pages = {31--40}
}

@article{tu_advantages_1996,
	title = {Advantages and disadvantages of using artificial neural networks versus logistic regression for predicting medical outcomes},
	volume = {49},
	issn = {0895-4356},
	abstract = {Artificial neural networks are algorithms that can be used to perform nonlinear statistical modeling and provide a new alternative to logistic regression, the most commonly used method for developing predictive models for dichotomous outcomes in medicine. Neural networks offer a number of advantages, including requiring less formal statistical training, ability to implicitly detect complex nonlinear relationships between dependent and independent variables, ability to detect all possible interactions between predictor variables, and the availability of multiple training algorithms. Disadvantages include its "black box" nature, greater computational burden, proneness to overfitting, and the empirical nature of model development. An overview of the features of neural networks and logistic regression is presented, and the advantages and disadvantages of using this modeling technique are discussed.},
	language = {eng},
	number = {11},
	journal = {Journal of Clinical Epidemiology},
	author = {Tu, J. V.},
	month = nov,
	year = {1996},
	pmid = {8892489},
	keywords = {Algorithms, Humans, Logistic Models, Neural Networks (Computer), Prognosis, Treatment Outcome},
	pages = {1225--1231}
}

@article{wei_turning_2002,
	title = {Turning telecommunications call details to churn prediction: a data mining approach},
	volume = {23},
	issn = {0957-4174},
	shorttitle = {Turning telecommunications call details to churn prediction},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417402000301},
	doi = {10.1016/S0957-4174(02)00030-1},
	abstract = {As deregulation, new technologies, and new competitors open up the mobile telecommunications industry, churn prediction and management has become of great concern to mobile service providers. A mobile service provider wishing to retain its subscribers needs to be able to predict which of them may be at-risk of changing services and will make those subscribers the focus of customer retention efforts. In response to the limitations of existing churn-prediction systems and the unavailability of customer demographics in the mobile telecommunications provider investigated, we propose, design, and experimentally evaluate a churn-prediction technique that predicts churning from subscriber contractual information and call pattern changes extracted from call details. This proposed technique is capable of identifying potential churners at the contract level for a specific prediction time-period. In addition, the proposed technique incorporates the multi-classifier class-combiner approach to address the challenge of a highly skewed class distribution between churners and non-churners. The empirical evaluation results suggest that the proposed call-behavior-based churn-prediction technique exhibits satisfactory predictive effectiveness when more recent call details are employed for the churn prediction model construction. Furthermore, the proposed technique is able to demonstrate satisfactory or reasonable predictive power within the one-month interval between model construction and churn prediction. Using a previous demographics-based churn-prediction system as a reference, the lift factors attained by our proposed technique appear largely satisfactory.},
	number = {2},
	urldate = {2018-09-13TZ},
	journal = {Expert Systems with Applications},
	author = {Wei, Chih-Ping and Chiu, I-Tang},
	month = aug,
	year = {2002},
	keywords = {Churn management, Churn prediction, Classification analysis, Data mining, Decision tree induction, Multi-classifier class-combiner approach, Telecommunications data mining},
	pages = {103--112}
}

@article{xie_customer_2009,
	title = {Customer churn prediction using improved balanced random forests},
	volume = {36},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417408004326},
	doi = {10.1016/j.eswa.2008.06.121},
	abstract = {Churn prediction is becoming a major focus of banks in China who wish to retain customers by satisfying their needs under resource constraints. In churn prediction, an important yet challenging problem is the imbalance in the data distribution. In this paper, we propose a novel learning method, called improved balanced random forests (IBRF), and demonstrate its application to churn prediction. We investigate the effectiveness of the standard random forests approach in predicting customer churn, while also integrating sampling techniques and cost-sensitive learning into the approach to achieve a better performance than most existing algorithms. The nature of IBRF is that the best features are iteratively learned by altering the class distribution and by putting higher penalties on misclassification of the minority class. We apply the method to a real bank customer churn data set. It is found to improve prediction accuracy significantly compared with other algorithms, such as artificial neural networks, decision trees, and class-weighted core support vector machines (CWC-SVM). Moreover, IBRF also produces better prediction results than other random forests algorithms such as balanced random forests and weighted random forests.},
	number = {3, Part 1},
	urldate = {2018-09-13TZ},
	journal = {Expert Systems with Applications},
	author = {Xie, Yaya and Li, Xiu and Ngai, E. W. T. and Ying, Weiyun},
	month = apr,
	year = {2009},
	keywords = {Churn prediction, Imbalanced data, Random forests},
	pages = {5445--5449}
}

@inproceedings{bin_customer_2007,
	title = {Customer {Churn} {Prediction} {Based} on the {Decision} {Tree} in {Personal} {Handyphone} {System} {Service}},
	doi = {10.1109/ICSSSM.2007.4280145},
	abstract = {Nowadays, churn prediction and management is critical for more and more companies in the fast changing and strongly competitive telecommunication market. In order to improve customer retention, telecommunication companies must be able to predict customers at risk who are prone to switch service provider. In this study, to overcome the limitations of lack of information of customers of Personal Handyphone System Service (PHSS) and to build an effective and accurate customer churn model, three research experimentations (changing sub-periods for training data sets, changing misclassification cost in churn model, changing sample methods for training data sets) are put forward to improve the prediction performance of churn model by using decision tree which is used widely, some optimal parameters (the time of sub-period being 10 days, misclassification cost being 1:5, and random sample method for train set) of models are found under the help of three research experimentations. The empirical evaluation results suggest that customer churn models built have a good performance through the course of model optical selecting, and show that the methods and techniques proposed are effective and feasible under the condition that information of customers is very little and class distribution is skewed. This study benefits not only churn prediction research and practice but also other data mining applications with similar characteristics.},
	booktitle = {2007 {International} {Conference} on {Service} {Systems} and {Service} {Management}},
	author = {Bin, L. and Peiji, S. and Juan, L.},
	month = jun,
	year = {2007},
	keywords = {Business Intelligence, Churn, Consumer electronics, Cost function, Data mining, Decision Tree, Decision trees, Optical saturation, PHSS, Personal Handyphone System Service, Predictive models, Switches, Technology management, Telecommunication switching, Training data, customer churn prediction, customer services, data mining applications, decision tree, decision trees, personal communication networks, personal handyphone system service, service industries, service provider, telecommunication companies, telecommunication market},
	pages = {1--5}
}

@inproceedings{dietterich_ensemble_2000,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ensemble {Methods} in {Machine} {Learning}},
	isbn = {978-3-540-45014-6},
	abstract = {Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classifier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overfit rapidly.},
	language = {en},
	booktitle = {Multiple {Classifier} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dietterich, Thomas G.},
	year = {2000},
	keywords = {Decision Tree, Ensemble Method, Input Feature, Learning Algorithm, Training Data},
	pages = {1--15}
}

@techreport{gronros_predicting_2018,
	address = {Stockholm, Sweden},
	title = {Predicting {Customer} {Churn} {Rate} in the {iGaming} {Industry} using {Supervised} {Machine} {Learning}},
	url = {https://www.math.kth.se/matstat/seminarier/reports/M-exjobb18/180601b.pdf},
	language = {en},
	institution = {KTH Royal Institute of Technology},
	author = {Grönros, Lovisa and Janér, Ida},
	year = {2018},
	pages = {68}
}

@article{pohar_comparison_2004,
	title = {Comparison of {Logistic} {Regression} and {Linear} {Discriminant} {Analysis}: {A} {Simulation} {Study}},
	volume = {1},
	url = {https://www.stat-d.si/mz/mz1.1/pohar.pdf},
	abstract = {Two of the most widely used statistical methods for analyzing categorical outcome variables are linear discriminant analysis and logistic regression. While both are appropriate for the development of linear classification models, linear discriminant analysis makes more assumptions about the underlying data. Hence, it is assumed that logistic regression is the more flexible and more robust method in case of violations of these assumptions. In this paper we consider the problem of choosing between the two methods, and set some guidelines for proper choice. The comparison between the methods is based on several measures of predictive accuracy. The performance of the methods is studied by simulations. We start with an example where all the assumptions of the linear discriminant analysis are satisfied and observe the impact of changes regarding the sample size, covariance matrix, Mahalanobis distance and direction of distance between group means. Next, we compare the robustness of the methods towards categorisation and non-normality of explanatory variables in a closely controlled way. We show that the results of LDA and LR are close whenever the normality assumptions are not too badly violated, and set some guidelines for recognizing these situations. We discuss the inappropriateness of LDA in all other cases.},
	language = {en},
	number = {1},
	journal = {Metodološki zvezki},
	author = {Pohar, Maja and Blas, Mateja and Turk, Sandra},
	year = {2004},
	pages = {143 -- 161}
}

@inproceedings{kiran_dahiya_customer_2015,
	title = {Customer churn analysis in telecom industry - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore-ieee-org.ezproxy1.library.usyd.edu.au/document/7359318/},
	doi = {10.1109/ICRITO.2015.7359318},
	abstract = {With the rapid development of telecommunication industry, the service providers are inclined more towards expansion of the subscriber base. To meet the need of surviving in the competitive environment, the retention of existing customers has become a huge challenge. In the survey done in the Telecom industry, it is stated that the cost of acquiring a new customer is far more that retaining the existing one. Therefore, by collecting knowledge from the telecom industries can help in predicting the association of the customers as whether or not they will leave the company. The required action needs to be undertaken by the telecom industries in order to initiate the acquisition of their associated customers for making their market value stagnant. Our paper proposes a new framework for the churn prediction model and implements it using the WEKA Data Mining software. The efficiency and the performance of Decision tree and Logistic regression techniques have been compared.},
	urldate = {2018-09-13TZ},
	publisher = {IEEE},
	author = {{Kiran Dahiya} and {Surbhi Bhatia}},
	year = {2015}
}

@article{radosavljevik_impact_2010,
	title = {The {Impact} of {Experimental} {Setup} in {Prepaid} {Churn} {Prediction} for {Mobile} {Telecommunications}: {What} to {Predict}, for {Whom} and {Does} the {Customer} {Experience} {Matter}?},
	volume = {3},
	url = {https://pdfs.semanticscholar.org/e5eb/e01c9348f60eb6dbb277d71de4262dadf056.pdf},
	abstract = {Prepaid customers in mobile telecommunications are not bound by a contract and can therefore change operators (‘churn’) at their convenience and without notification. This makes the task of predicting prepaid churn both challenging and financially rewarding. This paper presents an explorative, real world study of prepaid churn modeling by varying the experimental setup on three dimensions: data, outcome definition and population sample. Firstly, we add Customer Experience Management (CEM) data to data traditionally used for prepaid churn prediction. Secondly, we vary the outcome definition of prepaid churn. Thirdly, we alter the sample of the customers included, based on their inactivity period at the time of recording. While adding CEM parameters did not influence the predictability of churn, one variation on the sample and especially a particular change in the outcome definition had a substantial influence.},
	language = {en},
	number = {2},
	journal = {Transactions on Machine Learning and Data Mining},
	author = {Radosavljevik, Dejan},
	month = jan,
	year = {2010},
	pages = {20}
}

@article{mohammadi_hierarchical_2013,
	title = {Hierarchical {Neural} {Regression} {Models} for {Customer} {Churn} {Prediction}},
	url = {https://www.hindawi.com/journals/je/2013/543940/},
	abstract = {As customers are the main assets of each industry, customer churn prediction is becoming a major task for companies to remain in competition with competitors. In the literature, the better applicability and efficiency of hierarchical data mining techniques has been reported. This paper considers three hierarchical models by combining four different data mining techniques for churn prediction, which are backpropagation artificial neural networks (ANN), self-organizing maps (SOM), alpha-cut fuzzy c-means (α-FCM), and Cox proportional hazards regression model. The hierarchical models are ANN},
	language = {en},
	urldate = {2018-09-13TZ},
	journal = {Journal of Engineering},
	author = {Mohammadi, Golshan and Tavakkoli-Moghaddam, Reza and Mohammadi, Mehrdad},
	year = {2013},
	doi = {10.1155/2013/543940}
}

@book{kleinbaum_survival_2012,
	address = {New York},
	edition = {3rd ed},
	series = {Statistics for biology and health},
	title = {Survival analysis: a self-learning text},
	isbn = {978-1-4419-6645-2 978-1-4419-6646-9},
	shorttitle = {Survival analysis},
	language = {en},
	publisher = {Springer},
	author = {Kleinbaum, David G. and Klein, Mitchel},
	year = {2012},
	note = {OCLC: ocn760292284},
	keywords = {Programmed Instruction, Survival Analysis, Survival analysis (Biometry)}
}

@article{boruvka_cox-aalen_2015,
	title = {A {Cox}-{Aalen} {Model} for {Interval}-censored {Data}},
	volume = {42},
	copyright = {© 2014 Board of the Foundation of the Scandinavian Journal of Statistics.},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12113},
	doi = {10.1111/sjos.12113},
	abstract = {AbstractThe Cox-Aalen model, obtained by replacing the baseline hazard function in the well-known Cox model with a covariate-dependent Aalen model, allows for both fixed and dynamic covariate effects. In this paper, we examine maximum likelihood estimation for a Cox-Aalen model based on interval-censored failure times with fixed covariates. The resulting estimator globally converges to the truth slower than the parametric rate, but its finite-dimensional component is asymptotically efficient. Numerical studies show that estimation via a constrained Newton method performs well in terms of both finite sample properties and processing time for moderate-to-large samples with few covariates. We conclude with an application of the proposed methods to assess risk factors for disease progression in psoriatic arthritis.},
	language = {en},
	number = {2},
	urldate = {2018-09-13TZ},
	journal = {Scandinavian Journal of Statistics},
	author = {Boruvka, Audrey and Cook, Richard J.},
	month = jun,
	year = {2015},
	keywords = {maximum likelihood estimation, profile likelihood, quadratic programming, semiparametric model, survival data},
	pages = {414--426}
}

@article{efron_logistic_1988,
	title = {Logistic {Regression}, {Survival} {Analysis}, and the {Kaplan}-{Meier} {Curve}},
	volume = {83},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2288857},
	doi = {10.2307/2288857},
	abstract = {We discuss the use of standard logistic regression techniques to estimate hazard rates and survival curves from censored data. These techniques allow the statistician to use parametric regression modeling on censored data in a flexible way that provides both estimates and standard errors. An example is given that demonstrates the increased structure that can be seen in a parametric analysis, as compared with the nonparametric Kaplan-Meier survival curves. In fact, the logistic regression estimates are closely related to Kaplan-Meier curves, and approach the Kaplan-Meier estimate as the number of parameters grows large.},
	number = {402},
	urldate = {2018-09-13TZ},
	journal = {Journal of the American Statistical Association},
	author = {Efron, Bradley},
	year = {1988},
	pages = {414--425}
}

@article{huang_customer_2012,
	title = {Customer churn prediction in telecommunications},
	volume = {39},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417411011353},
	doi = {10.1016/j.eswa.2011.08.024},
	abstract = {This paper presents a new set of features for land-line customer churn prediction, including 2 six-month Henley segmentation, precise 4-month call details, line information, bill and payment information, account information, demographic profiles, service orders, complain information, etc. Then the seven prediction techniques (Logistic Regressions, Linear Classifications, Naive Bayes, Decision Trees, Multilayer Perceptron Neural Networks, Support Vector Machines and the Evolutionary Data Mining Algorithm) are applied in customer churn as predictors, based on the new features. Finally, the comparative experiments were carried out to evaluate the new feature set and the seven modelling techniques for customer churn prediction. The experimental results show that the new features with the six modelling techniques are more effective than the existing ones for customer churn prediction in the telecommunication service field.},
	number = {1},
	urldate = {2018-09-13TZ},
	journal = {Expert Systems with Applications},
	author = {Huang, Bingquan and Kechadi, Mohand Tahar and Buckley, Brian},
	month = jan,
	year = {2012},
	keywords = {Churn prediction, Decision Trees, Evolutionary Data Mining Algorithms, Imbalanced datasets, Linear Classifications, Logistic Regressions, Multilayer Perceptron Neural Networks, Naive Bayes, ROC and AUC techniques, Support Vector Machines},
	pages = {1414--1425}
}

@article{hadden_computer_2007,
	title = {Computer assisted customer churn management: {State}-of-the-art and future trends},
	volume = {34},
	issn = {0305-0548},
	shorttitle = {Computer assisted customer churn management},
	url = {http://www.sciencedirect.com/science/article/pii/S0305054805003503},
	doi = {10.1016/j.cor.2005.11.007},
	abstract = {A business incurs much higher charges when attempting to win new customers than to retain existing ones. As a result, much research has been invested into new ways of identifying those customers who have a high risk of churning. However, customer retention efforts have also been costing organisations large amounts of resource. In response to these issues, the next generation of churn management should focus on accuracy. A variety of churn management techniques have been developed as a response to the above requirements. The focus of this paper is to review some of the most popular technologies that have been identified in the literature for the development of a customer churn management platform. The advantages and disadvantages of the identified technologies are discussed, and a discussion on the future research directions is offered.},
	number = {10},
	urldate = {2018-09-13TZ},
	journal = {Computers \& Operations Research},
	author = {Hadden, John and Tiwari, Ashutosh and Roy, Rajkumar and Ruta, Dymitr},
	month = oct,
	year = {2007},
	keywords = {Churn prediction, Customer churn management, Soft computing},
	pages = {2902--2917}
}

@inproceedings{morik_analysing_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Analysing {Customer} {Churn} in {Insurance} {Data} – {A} {Case} {Study}},
	isbn = {978-3-540-30116-5},
	abstract = {Designing a new application of knowledge discovery is a very tedious task. The success is determined to a great extent by an adequate example representation. The transformation of given data to the example representation is a matter of feature generation and selection. The search for an appropriate approach is difficult. In particular, if time data are involved, there exist a large variety of how to handle them. Reports on successful cases can provide case designers with a guideline for the design of new, similar cases. In this paper we present a complete knowledge discovery process applied to insurance data. We use the TF/IDF representation from information retrieval for compiling time-related features of the data set. Experimental reasults show that these new features lead to superior results in terms of accuracy, precision and recall. A heuristic is given which calculates how much the feature space is enlarged or shrinked by the transformation to TF/IDF.},
	language = {en},
	booktitle = {Knowledge {Discovery} in {Databases}: {PKDD} 2004},
	publisher = {Springer Berlin Heidelberg},
	author = {Morik, Katharina and Köpcke, Hanna},
	editor = {Boulicaut, Jean-François and Esposito, Floriana and Giannotti, Fosca and Pedreschi, Dino},
	year = {2004},
	keywords = {customer relationship management, insurance data analysis, preprocessing for KDD, time-stamped data},
	pages = {325--336}
}

@misc{flaounas_data_2016,
	title = {Data {Science} tricks},
	url = {https://machinelearnings.co/data-science-tricks-simple-anomaly-detection-for-metrics-with-a-weekly-pattern-2e236970d77},
	abstract = {Simple anomaly detection for metrics with a weekly pattern},
	urldate = {2018-09-13TZ},
	journal = {Machine Learnings},
	author = {Flaounas, Ilias},
	month = jan,
	year = {2016}
}

@inproceedings{khan_behavioral_2015,
	address = {New York City, NY, USA},
	title = {Behavioral {Modeling} for {Churn} {Prediction}: {Early} {Indicators} and {Accurate} {Predictors} of {Custom} {Defection} and {Loyalty}},
	isbn = {978-1-4673-7278-7},
	shorttitle = {Behavioral {Modeling} for {Churn} {Prediction}},
	url = {http://ieeexplore.ieee.org/document/7207291/},
	doi = {10.1109/BigDataCongress.2015.107},
	abstract = {Churn prediction, or the task of identifying customers themselves are complex, the Churn Scores they produce are who are likely to discontinue use of a service, is an important and lucrative concern of firms in many different industries. As these firms collect an increasing amount of large-scale, heterogeneous data on the characteristics and behaviors of customers, new methods become possible for predicting churn. In this paper, we present a unified analytic framework for detecting the early warning signs of churn, and assigning a “Churn Score” to each customer that indicates the likelihood that the particular individual will churn within a predefined amount of time. This highly accurate.},
	language = {en},
	urldate = {2018-09-13TZ},
	booktitle = {2015 {IEEE} {International} {Congress} on {Big} {Data}},
	publisher = {IEEE},
	author = {Khan, Muhammad Raza and Manoj, Joshua and Singh, Anikate and Blumenstock, Joshua},
	month = jun,
	year = {2015},
	pages = {677--680}
}

@phdthesis{pietracaprina_machine_2016,
	title = {Machine learning techniques for customer churn prediction in banking environments},
	url = {http://tesi.cab.unipd.it/53212/1/Valentino_Avon_-_1104319.pdf},
	language = {en},
	school = {Universit`a degli Studi di Padova},
	author = {Pietracaprina, Andrea and Pucci, Geppino},
	year = {2016}
}

@phdthesis{martins_predicting_2017,
	address = {Stockholm, Sweden},
	title = {Predicting user churn on streaming services using recurrent neural networks},
	abstract = {Providers of online services have witnessed a rapid growth of their user base in the last few years. The phenomenon has attracted an increasing number of competitors determined on obtaining their own share of the market. In this context, the cost of attracting new customers has increased signiﬁcantly, raising the importance of retaining existing clients. Therefore, it has become progressively more important for the companies to improve user experience and ensure they keep a larger share of their users active in consuming their product. Companies are thus compelled to build tools that can identify what prompts customers to stay and also identify the users intent on abandoning the service. The focus of this thesis is to address the problem of predicting user abandonment, also known as churn, and also detecting motives for user retention on data provided by an online streaming service.},
	language = {en},
	school = {KTH Royal Institute of Technology},
	author = {Martins, Helder},
	year = {2017}
}

@techreport{reichheld_prescription_nodate,
	title = {Prescription for {Cutting} {Costs}},
	url = {http://www2.bain.com/Images/BB_Prescription_cutting_costs.pdf},
	language = {en},
	institution = {Bain \& Company},
	author = {Reichheld, Fred},
	pages = {3}
}

@misc{gallo_value_2014,
	title = {The {Value} of {Keeping} the {Right} {Customers}},
	url = {https://hbr.org/2014/10/the-value-of-keeping-the-right-customers},
	abstract = {A refresher on customer churn rate.},
	urldate = {2018-09-12TZ},
	journal = {Harvard Business Review},
	author = {Gallo, Amy},
	month = oct,
	year = {2014}
}

@misc{dalinina_building_nodate,
	title = {Building {Customer} {Churn} {Models} for {Business}},
	url = {https://www.datascience.com/blog/what-is-a-churn-analysis-and-why-is-it-valuable-for-business},
	abstract = {Churn analysis is vital to creating a data-driven customer retention strategy. This intro to churn modeling for business explains how to deploy a churn model.},
	language = {en-us},
	urldate = {2018-09-09TZ},
	author = {Dalinina, Ruslana}
}

@article{neslin_defection_2006,
	title = {Defection {Detection}: {Measuring} and {Understanding} the {Predictive} {Accuracy} of {Customer} {Churn} {Models}},
	volume = {43},
	issn = {0022-2437},
	shorttitle = {Defection {Detection}},
	url = {http://journals.ama.org/doi/abs/10.1509/jmkr.43.2.204},
	doi = {10.1509/jmkr.43.2.204},
	abstract = {This article provides a descriptive analysis of how methodological factors contribute to the accuracy of customer churn predictive models. The study is based on a tournament in which both academics and practitioners downloaded data from a publicly available Web site, estimated a model, and made predictions on two validation databases. The results suggest several important findings. First, methods do matter. The differences observed in predictive accuracy across submissions could change the profitability of a churn management campaign by hundreds of thousands of dollars. Second, models have staying power. They suffer very little decrease in performance if they are used to predict churn for a database compiled three months after the calibration data. Third, researchers use a variety of modeling “approaches,” characterized by variables such as estimation technique, variable selection procedure, number of variables included, and time allocated to steps in the model-building process. The authors find important differences in performance among these approaches and discuss implications for both researchers and practitioners.},
	number = {2},
	urldate = {2018-09-09TZ},
	journal = {Journal of Marketing Research},
	author = {Neslin, Scott A and Gupta, Sunil and Kamakura, Wagner and Lu, Junxiang and Mason, Charlotte H},
	month = may,
	year = {2006},
	keywords = {reading},
	pages = {204--211}
}

@article{neslin_defection_2006-1,
	title = {Defection {Detection}: {Measuring} and {Understanding} the {Predictive} {Accuracy} of {Customer} {Churn} {Models}},
	volume = {43},
	issn = {0022-2437},
	shorttitle = {Defection {Detection}},
	url = {http://www.jstor.org/stable/30163387},
	abstract = {This article provides a descriptive analysis of how methodological factors contribute to the accuracy of customer churn predictive models. The study is based on a tournament in which both academics and practitioners downloaded data from a publicly available Web site, estimated a model, and made predictions on two validation databases. The results suggest several important findings. First, methods do matter. The differences observed in predictive accuracy across submissions could change the profitability of a churn management campaign by hundreds of thousands of dollars. Second, models have staying power. They suffer very little decrease in performance if they are used to predict churn for a database compiled three months after the calibration data. Third, researchers use a variety of modeling "approaches," characterized by variables such as estimation technique, variable selection procedure, number of variables included, and time allocated to steps in the model-building process. The authors find important differences in performance among these approaches and discuss implications for both researchers and practitioners.},
	number = {2},
	urldate = {2018-09-09TZ},
	journal = {Journal of Marketing Research},
	author = {Neslin, Scott A. and Gupta, Sunil and Kamakura, Wagner and Lu, Junxiang and Mason, Charlotte H.},
	year = {2006},
	pages = {204--211}
}

@article{vafeiadis_comparison_2015,
	title = {A comparison of machine learning techniques for customer churn prediction},
	volume = {55},
	issn = {1569-190X},
	url = {http://www.sciencedirect.com/science/article/pii/S1569190X15000386},
	doi = {10.1016/j.simpat.2015.03.003},
	abstract = {We present a comparative study on the most popular machine learning methods applied to the challenging problem of customer churning prediction in the telecommunications industry. In the first phase of our experiments, all models were applied and evaluated using cross-validation on a popular, public domain dataset. In the second phase, the performance improvement offered by boosting was studied. In order to determine the most efficient parameter combinations we performed a series of Monte Carlo simulations for each method and for a wide range of parameters. Our results demonstrate clear superiority of the boosted versions of the models against the plain (non-boosted) versions. The best overall classifier was the SVM-POLY using AdaBoost with accuracy of almost 97\% and F-measure over 84\%.},
	urldate = {2018-09-09TZ},
	journal = {Simulation Modelling Practice and Theory},
	author = {Vafeiadis, T. and Diamantaras, K. I. and Sarigiannidis, G. and Chatzisavvas, K. Ch.},
	month = jun,
	year = {2015},
	keywords = {read},
	pages = {1--9}
}

@article{ngai_application_2009,
	title = {Application of data mining techniques in customer relationship management: {A} literature review and classification},
	volume = {36},
	issn = {0957-4174},
	shorttitle = {Application of data mining techniques in customer relationship management},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417408001243},
	doi = {10.1016/j.eswa.2008.02.021},
	abstract = {Despite the importance of data mining techniques to customer relationship management (CRM), there is a lack of a comprehensive literature review and a classification scheme for it. This is the first identifiable academic literature review of the application of data mining techniques to CRM. It provides an academic database of literature between the period of 2000–2006 covering 24 journals and proposes a classification scheme to classify the articles. Nine hundred articles were identified and reviewed for their direct relevance to applying data mining techniques to CRM. Eighty-seven articles were subsequently selected, reviewed and classified. Each of the 87 selected papers was categorized on four CRM dimensions (Customer Identification, Customer Attraction, Customer Retention and Customer Development) and seven data mining functions (Association, Classification, Clustering, Forecasting, Regression, Sequence Discovery and Visualization). Papers were further classified into nine sub-categories of CRM elements under different data mining techniques based on the major focus of each paper. The review and classification process was independently verified. Findings of this paper indicate that the research area of customer retention received most research attention. Of these, most are related to one-to-one marketing and loyalty programs respectively. On the other hand, classification and association models are the two commonly used models for data mining in CRM. Our analysis provides a roadmap to guide future research and facilitate knowledge accumulation and creation concerning the application of data mining techniques in CRM.},
	number = {2, Part 2},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Ngai, E. W. T. and Xiu, Li and Chau, D. C. K.},
	month = mar,
	year = {2009},
	keywords = {read},
	pages = {2592--2602}
}

@article{coussement_improved_2010,
	title = {Improved marketing decision making in a customer churn prediction context using generalized additive models},
	volume = {37},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417409007325},
	doi = {10.1016/j.eswa.2009.07.029},
	abstract = {Nowadays, companies are investing in a well-considered CRM strategy. One of the cornerstones in CRM is customer churn prediction, where one tries to predict whether or not a customer will leave the company. This study focuses on how to better support marketing decision makers in identifying risky customers by using Generalized Additive Models (GAM). Compared to Logistic Regression, GAM relaxes the linearity constraint which allows for complex non-linear fits to the data. The contributions to the literature are three-fold: (i) it is shown that GAM is able to improve marketing decision making by better identifying risky customers; (ii) it is shown that GAM increases the interpretability of the churn model by visualizing the non-linear relationships with customer churn identifying a quasi-exponential, a U, an inverted U or a complex trend and (iii) marketing managers are able to significantly increase business value by applying GAM in this churn prediction context.},
	number = {3},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Coussement, Kristof and Benoit, Dries F. and Van den Poel, Dirk},
	month = mar,
	year = {2010},
	pages = {2132--2143}
}

@article{burez_handling_2009,
	title = {Handling class imbalance in customer churn prediction},
	volume = {36},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417408002121},
	doi = {10.1016/j.eswa.2008.05.027},
	abstract = {Customer churn is often a rare event in service industries, but of great interest and great value. Until recently, however, class imbalance has not received much attention in the context of data mining [Weiss, G. M. (2004). Mining with rarity: A unifying framework. SIGKDD Explorations, 6(1), 7–19]. In this study, we investigate how we can better handle class imbalance in churn prediction. Using more appropriate evaluation metrics (AUC, lift), we investigated the increase in performance of sampling (both random and advanced under-sampling) and two specific modelling techniques (gradient boosting and weighted random forests) compared to some standard modelling techniques. AUC and lift prove to be good evaluation metrics. AUC does not depend on a threshold, and is therefore a better overall evaluation metric compared to accuracy. Lift is very much related to accuracy, but has the advantage of being well used in marketing practice [Ling, C., \& Li, C. (1998). Data mining for direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York, NY: AAAI Press]. Results show that under-sampling can lead to improved prediction accuracy, especially when evaluated with AUC. Unlike Ling and Li [Ling, C., \& Li, C. (1998). Data mining for direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York, NY: AAAI Press], we find that there is no need to under-sample so that there are as many churners in your training set as non churners. Results show no increase in predictive performance when using the advanced sampling technique CUBE in this study. This is in line with findings of Japkowicz [Japkowicz, N. (2000). The class imbalance problem: significance and strategies. In Proceedings of the 2000 international conference on artificial intelligence (IC-AI’2000): Special track on inductive learning, Las Vegas, Nevada], who noted that using sophisticated sampling techniques did not give any clear advantage. Weighted random forests, as a cost-sensitive learner, performs significantly better compared to random forests, and is therefore advised. It should, however always be compared to logistic regression. Boosting is a very robust classifier, but never outperforms any other technique.},
	number = {3, Part 1},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Burez, J. and Van den Poel, D.},
	month = apr,
	year = {2009},
	pages = {4626--4636}
}

@article{xie_customer_2009-1,
	title = {Customer churn prediction using improved balanced random forests},
	volume = {36},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417408004326},
	doi = {10.1016/j.eswa.2008.06.121},
	abstract = {Churn prediction is becoming a major focus of banks in China who wish to retain customers by satisfying their needs under resource constraints. In churn prediction, an important yet challenging problem is the imbalance in the data distribution. In this paper, we propose a novel learning method, called improved balanced random forests (IBRF), and demonstrate its application to churn prediction. We investigate the effectiveness of the standard random forests approach in predicting customer churn, while also integrating sampling techniques and cost-sensitive learning into the approach to achieve a better performance than most existing algorithms. The nature of IBRF is that the best features are iteratively learned by altering the class distribution and by putting higher penalties on misclassification of the minority class. We apply the method to a real bank customer churn data set. It is found to improve prediction accuracy significantly compared with other algorithms, such as artificial neural networks, decision trees, and class-weighted core support vector machines (CWC-SVM). Moreover, IBRF also produces better prediction results than other random forests algorithms such as balanced random forests and weighted random forests.},
	number = {3, Part 1},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Xie, Yaya and Li, Xiu and Ngai, E. W. T. and Ying, Weiyun},
	month = apr,
	year = {2009},
	pages = {5445--5449}
}

@article{tsai_customer_2009,
	title = {Customer churn prediction by hybrid neural networks},
	volume = {36},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417409004758},
	doi = {10.1016/j.eswa.2009.05.032},
	abstract = {As churn management is a major task for companies to retain valuable customers, the ability to predict customer churn is necessary. In literature, neural networks have shown their applicability to churn prediction. On the other hand, hybrid data mining techniques by combining two or more techniques have been proved to provide better performances than many single techniques over a number of different domain problems. This paper considers two hybrid models by combining two different neural network techniques for churn prediction, which are back-propagation artificial neural networks (ANN) and self-organizing maps (SOM). The hybrid models are ANN combined with ANN (ANN+ANN) and SOM combined with ANN (SOM+ANN). In particular, the first technique of the two hybrid models performs the data reduction task by filtering out unrepresentative training data. Then, the outputs as representative data are used to create the prediction model based on the second technique. To evaluate the performance of these models, three different kinds of testing sets are considered. They are the general testing set and two fuzzy testing sets based on the filtered out data by the first technique of the two hybrid models, i.e. ANN and SOM, respectively. The experimental results show that the two hybrid models outperform the single neural network baseline model in terms of prediction accuracy and Types I and II errors over the three kinds of testing sets. In addition, the ANN+ANN hybrid model significantly performs better than the SOM+ANN hybrid model and the ANN baseline model.},
	number = {10},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Tsai, Chih-Fong and Lu, Yu-Hsin},
	month = dec,
	year = {2009},
	pages = {12547--12553}
}

@article{verbeke_building_2011,
	title = {Building comprehensible customer churn prediction models with advanced rule induction techniques},
	volume = {38},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417410008067},
	doi = {10.1016/j.eswa.2010.08.023},
	abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study.},
	number = {3},
	urldate = {2018-09-09TZ},
	journal = {Expert Systems with Applications},
	author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
	month = mar,
	year = {2011},
	pages = {2354--2364}
}

@article{lu_customer_2014,
	title = {A {Customer} {Churn} {Prediction} {Model} in {Telecom} {Industry} {Using} {Boosting}},
	volume = {10},
	issn = {1551-3203},
	doi = {10.1109/TII.2012.2224355},
	abstract = {With the rapid growth of digital systems and associated information technologies, there is an emerging trend in the global economy to build digital customer relationship management (CRM) systems. This trend is more obvious in the telecommunications industry, where companies become increasingly digitalized. Customer churn prediction is a main feature of in modern telecomcommunication CRM systems. This research conducts a real-world study on customer churn prediction and proposes the use of boosting to enhance a customer churn prediction model. Unlike most research that uses boosting as a method to boost the accuracy of a given basis learner, this paper tries to separate customers into two clusters based on the weight assigned by the boosting algorithm. As a result, a higher risk customer cluster has been identified. Logistic regression is used in this research as a basis learner, and a churn prediction model is built on each cluster, respectively. The result is compared with a single logistic regression model. Experimental evaluation reveals that boosting also provides a good separation of churn data; thus, boosting is suggested for churn prediction analysis.},
	number = {2},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Lu, N. and Lin, H. and Lu, J. and Zhang, G.},
	month = may,
	year = {2014},
	pages = {1659--1665}
}

@article{delen_comparative_2010,
	title = {A comparative analysis of machine learning techniques for student retention management},
	volume = {49},
	issn = {0167-9236},
	url = {http://www.sciencedirect.com/science/article/pii/S0167923610001041},
	doi = {10.1016/j.dss.2010.06.003},
	abstract = {Student retention is an essential part of many enrollment management systems. It affects university rankings, school reputation, and financial wellbeing. Student retention has become one of the most important priorities for decision makers in higher education institutions. Improving student retention starts with a thorough understanding of the reasons behind the attrition. Such an understanding is the basis for accurately predicting at-risk students and appropriately intervening to retain them. In this study, using five years of institutional data along with several data mining techniques (both individuals as well as ensembles), we developed analytical models to predict and to explain the reasons behind freshmen student attrition. The comparative analyses results showed that the ensembles performed better than individual models, while the balanced dataset produced better prediction results than the unbalanced dataset. The sensitivity analysis of the models revealed that the educational and financial variables are among the most important predictors of the phenomenon.},
	number = {4},
	urldate = {2018-09-09TZ},
	journal = {Decision Support Systems},
	author = {Delen, Dursun},
	month = nov,
	year = {2010},
	pages = {498--506}
}

@article{lemmens_bagging_2006-1,
	title = {Bagging and {Boosting} {Classification} {Trees} to {Predict} {Churn}},
	volume = {43},
	issn = {0022-2437},
	url = {http://journals.ama.org/doi/abs/10.1509/jmkr.43.2.276},
	doi = {10.1509/jmkr.43.2.276},
	abstract = {In this article, the authors explore the bagging and boosting classification techniques. They apply the two techniques to a customer database of an anonymous U.S. wireless telecommunications company, and both significantly improve accuracy in predicting churn. This higher predictive performance could ultimately lead to incremental profits for companies that use these methods. Furthermore, the results recommend the use of a balanced sampling scheme when predicting a rare event from large data sets, but this requires an appropriate bias correction.},
	number = {2},
	urldate = {2018-09-09TZ},
	journal = {Journal of Marketing Research},
	author = {Lemmens, Aurélie and Croux, Christophe},
	month = may,
	year = {2006},
	pages = {276--286}
}

@article{han_flow_2018,
	title = {Flow {Partitioning} in {Rectangular} {Open} {Channel} {Flow}},
	url = {https://www.hindawi.com/journals/mpe/2018/6491501/},
	abstract = {Hydraulic engineers often divide a flow region into subregions to simplify calculations. However, the implementation of flow divisibility remains an open issue and has not yet been implemented as a fully developed mathematical tool for modeling complex channel flows independently of experimental verification. This paper addresses whether a three-dimensional flow is physically divisible, meaning that division lines with zero Reynolds shear stress exist. An intensive laboratory investigation was conducted to carefully measure the time-averaged velocity in a rectangular open channel flow using a laser Doppler anemometry system. Two innovative methods are employed to determine the locations of division lines based on the measured velocity profile. The results clearly reveal that lines with zero total shear stress are discernible, indicating that the flow is physically divisible. Moreover, the experimental data were employed to test previously proposed methods of calculating division lines, and the results show that Yang and Lim’s method is the most reasonable predictor.},
	language = {en},
	urldate = {2018-08-31TZ},
	journal = {Mathematical Problems in Engineering},
	author = {Han, Yu and Yang, Shu-Qing and Sivakumar, Muttucumaru and Qiu, Liu-Chao and Chen, Jian},
	year = {2018},
	doi = {10.1155/2018/6491501}
}

@book{hastie_elements_2009,
	address = {New York, NETHERLANDS},
	title = {Elements of {Statistical} {Learning}: {Data} {Mining}, {Inference}, and {Prediction}},
	isbn = {978-0-387-84858-7},
	shorttitle = {Elements of {Statistical} {Learning}},
	url = {http://ebookcentral.proquest.com/lib/usyd/detail.action?docID=437866},
	abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting - the first comprehensive treatment of this topic in any book.},
	urldate = {2018-08-31TZ},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	keywords = {Data mining., Electronic books. -- local, Supervised learning (Machine learning)}
}

@misc{jain_fundamentals_2016,
	title = {Fundamentals of {Deep} {Learning} - {Starting} with {Artificial} {Neural} {Network}},
	url = {https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/},
	abstract = {This article explains artificial neural network fundamental of deep learning for beginners. it also explains forward \& backward propogation},
	urldate = {2018-08-23TZ},
	journal = {Analytics Vidhya},
	author = {Jain, Aarshay},
	month = mar,
	year = {2016}
}
@article{despotovic_artificial_2012,
	title = {Artificial {Intelligence} {Techniques} for {Modelling} of {Temperature} in the {Metal} {Cutting} {Process}},
	url = {https://www.intechopen.com/books/metallurgy-advances-in-materials-and-processes/artificial-intelligence-techniques-for-modelling-of-temperature-in-the-metal-cutting-process},
	doi = {10.5772/47850},
	language = {en},
	urldate = {2018-08-15TZ},
	journal = {Metallurgy - Advances in Materials and Processes},
	author = {Despotovic, Dejan Tanikić {and} Vladimir},
	year = {2012}
}

@misc{chollet_keras_2015,
	title = {Keras},
	url = {https://keras.io},
	author = {Chollet, François and {others}},
	year = {2015}
}

@article{banerjee_anisotropy_nodate,
	title = {Anisotropy {Properties} of {Turbulence}},
	abstract = {In the literature, anisotropy-invariant maps are being proposed to represent a domain within which all realizable Reynolds stress invariants must lie. It is shown that the representation proposed by Lumley and Newman has disadvantages owing to the fact that the anisotropy invariants (II, III) are nonlinear functions of stresses. In the current work, it is proposed to use an equivalent linear representation of the anisotropy invariants in terms of eigenvalues. A novel barycentric map, based on the convex combination of scalar metrics dependent on eigenvalues, is proposed to provide a non-distorted visual representation of anisotropy in turbulent quantities. This barycentric map provides the possibility of viewing the Reynolds stress and any anisotropic stress tensor. Additionally the barycentric map provides the possibility of quantifying the weighting for any point inside it in terms of the limiting states (one component, two component, three component). The mathematical basis for the barycentric map is derived using the spectral decomposition theorem for second-order tensors. In this way, an analytical proof is provided that All turbulence lies along the boundaries or inside the barycentric map. It is proved that the barycentric map and the anisotropy-invariant maps are one to one uniquely interdependent and as a result satisfy the requirement of realizability.},
	language = {en},
	author = {BANERJEE, SANKHA and ERTUNC, OEZGUER and DURST, FRANZ},
	pages = {32}
}

@book{hamalainen_implementing_2001,
	address = {Espoo},
	title = {Implementing an explicit algebraic {Reynolds} stress model into the three-dimensional {FINFLO} flow solver},
	isbn = {978-951-22-5605-1},
	language = {en},
	publisher = {Helsinki University of Technology},
	author = {Hämäläinen, Ville},
	year = {2001},
	note = {OCLC: 58378993}
}

@incollection{launder_numerical_2002,
	address = {Cambridge},
	title = {Numerical {Aspects} of {Applying} {Second}-{Moment} {Closure} to {Complex} {Flows}},
	url = {https://www.cambridge.org/core/books/closure-strategies-for-turbulent-and-transitional-flows/numerical-aspects-of-applying-secondmoment-closure-to-complex-flows/9BD3D9D1E32AEC0600A8F1C0BAD25B47},
	abstract = {AbstractThe incorporation of Reynolds-stress closure into general finite-volume schemes, in which the discretization of convection is minimally diffusive, presents a number of algorithmic problems not encountered in schemes containing eddyviscosity models. The main problem is low numerical stability, arising from the general stiffness of the turbulence-model equations, the absence of the numerically stabilizing second-order derivatives associated with the eddy viscosity, and – in the case of a fully collocated storage of all variables – a decoupling between stresses and strains. The chapter presents a number of algorithmic measures designed to enhance the stability and rate of convergence of incompressible as well as compressible-flow solvers, the latter based on modern Riemann schemes. It also discusses aspects of the incorporation of wall boundary conditions for the Cartesian stress components in conjunction with wall laws which are formulated in wall-oriented coordinates. Two examples are included for complex 3D flows, one incompressible and the other compressible (transonic).IntroductionDespite decades of research into the formulation, improvement and validation of second-moment closure models, the large majority of RANS codes applied in practice continue to use linear eddy-viscosity models to represent the effects of turbulence on the mean flow. The appeal of such models is rooted in their simplicity, favourable numerical characteristics and surprisingly good predictive capabilities over a fair range of conditions, especially if the basic model forms are augmented by ad hoc corrections to counteract a number of fundamental weaknesses.While there is no argument about the fundamental superiority of second-moment closure and the mechanisms responsible for it, there is no consensus on the degree to which this fundamental strength translates itself into practical predictive advantages and broad generality.},
	booktitle = {Closure {Strategies} for {Turbulent} and {Transitional} {Flows}},
	publisher = {Cambridge University Press},
	author = {Leschziner, M.A. and Lien, F.-S.},
	editor = {Launder, B. E. and Sandham, N. D.},
	year = {2002},
	doi = {10.1017/CBO9780511755385.007},
	pages = {153--187}
}

@article{mansour_reynolds-stress_1988,
	title = {Reynolds-stress and dissipation-rate budgets in a turbulent channel flow},
	volume = {194},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynoldsstress-and-dissipationrate-budgets-in-a-turbulent-channel-flow/09CF7C2D0F670946BDBFB9A0E01253B2},
	doi = {10.1017/S0022112088002885},
	abstract = {The Budgets For The Reynolds Stresses And For The Dissipation Rate Of The Turbulence Kinetic Energy Are Computed Using Direct Simulation Data Of A Turbulent Channel Flow. The Budget Data Reveal That All The Terms In The Budget Become Important Close To The Wall. For Inhomogeneous Pressure Boundary Conditions, The Pressure—Strain Term Is Split Into A Return Term, A Rapid Term And A Stokes Term. The Stokes Term Is Important Close To The Wall. The Rapid And Return Terms Play Different Roles Depending On The Component Of The Term. A Split Of The Velocity Pressure-Gradient Term Into A Redistributive Term And A Diffusion Term Is Proposed, Which Should Be Simpler To Model. The Budget Data Are Used To Test Existing Closure Models For The Pressure—Strain Term, The Dissipation Rate, And The Transport Rate. In General, Further Work Is Needed To Improve the models.},
	language = {en},
	urldate = {2018-06-07TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Mansour, N. N. and Kim, J. and Moin, P.},
	month = sep,
	year = {1988},
	pages = {15--44}
}

@article{germano_dynamic_1991,
	title = {A dynamic subgrid‐scale eddy viscosity model},
	volume = {3},
	issn = {0899-8213},
	url = {https://aip.scitation.org/doi/abs/10.1063/1.857955},
	doi = {10.1063/1.857955},
	number = {7},
	urldate = {2018-06-06TZ},
	journal = {Physics of Fluids A: Fluid Dynamics},
	author = {Germano, Massimo and Piomelli, Ugo and Moin, Parviz and Cabot, William H.},
	month = jul,
	year = {1991},
	pages = {1760--1765}
}

@article{gray_validity_1976,
	title = {The validity of the boussinesq approximation for liquids and gases},
	volume = {19},
	issn = {0017-9310},
	url = {http://www.sciencedirect.com/science/article/pii/001793107690168X},
	doi = {10.1016/0017-9310(76)90168-X},
	abstract = {A new method for obtaining approximate equations for natural convection flows is presented. The systematic application of this method leads to explicit conditions for the neglect of various terms. It is shown that this method allows the specification of the conditions under which the traditional Boussinesq approximation applies to a given Newtonian liquid or gas. The method is applied to room temperature water and air.
Résumé
On présente une nouvelle méthode d'obtention des équations approchées des écoulements en convection naturelle. L'application systématique de cette méthode conduit à des conditions précises sur les divers termes à négliger. On montre que cette méthode permet de spécifier les conditions sous lesquelles s'applique l'approximation habituelle de Boussinesq dans un liquide ou un gaz Newtonien. La mðhode est appliquée à l'eau et à l'air à température ambiante.
Zusammenfassung
Um Näherungsgleichungen für freie Konvektionsströmungen zu erhalten, wird eine neue Methode dargestellt. Die systematische Anwendung dieser Methode führt zu expliziten Bedingungen für die Vernachlässigung verschiedener Terme. Es wird gezeigt, wie nach dieser Methode die Bedingungen dargestellt werden können, für die die traditionelle Boussinesq-Näherung auf eine gegebene Newtonsche Flüssigkeit oder ein Gas angewendet werden kann. Die Methode wird für Wasser und Luft bei Raumtemperatur angewandt.
Реферат
Пpивoдитcя нoвый мeтoд вывoдa пpиближeнныч ypaвнeний для зaдaч ecтecтвeннoй кoнвeкции. Иcпoльзoвaниe дaннoгo мeтoдa пoзвoляeт в явнoм видe выяcнить ycлoвия, пpи кoтopыч мoжнo пpeнeбpeчь нeкoтopыми члeнaми в ypaвнeнияч. Пoкaзaнo, чтo этoт мeтoд oпpeдeляeт ycлoвия, пpи кoтopыч тpaдициoннoe пpиближeниe Бycceнecкa мoжeт быть иcпoльзoвaнo для cлyчaя ньютoнoвcкoй жидкocти или гaзa. Meтoд иcпoльзyeтcя для вoды и вoздyчa пpи кoмнaтнoй тeмпepaтype.},
	number = {5},
	urldate = {2018-06-06TZ},
	journal = {International Journal of Heat and Mass Transfer},
	author = {Gray, Donald D. and Giorgini, Aldo},
	month = may,
	year = {1976},
	pages = {545--551}
}

@misc{kirkpatrick_puffin_2013,
	title = {The {PUFFIN} {Manual}: {An} {Engineering} and {Environmental} {Fluid} {Dynamics} {Simulation} {Model}},
	author = {Kirkpatrick, Michael P.},
	year = {2013}
}

@techreport{slotnick_cfd_2014,
	title = {{CFD} {Vision} 2030 {Study}: {A} {Path} to {Revolutionary} {Computational} {Aerosciences}},
	shorttitle = {{CFD} {Vision} 2030 {Study}},
	url = {https://ntrs.nasa.gov/search.jsp?R=20140003093},
	abstract = {This report documents the results of a study to address the long range, strategic planning required by NASA's Revolutionary Computational Aerosciences  program in the area of computational fluid dynamics , including future software and hardware requirements for High Performance Computing . Specifically, the "Vision 2030" CFD study is to provide a knowledge-based forecast of the future computational capabilities required for turbulent, transitional, and reacting flow simulations across a broad Mach number regime, and to lay the foundation for the development of a future framework and/or environment where physics-based, accurate predictions of complex turbulent flows, including flow separation, can be accomplished routinely and efficiently in cooperation with other physics-based simulations to enable multi-physics analysis and design. Specific technical requirements from the aerospace industrial and scientific communities were obtained to determine critical capability gaps, anticipated technical challenges, and impediments to achieving the target CFD capability in 2030. A preliminary development plan and roadmap were created to help focus investments in technology development to help achieve the CFD vision in 2030.},
	urldate = {2018-06-04TZ},
	author = {Slotnick, JeffreyKhodadoust},
	month = mar,
	year = {2014},
	keywords = {aerospace sciences, aerothermodynamics, computational fluid dynamics, computer programs, computer systems performance, forecasting, knowledge based systems, separated flow, simulation, targets, transition flow, turbulent flow}
}

@book{rocha_preventing_1999,
	title = {Preventing {Premature} {Convergence} to {Local} {Optima} in {Genetic} {Algorithms} via {Random} {Offspring} {Generation}},
	abstract = {Abstract. The Genetic Algorithms (GAs) paradigm is being used increasingly in search and optimization problems. The method has shown to be efficient and robust in a considerable number of scientific domains, where the complexity and cardinality of the problems considered elected themselves as key factors to be taken into account. However, there are still some insufficiencies; indeed, one of the major problems usually associated with the use of GAs is the premature convergence to solutions coding local optima of the objective function. The problem is tightly related with the loss of genetic diversity of the GA’s population, being the cause of a decrease on the quality of the solutions found. Out of question, this fact has lead to the development of different techniques aiming to solve, or at least to minimize the problem; traditional methods usually work to maintain a certain degree of genetic diversity on the target populations, without affecting the convergence process of the GA. In one’s work, some of these techniques are compared and an innovative one, the Random Offspring Generation, is presented and evaluated in its merits. The Traveling Salesman Problem is used as a benchmark.},
	author = {Rocha, Miguel and Neves, José},
	year = {1999}
}

@article{koza_genetic_1994,
	title = {Genetic programming as a means for programming computers by natural selection},
	volume = {4},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/article/10.1007/BF00175355},
	doi = {10.1007/BF00175355},
	abstract = {Many seemingly different problems in machine learning, artificial intelligence, and symbolic processing can be viewed as requiring the discovery of a computer program that produces some desired output for particular inputs. When viewed in this way, the process of solving these problems becomes equivalent to searching a space of possible computer programs for a highly fit individual computer program. The recently developed genetic programming paradigm described herein provides a way to search the space of possible computer programs for a highly fit individual computer program to solve (or approximately solve) a surprising variety of different problems from different fields. In genetic programming, populations of computer programs are genetically bred using the Darwinian principle of survival of the fittest and using a genetic crossover (sexual recombination) operator appropriate for genetically mating computer programs. Genetic programming is illustrated via an example of machine learning of the Boolean 11-multiplexer function and symbolic regression of the econometric exchange equation from noisy empirical data.Hierarchical automatic function definition enables genetic programming to define potentially useful functions automatically and dynamically during a run, much as a human programmer writing a complex computer program creates subroutines (procedures, functions) to perform groups of steps which must be performed with different instantiations of the dummy variables (formal parameters) in more than one place in the main program. Hierarchical automatic function definition is illustrated via the machine learning of the Boolean 11-parity function.},
	language = {en},
	number = {2},
	urldate = {2018-06-03TZ},
	journal = {Statistics and Computing},
	author = {Koza, John R.},
	month = jun,
	year = {1994},
	pages = {87--112}
}

@article{ling_reynolds_2016,
	title = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
	volume = {807},
	copyright = {© Cambridge University Press 2016. This is a work of the U.S. Government and is not subject to copyright protection in the United States.},
	issn = {00221120},
	url = {https://search.proquest.com/docview/1884540899/abstract/D5BFAC8BEDAA470DPQ/1},
	doi = {http://dx.doi.org.ezproxy1.library.usyd.edu.au/10.1017/jfm.2016.615},
	language = {English},
	urldate = {2017-12-23TZ},
	journal = {Journal of Fluid Mechanics; Cambridge},
	author = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
	month = nov,
	year = {2016},
	keywords = {Neural networks, posterior, priori, reynolds stress directly},
	pages = {155--166}
}

@incollection{weinmann_suitability_2009,
	series = {Fluid {Dynamics} and {Co}-located {Conferences}},
	title = {Suitability of {Explicit} {Algebraic} {Stress} {Models} for {Predicting} {Complex} {Three}-{Dimensional} {Flows}},
	url = {https://doi.org/10.2514/6.2009-3663},
	urldate = {2018-06-01},
	booktitle = {19th {AIAA} {Computational} {Fluid} {Dynamics}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Weinmann, Markus and Sandberg, Richard},
	month = jun,
	year = {2009},
	doi = {10.2514/6.2009-3663}
}

@article{xiao_quantifying_2016,
	title = {Quantifying and reducing model-form uncertainties in {Reynolds}-averaged {Navier}–{Stokes} simulations: {A} data-driven, physics-informed {Bayesian} approach},
	volume = {324},
	issn = {0021-9991},
	shorttitle = {Quantifying and reducing model-form uncertainties in {Reynolds}-averaged {Navier}–{Stokes} simulations},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999116303394},
	doi = {10.1016/j.jcp.2016.07.038},
	abstract = {Despite their well-known limitations, Reynolds-Averaged Navier–Stokes (RANS) models are still the workhorse tools for turbulent flow simulations in today's engineering analysis, design and optimization. While the predictive capability of RANS models depends on many factors, for many practical flows the turbulence models are by far the largest source of uncertainty. As RANS models are used in the design and safety evaluation of many mission-critical systems such as airplanes and nuclear power plants, quantifying their model-form uncertainties has significant implications in enabling risk-informed decision-making. In this work we develop a data-driven, physics-informed Bayesian framework for quantifying model-form uncertainties in RANS simulations. Uncertainties are introduced directly to the Reynolds stresses and are represented with compact parameterization accounting for empirical prior knowledge and physical constraints (e.g., realizability, smoothness, and symmetry). An iterative ensemble Kalman method is used to assimilate the prior knowledge and observation data in a Bayesian framework, and to propagate them to posterior distributions of velocities and other Quantities of Interest (QoIs). We use two representative cases, the flow over periodic hills and the flow in a square duct, to evaluate the performance of the proposed framework. Both cases are challenging for standard RANS turbulence models. Simulation results suggest that, even with very sparse observations, the obtained posterior mean velocities and other QoIs have significantly better agreement with the benchmark data compared to the baseline results. At most locations the posterior distribution adequately captures the true model error within the developed model form uncertainty bounds. The framework is a major improvement over existing black-box, physics-neutral methods for model-form uncertainty quantification, where prior knowledge and details of the models are not exploited. This approach has potential implications in many fields in which the governing equations are well understood but the model uncertainty comes from unresolved physical processes.},
	urldate = {2018-04-09TZ},
	journal = {Journal of Computational Physics},
	author = {Xiao, H. and Wu, J. -L. and Wang, J. -X. and Sun, R. and Roy, C. J.},
	month = nov,
	year = {2016},
	keywords = {bayesian, read this, uncertainty quantification},
	pages = {115--136}
}

@article{milano_neural_2002,
	title = {Neural {Network} {Modeling} for {Near} {Wall} {Turbulent} {Flow}},
	volume = {182},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999102971469},
	doi = {10.1006/jcph.2002.7146},
	abstract = {A neural network methodology is developed in order to reconstruct the near wall field in a turbulent flow by exploiting flow fields provided by direct numerical simulations. The results obtained from the neural network methodology are compared with the results obtained from prediction and reconstruction using proper orthogonal decomposition (POD). Using the property that the POD is equivalent to a specific linear neural network, a nonlinear neural network extension is presented. It is shown that for a relatively small additional computational cost nonlinear neural networks provide us with improved reconstruction and prediction capabilities for the near wall velocity fields. Based on these results advantages and drawbacks of both approaches are discussed with an outlook toward the development of near wall models for turbulence modeling and control.},
	number = {1},
	urldate = {2018-06-02TZ},
	journal = {Journal of Computational Physics},
	author = {Milano, Michele and Koumoutsakos, Petros},
	month = oct,
	year = {2002},
	keywords = {Neural networks},
	pages = {1--26}
}

@article{wang_physics-informed_2017,
	title = {Physics-informed machine learning approach for reconstructing {Reynolds} stress modeling discrepancies based on {DNS} data},
	volume = {2},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.2.034603},
	doi = {10.1103/PhysRevFluids.2.034603},
	abstract = {Turbulence modeling is a critical component in numerical simulations of industrial flows based on Reynolds-averaged Navier-Stokes (RANS) equations. However, after decades of efforts in the turbulence modeling community, universally applicable RANS models with predictive capabilities are still lacking. Large discrepancies in the RANS-modeled Reynolds stresses are the main source that limits the predictive accuracy of RANS models. Identifying these discrepancies is of significance to possibly improve the RANS modeling. In this work, we propose a data-driven, physics-informed machine learning approach for reconstructing discrepancies in RANS modeled Reynolds stresses. The discrepancies are formulated as functions of the mean flow features. By using a modern machine learning technique based on random forests, the discrepancy functions are trained by existing direct numerical simulation (DNS) databases and then used to predict Reynolds stress discrepancies in different flows where data are not available. The proposed method is evaluated by two classes of flows: (1) fully developed turbulent flows in a square duct at various Reynolds numbers and (2) flows with massive separations. In separated flows, two training flow scenarios of increasing difficulties are considered: (1) the flow in the same periodic hills geometry yet at a lower Reynolds number and (2) the flow in a different hill geometry with a similar recirculation zone. Excellent predictive performances were observed in both scenarios, demonstrating the merits of the proposed method.},
	number = {3},
	urldate = {2018-06-02TZ},
	journal = {Physical Review Fluids},
	author = {Wang, Jian-Xun and Wu, Jin-Long and Xiao, Heng},
	month = mar,
	year = {2017},
	keywords = {Random forest, reynolds stress discrepency},
	pages = {034603}
}

@inproceedings{michalski_understanding_1986,
	title = {Understanding {The} {Nature} {Of} {Learning}: {Issues} {And} {Research} {Directions}},
	shorttitle = {Understanding {The} {Nature} {Of} {Learning}},
	abstract = {This chapter presents an overview of goals and directions in machine learning research, and is intended to serve as a conceptual road map to other chapters. It investigates intrinsic aspects of the learning process, classifies current  lines of research, and presents the author's view of the relationship among learning paradigms, strategies and orientations.},
	booktitle = {Machine {Learning}: {An} {Artificial} {Intelligence} {Approach}},
	publisher = {Morgan Kaufmann},
	author = {Michalski, Ryszard S.},
	year = {1986},
	pages = {3--25}
}

@article{piatetsky-shapiro_knowledge_1991,
	title = {Knowledge {Discovery} in {Real} {Databases}: {A} {Report} on the {IJCAI}-89 {Workshop}},
	volume = {11},
	issn = {0738-4602},
	shorttitle = {Knowledge {Discovery} in {Real} {Databases}},
	url = {http://dl.acm.org/citation.cfm?id=124898.124915},
	number = {5},
	urldate = {2018-06-02TZ},
	journal = {AI Mag.},
	author = {Piatetsky-Shapiro, Gregory},
	month = jan,
	year = {1991},
	pages = {68--70}
}

@article{ling_machine_2016,
	title = {Machine learning strategies for systems with invariance properties},
	volume = {318},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999116301309},
	doi = {10.1016/j.jcp.2016.05.003},
	abstract = {In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using data-driven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.},
	urldate = {2018-06-02TZ},
	journal = {Journal of Computational Physics},
	author = {Ling, Julia and Jones, Reese and Templeton, Jeremy},
	month = aug,
	year = {2016},
	keywords = {Constitutive models, Machine learning, Tensor invariants, Turbulence models},
	pages = {22--35}
}

@article{hinton_deep_2012,
	title = {Deep {Neural} {Networks} for {Acoustic} {Modeling} in {Speech} {Recognition}: {The} {Shared} {Views} of {Four} {Research} {Groups}},
	volume = {29},
	issn = {1053-5888},
	shorttitle = {Deep {Neural} {Networks} for {Acoustic} {Modeling} in {Speech} {Recognition}},
	doi = {10.1109/MSP.2012.2205597},
	abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Hinton, G. and Deng, L. and Yu, D. and Dahl, G. E. and Mohamed, A. r and Jaitly, N. and Senior, A. and Vanhoucke, V. and Nguyen, P. and Sainath, T. N. and Kingsbury, B.},
	month = nov,
	year = {2012},
	keywords = {Acoustics, Automatic speech recognition, Data models, Gaussian mixture models, Gaussian processes, HMM states, Hidden Markov models, Neural networks, Speech recognition, Training, acoustic modeling, deep neural networks, feed-forward neural network, feedforward neural nets, hidden Markov models, posterior probabilities, speech recognition, temporal variability},
	pages = {82--97}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2018-06-02TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}

@book{trippi_neural_1992,
	address = {New York, NY, USA},
	title = {Neural {Networks} in {Finance} and {Investing}: {Using} {Artificial} {Intelligence} to {Improve} {Real} {World} {Performance}},
	isbn = {978-1-55738-452-2},
	shorttitle = {Neural {Networks} in {Finance} and {Investing}},
	abstract = {From the Publisher:Neural networks are revolutionizing virtually every aspect of financial and investment decision making. Financial firms worldwide are employing neural networks to tackle difficult tasks involving intuitive judgement or requiring the detection of data patterns which elude conventional analytic techniques. Many observers believe neural networks will eventually outperform even the best traders and investors. Neural networks are already being used to trade the securities markets, to forecast the economy and to analyze credit risk. Indeed, apart from the U.S. Department of Defense, the financial services industry has invested more money in neural network research than any other industry or government body. Unlike other types of artificial intelligence, neural networks mimic to some extent the processing characteristics of the human brain. As a result, neural networks can draw conclusions from incomplete data, recognize patterns as they unfold in real time and forecast the future. They can even learn from past mistakes! In Neural Networks in Finance and Investing, Robert Trippi and Efraim Turban have assembled a stellar collection of articles by experts in industry and academia on the applications of neural networks in this important arena. They discuss neural network successes and failures, as well as identify the vast unrealized potential of neural networks in numerous specialized areas of financial decision making. Topics include neural network fundamentals and overview, analysis of financial condition, business failure prediction, debt risk assessment, security market applications, and neural network approaches to financial forecasting. Nowhere else will the finance professional find such an exciting and relevant in-depth examination of neural networks. Individual chapters discuss how to use neural networks to forecast the stock market, to trade commodities, to assess bond and mortgage risk, to predict bankruptcy and to implement investment strategies. Taken toge},
	publisher = {McGraw-Hill, Inc.},
	editor = {Trippi, Robert R. and Turban, Efraim},
	year = {1992}
}

@inproceedings{banfield_comparison_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Comparison} of {Ensemble} {Creation} {Techniques}},
	isbn = {978-3-540-22144-9 978-3-540-25966-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-25966-4_22},
	doi = {10.1007/978-3-540-25966-4_22},
	abstract = {We experimentally evaluated bagging and six other randomization-based ensemble tree methods. Bagging uses randomization to create multiple training sets. Other approaches, such as Randomized C4.5, apply randomization in selecting a test at a given node of a tree. Then there are approaches, such as random forests and random subspaces, that apply randomization in the selection of attributes to be used in building the tree. On the other hand boosting incrementally builds classifiers by focusing on examples misclassified by existing classifiers. Experiments were performed on 34 publicly available data sets. While each of the other six approaches has some strengths, we find that none of them is consistently more accurate than standard bagging when tested for statistical significance.},
	language = {en},
	urldate = {2018-06-01TZ},
	booktitle = {Multiple {Classifier} {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Banfield, Robert E. and Hall, Lawrence O. and Bowyer, Kevin W. and Bhadoria, Divya and Kegelmeyer, W. Philip and Eschrich, Steven},
	month = jun,
	year = {2004},
	pages = {223--232}
}

@article{ling_uncertainty_2016,
	title = {Uncertainty {Analysis} and {Data}-{Driven} {Model} {Advances} for a {Jet}-in-{Crossflow}},
	volume = {139},
	issn = {0889-504X},
	url = {http://dx.doi.org/10.1115/1.4034556},
	doi = {10.1115/1.4034556},
	abstract = {For film cooling of combustor linings and turbine blades, it is critical to be able to accurately model jets-in-crossflow. Current Reynolds-averaged Navier–Stokes (RANS) models often give unsatisfactory predictions in these flows, due in large part to model form error, which cannot be resolved through calibration or tuning of model coefficients. The Boussinesq hypothesis, upon which most two-equation RANS models rely, posits the existence of a non-negative scalar eddy viscosity, which gives a linear relation between the Reynolds stresses and the mean strain rate. This model is rigorously analyzed in the context of a jet-in-crossflow using the high-fidelity large eddy simulation data of Ruiz et al. (2015, “Flow Topologies and Turbulence Scales in a Jet-in-Cross-Flow,” Phys. Fluids, 27(4), p. 045101), as well as RANS k–ϵ results for the same flow. It is shown that the RANS models fail to accurately represent the Reynolds stress anisotropy in the injection hole, along the wall, and on the lee side of the jet. Machine learning methods are developed to provide improved predictions of the Reynolds stress anisotropy in this flow.},
	number = {2},
	urldate = {2018-06-01TZ},
	journal = {Journal of Turbomachinery},
	author = {Ling, Julia and Ruiz, Anthony and Lacaze, Guilhem and Oefelein, Joseph},
	month = oct,
	year = {2016},
	pages = {021008--021008--9}
}

@incollection{tracey_application_2013,
	series = {Aerospace {Sciences} {Meetings}},
	title = {Application of {Supervised} {Learning} to {Quantify} {Uncertainties} in {Turbulence} and {Combustion} {Modeling}},
	url = {http://arc.aiaa.org/doi/10.2514/6.2013-259},
	urldate = {2018-06-01TZ},
	booktitle = {51st {AIAA} {Aerospace} {Sciences} {Meeting} including the {New} {Horizons} {Forum} and {Aerospace} {Exposition}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Tracey, Brendan and Duraisamy, Karthik and Alonso, Juan},
	month = jan,
	year = {2013},
	doi = {10.2514/6.2013-259}
}

@article{louppe_understanding_2014,
	title = {Understanding {Random} {Forests}: {From} {Theory} to {Practice}},
	shorttitle = {Understanding {Random} {Forests}},
	url = {http://arxiv.org/abs/1407.7502},
	abstract = {Data analysis and machine learning have become an integrative part of the modern scientific methodology, offering automated procedures for the prediction of a phenomenon based on past observations, unraveling underlying patterns in data and providing insights about the problem. Yet, caution should avoid using machine learning as a black-box tool, but rather consider it as a methodology, with a rational thought process that is entirely dependent on the problem under study. In particular, the use of algorithms should ideally require a reasonable understanding of their mechanisms, properties and limitations, in order to better apprehend and interpret their results. Accordingly, the goal of this thesis is to provide an in-depth analysis of random forests, consistently calling into question each and every part of the algorithm, in order to shed new light on its learning capabilities, inner workings and interpretability. The first part of this work studies the induction of decision trees and the construction of ensembles of randomized trees, motivating their design and purpose whenever possible. Our contributions follow with an original complexity analysis of random forests, showing their good computational performance and scalability, along with an in-depth discussion of their implementation details, as contributed within Scikit-Learn. In the second part of this work, we analyse and discuss the interpretability of random forests in the eyes of variable importance measures. The core of our contributions rests in the theoretical characterization of the Mean Decrease of Impurity variable importance measure, from which we prove and derive some of its properties in the case of multiway totally randomized trees and in asymptotic conditions. In consequence of this work, our analysis demonstrates that variable importances [...].},
	urldate = {2018-06-01TZ},
	journal = {arXiv:1407.7502 [stat]},
	author = {Louppe, Gilles},
	month = jul,
	year = {2014},
	note = {arXiv: 1407.7502},
	keywords = {Statistics - Machine Learning}
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/article/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2018-06-01TZ},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	pages = {5--32}
}

@inproceedings{zhang_machine_2015,
	series = {{AIAA} {AVIATION} {Forum}},
	title = {Machine {Learning} {Methods} for {Data}-{Driven} {Turbulence} {Modeling}},
	url = {http://arc.aiaa.org/doi/10.2514/6.2015-2460},
	urldate = {2018-06-01TZ},
	booktitle = {22nd {AIAA} {Computational} {Fluid} {Dynamics} {Conference}},
	author = {Zhang, Ze Jia and Duraisamy, Karthikeyan},
	month = jun,
	year = {2015},
	doi = {10.2514/6.2015-2460}
}

@incollection{dennis_jr._computational_1973,
	title = {{SOME} {COMPUTATIONAL} {TECHNIQUES} {FOR} {THE} {NONLINEAR} {LEAST} {SQUARES} {PROBLEM}},
	isbn = {978-0-12-148950-2},
	url = {https://www.sciencedirect.com/science/article/pii/B9780121489502500109},
	abstract = {This chapter discusses some computational techniques for the nonlinear least squares problem. It presents one way of looking at some of the more useful computational techniques for solving the over-determined nonlinear least squares problem. In particular, it shows that these methods can profitably be viewed as Newton-like methods. The chapter also discusses the advantages and disadvantages of the Gauss–Newton method. The large residual problems are of prime importance. These are usually the problems that have the added complication of a large number of equations. In the linear case, such problems have become fairly routine through the use of the so-called Kalman filter. Little is known about the adaptability of Kalman filtering to large nonlinear problems. Recently there has been a flurry of activity concerning the exploitation of any linearity in the problem.},
	urldate = {2018-06-01TZ},
	booktitle = {Numerical {Solution} of {Systems} of {Nonlinear} {Algebraic} {Equations}},
	publisher = {Academic Press},
	author = {Dennis Jr., J. E.},
	editor = {Byrne, George D. and Hall, Charles A.},
	year = {1973},
	doi = {10.1016/B978-0-12-148950-2.50010-9},
	pages = {157--183}
}

@article{osborne_new_2000,
	title = {A new approach to variable selection in least squares problems},
	volume = {20},
	issn = {0272-4979},
	url = {https://academic.oup.com/imajna/article/20/3/389/777743},
	doi = {10.1093/imanum/20.3.389},
	abstract = {Abstract.  The title Lasso has been suggested by Tibshirani (1996) as a colourful name for a technique of variable selection which requires the minimization of},
	language = {en},
	number = {3},
	urldate = {2018-06-01TZ},
	journal = {IMA Journal of Numerical Analysis},
	author = {Osborne, M. R. and Presnell, B. and Turlach, B. A.},
	month = jul,
	year = {2000},
	pages = {389--403}
}

@article{kuo_least-squares_1998,
	title = {A {Least}-{Squares} {Estimation} {Approach} to {Improving} the {Precision} of {Inverse} {Dynamics} {Computations}},
	volume = {120},
	issn = {0148-0731},
	url = {http://biomechanical.asmedigitalcollection.asme.org/article.aspx?articleid=1401138},
	doi = {10.1115/1.2834295},
	number = {1},
	urldate = {2018-06-01TZ},
	journal = {Journal of Biomechanical Engineering},
	author = {Kuo, A. D.},
	month = feb,
	year = {1998},
	pages = {148--159}
}

@article{jamil_literature_2013,
	title = {A literature survey of benchmark functions for global optimisation problems},
	volume = {4},
	issn = {2040-3607},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJMMNO.2013.055204},
	doi = {10.1504/IJMMNO.2013.055204},
	abstract = {Test functions are important to validate and compare the performance of optimisation algorithms. There have been many test or benchmark functions reported in the literature; however, there is no standard list or set of benchmark functions. Ideally, test functions should have diverse properties to be truly useful to test new algorithms in an unbiased way. For this purpose, we have reviewed and compiled a rich set of 175 benchmark functions for unconstrained optimisation problems with diverse properties in terms of modality, separability, and valley landscape. This is by far the most complete set of functions so far in the literature, and it can be expected that this complete set of functions can be used for validation of new optimisation in the future.},
	number = {2},
	urldate = {2018-06-01TZ},
	journal = {International Journal of Mathematical Modelling and Numerical Optimisation},
	author = {Jamil, Momin and Yang, Xin-She},
	month = jan,
	year = {2013},
	pages = {150--194}
}

@book{link_bayesian_2010,
	edition = {First edition},
	title = {Bayesian {Inference}},
	isbn = {978-0-12-374854-6},
	url = {http://linkinghub.elsevier.com/retrieve/pii/C20090016742},
	language = {en},
	urldate = {2018-05-29TZ},
	publisher = {Elsevier},
	author = {Link, William A. and Barker, Richard J.},
	year = {2010},
	doi = {10.1016/C2009-0-01674-2}
}

@article{edeling_bayesian_2014,
	title = {Bayesian estimates of parameter variability in the k–epsilon turbulence model},
	volume = {258},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999113007031},
	doi = {10.1016/j.jcp.2013.10.027},
	abstract = {In this paper we are concerned with obtaining estimates for the error in Reynolds-averaged Navier–Stokes (RANS) simulations based on the Launder–Sharma k–ε turbulence closure model, for a limited class of flows. In particular we search for estimates grounded in uncertainties in the space of model closure coefficients, for wall-bounded flows at a variety of favorable and adverse pressure gradients. In order to estimate the spread of closure coefficients which reproduces these flows accurately, we perform 13 separate Bayesian calibrations – each at a different pressure gradient – using measured boundary-layer velocity profiles, and a statistical model containing a multiplicative model-inadequacy term in the solution space. The results are 13 joint posterior distributions over coefficients and hyper-parameters. To summarize this information we compute Highest Posterior-Density (HPD) intervals, and subsequently represent the total solution uncertainty with a probability-box (p-box). This p-box represents both parameter variability across flows, and epistemic uncertainty within each calibration. A prediction of a new boundary-layer flow is made with uncertainty bars generated from this uncertainty information, and the resulting error estimate is shown to be consistent with measurement data.},
	urldate = {2018-04-09TZ},
	journal = {Journal of Computational Physics},
	author = {Edeling, W. N. and Cinnella, P. and Dwight, R. P. and Bijl, H.},
	month = feb,
	year = {2014},
	keywords = {bayesian, uncertainty quantification},
	pages = {73--94}
}

@article{wang_large_2005,
	title = {Large eddy simulation of stably stratified turbulent open channel flows with low- to high-{Prandtl} number},
	volume = {48},
	issn = {0017-9310},
	url = {http://www.sciencedirect.com/science/article/pii/S0017931005000347},
	doi = {10.1016/j.ijheatmasstransfer.2004.12.017},
	abstract = {Large eddy simulation of thermally stratified turbulent open channel flows with low- to high-Prandtl number is performed. The three-dimensional filtered Navier–Stokes and energy equations under the Boussinesq approximation are numerically solved using a fractional-step method. Dynamic subgrid-scale (SGS) models for the turbulent SGS stress and heat flux are employed to close the governing equations. The objective of this study is to reveal the effects of both the Prandtl number (Pr) and Richardson (Riτ) number on the characteristics of turbulent flow, heat transfer, and large-scale motions in weakly stratified turbulence. The stably stratified turbulent open channel flows are calculated for Pr from 0.1 up to 100, Riτ from 0 to 20, and the Reynolds number (Reτ) 180 based on the wall friction velocity and the channel height. To elucidate the turbulent flow and heat transfer behaviors, some typical quantities, including the mean velocity, temperature and their fluctuations, turbulent heat fluxes, and the structures of the velocity and temperature fluctuations, are analyzed.},
	number = {10},
	urldate = {2018-05-27TZ},
	journal = {International Journal of Heat and Mass Transfer},
	author = {Wang, Lei and Lu, Xi-Yun},
	month = may,
	year = {2005},
	keywords = {Heat transfer, Large eddy simulation (LES), Stably stratified turbulence, Subgrid scale (SGS) model, Thermally stratified turbulence, Turbulent open channel flow},
	pages = {1883--1897}
}

@article{taylor_large_2005,
	title = {Large eddy simulation of stably stratified open channel flow},
	volume = {17},
	issn = {1070-6631},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.2130747},
	doi = {10.1063/1.2130747},
	number = {11},
	urldate = {2018-05-27TZ},
	journal = {Physics of Fluids},
	author = {Taylor, John R. and Sarkar, Sutanu and Armenio, Vincenzo},
	month = nov,
	year = {2005},
	pages = {116602}
}

@article{taylor_large_nodate,
	title = {Large eddy simulation of stably stratified open channel flow: {Physics} of {Fluids}: {Vol} 17, {No} 11},
	url = {https://doi-org.ezproxy1.library.usyd.edu.au/10.1063/1.2130747},
	abstract = {Large eddy simulation has been used to study flow in an open channel with stable stratification imposed at the free surface by a constant heat flux and an adiabatic bottom wall. This leads to a stable pycnocline overlying a well-mixed turbulent region near the bottom wall. The results are contrasted with studies in which the bottom heat flux is nonzero, a difference analogous to that between oceanic and atmospheric boundary layers. Increasing the friction Richardson number, a measure of the relative importance of the imposed surface stratification with respect to wall-generated turbulence, leads to a stronger, thicker pycnocline which eventually limits the impact of wall-generated turbulence on the free surface. Increasing stratification also leads to an increase in the pressure-driven mean streamwise velocity and a concomitant decrease in the skin friction coefficient, which is, however, smaller than in the previous channel flow studies where the bottom buoyancy flux was nonzero. It is found that the turbulence in any given region of the flow can be classified into three regimes (unstratified, buoyancy-affected, and buoyancy-dominated) based on the magnitude of the Ozmidov length scale relative to a vertical length characterizing the large scales of turbulence and to the Kolmogorov scale. Since stratification does not strongly influence the near-wall turbulent production in the present configuration, the behavior of the buoyancy flux, turbulent Prandtl number, and mixing efficiency is qualitatively different from that seen in stratified shear layers and in channel flow with fixed temperature walls, and, furthermore, collapse of quantities as a function of gradient Richardson number is not observed. The vertical Froude number is a better measure of stratified turbulence in the upper portion of the channel where buoyancy, by providing a potential energy barrier, primarily affects the transport of turbulent patches generated at the bottom wall. The characteristics of free-surface turbulence including the kinetic energy budget and pressure-strain correlations are examined and found to depend strongly on the surface stratification.},
	urldate = {2018-05-27TZ},
	author = {Taylor, John R. and Sarkar, Sutanu}
}

@misc{noauthor_large_nodate,
	title = {Large eddy simulation of stably stratified turbulent open channel flows with low- to high-{Prandtl} number - {ScienceDirect}},
	url = {https://www-sciencedirect-com.ezproxy1.library.usyd.edu.au/science/article/pii/S0017931005000347},
	urldate = {2018-05-27TZ}
}

@article{armenio_investigation_2002,
	title = {An investigation of stably stratified turbulent channel flow using large-eddy simulation},
	volume = {459},
	issn = {1469-7645, 0022-1120},
	url = {http://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/an-investigation-of-stably-stratified-turbulent-channel-flow-using-large-eddy-simulation/B651550D5EF5686BB1A481DF1FDFEC68#},
	doi = {10.1017/S0022112002007851},
	abstract = {Boundary-forced stratified turbulence is studied in the prototypical case of turbulent
channel flow subject to stable stratification. The large-eddy simulation approach is
used with a mixed subgrid model that involves a dynamic eddy viscosity component
and a scale-similarity component. After an initial transient, the flow reaches a new
balanced state corresponding to active wall-bounded turbulence with reduced vertical
transport which, for the cases in our study with moderate-to-large levels of stratification,
coexists with internal wave activity in the core of the channel. A systematic
reduction of turbulence levels, density fluctuations and associated vertical transport
with increasing stratification is observed. Countergradient buoyancy flux is observed
in the outer region for sufficiently high stratification.Mixing of the density field in stratified channel flow results from turbulent events
generated near the boundaries that couple with the outer, more stable flow. The
vertical density structure is thus of interest for analogous boundary-forced mixing
situations in geophysical flows. It is found that, with increasing stratification, the
mean density profile becomes sharper in the central region between the two turbulent
layers at the upper and lower walls, similar to observations in field measurements as
well as laboratory experiments with analogous density-mixing situations.Channel flow is strongly inhomogeneous with alternative choices for the Richardson
number. In spite of these complications, the gradient Richardson number, Rig, appears
to be the important local determinant of buoyancy effects. All simulated cases show
that correlation coefficients associated with vertical transport collapse from their nominal unstratified
values over a narrow range, 0.15 {\textless} Rig {\textless} 0.25. The vertical turbulent
Froude number, Frw, has an O(1) value across most of the channel. It
is remarkable that stratified channel flow, with such a large variation of overall
density difference (factor of 26) between cases, shows a relatively universal behaviour
of correlation coefficients and vertical Froude number when plotted as a function of
Rig. The visualizations show wavy motion in the core region where the gradient
Richardson number, Rig, is large and low-speed streaks in the near-wall region,
typical of unstratified channel flow, where Rig is small. It appears from the
visualizations that, with increasing stratification, the region with wavy motion progressively encroaches
into the zone with active turbulence; the location of Rig ≃ 0.2 roughly
corresponds to the boundary between the two zones.},
	language = {en},
	urldate = {2018-05-27TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Armenio, Vincenzo and Sarkar, Sutanu},
	month = may,
	year = {2002},
	pages = {1--42}
}

@inproceedings{spalart_comments_1997,
	title = {Comments on the {Feasibility} of {LES} for {Wings}, and on a {Hybrid} {RANS}/{LES} {Approach}},
	author = {Spalart, Philippe and Jou, W-H and Strelets, Michael and Allmaras, Steven},
	month = jan,
	year = {1997}
}

@book{pope_turbulent_2000,
	address = {Cambridge},
	title = {Turbulent {Flows}},
	publisher = {Cambridge University Press},
	author = {Pope, Stephen B.},
	year = {2000}
}

@article{ling_evaluation_2015,
	title = {Evaluation of machine learning algorithms for prediction of regions of high {Reynolds} averaged {Navier} {Stokes} uncertainty},
	volume = {27},
	issn = {1070-6631},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.4927765},
	doi = {10.1063/1.4927765},
	number = {8},
	urldate = {2018-04-09TZ},
	journal = {Physics of Fluids},
	author = {Ling, J. and Templeton, J.},
	month = aug,
	year = {2015},
	keywords = {priori, uncertainty quantification},
	pages = {085103}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Nature Publishing Group},
	issn = {1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2018-05-27TZ},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	keywords = {priori},
	pages = {436--444}
}

@article{parish_paradigm_2016,
	title = {A paradigm for data-driven predictive modeling using field inversion and machine learning},
	volume = {305},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999115007524},
	doi = {10.1016/j.jcp.2015.11.012},
	abstract = {We propose a modeling paradigm, termed field inversion and machine learning (FIML), that seeks to comprehensively harness data from sources such as high-fidelity simulations and experiments to aid the creation of improved closure models for computational physics applications. In contrast to inferring model parameters, this work uses inverse modeling to obtain corrective, spatially distributed functional terms, offering a route to directly address model-form errors. Once the inference has been performed over a number of problems that are representative of the deficient physics in the closure model, machine learning techniques are used to reconstruct the model corrections in terms of variables that appear in the closure model. These reconstructed functional forms are then used to augment the closure model in a predictive computational setting. As a first demonstrative example, a scalar ordinary differential equation is considered, wherein the model equation has missing and deficient terms. Following this, the methodology is extended to the prediction of turbulent channel flow. In both of these applications, the approach is demonstrated to be able to successfully reconstruct functional corrections and yield accurate predictive solutions while providing a measure of model form uncertainties.},
	urldate = {2018-05-27TZ},
	journal = {Journal of Computational Physics},
	author = {Parish, Eric J. and Duraisamy, Karthik},
	month = jan,
	year = {2016},
	keywords = {Closure modeling, Data-driven modeling, Machine learning},
	pages = {758--774}
}

@article{edeling_data-free_2018,
	title = {Data-{Free} and {Data}-{Driven} {RANS} {Predictions} with {Quantified} {Uncertainty}},
	volume = {100},
	issn = {1386-6184, 1573-1987},
	url = {http://link.springer.com/article/10.1007/s10494-017-9870-6},
	doi = {10.1007/s10494-017-9870-6},
	abstract = {For the purpose of estimating the epistemic model-form uncertainty in Reynolds-Averaged Navier-Stokes closures, we propose two transport equations to locally perturb the Reynolds stress tensor of a given baseline eddy-viscosity model. The spatial structure of the perturbations is determined by the proposed transport equations, and thus does not have to be inferred from full-field reference data. Depending on a small number of model parameters and the local flow conditions, a ’return to eddy viscosity’ is described, and the underlying baseline state can be recovered. In order to make predictions with quantified uncertainty, we identify two separate methods, i.e. a data-free and data-driven approach. In the former no reference data is required and computationally inexpensive intervals are computed. When reference data is available, Bayesian inference can be applied to obtained informed distributions of the model parameters and simulation output.},
	language = {en},
	number = {3},
	urldate = {2018-04-13TZ},
	journal = {Flow, Turbulence and Combustion},
	author = {Edeling, W. N. and Iaccarino, G. and Cinnella, P.},
	month = apr,
	year = {2018},
	keywords = {not-used},
	pages = {593--616}
}

@article{pichler_investigation_2016,
	title = {Investigation of the {Accuracy} of {RANS} {Models} to {Predict} the {Flow} {Through} a {Low}-{Pressure} {Turbine}},
	volume = {138},
	issn = {0889-504X},
	url = {http://dx.doi.org/10.1115/1.4033507},
	doi = {10.1115/1.4033507},
	abstract = {In the present paper, direct numerical simulation (DNS) data of a low-pressure turbine (LPT) are investigated in light of turbulence modeling. Many compressible turbulence models use Favre-averaged transport equations of the conservative variables and turbulent kinetic energy (TKE) along with other modeling equations. First, a general discussion on the turbulence modeling error propagation prescribed by transport equations is presented, leading to the terms that are considered to be of interest for turbulence model improvement. In order to give turbulence modelers means of validating their models, the terms appearing in the Favre-averaged momentum equations are presented along pitchwise profiles at three axial positions. These three positions have been chosen such that they represent regions with different flow characteristics. General trends indicate that terms related with thermodynamic fluctuations and Favre fluctuations are small and can be neglected for most of the flow field. The largest errors arise close to the trailing edge (TE) region where vortex shedding occurs. Finally, linear models and the scope for their improvement are discussed in terms of a priori testing. Using locally optimized turbulence viscosities, the improvement potential of widely used models is shown. On the other hand, this study also highlights the danger of pure local optimization.},
	number = {12},
	urldate = {2018-04-13TZ},
	journal = {Journal of Turbomachinery},
	author = {Pichler, R. and Sandberg, R. D. and Michelassi, V. and Bhaskaran, R.},
	month = jun,
	year = {2016},
	keywords = {priori},
	pages = {121009--121009--12}
}
@article{weatheritt_machine_2017,
	title = {Machine {Learning} for {Turbulence} {Model} {Development} {Using} a {High}-{Fidelity} {HPT} {Cascade} {Simulation}},
	url = {http://dx.doi.org/10.1115/GT2017-63497},
	doi = {10.1115/GT2017-63497},
	abstract = {The validity of the Boussinesq approximation in the wake behind a high-pressure turbine blade is explored. We probe the mathematical assumptions of such a relationship by employing a least-squares technique. Next, we use an evolutionary algorithm to modify the anisotropy tensor a priori using highly resolved LES data. In the latter case we build a non-linear stress-strain relationship. Results show that the standard eddy-viscosity assumption underpredicts turbulent diffusion and is theoretically invalid. By increasing the coefficient of the linear term, the farwake prediction shows minor improvement. By using additional non-linear terms in the stress-strain coupling relationship, created by the evolutionary algorithm, the near-wake can also be improved upon. Terms created by the algorithm are scrutinized and the discussion is closed by suggesting a tentative non-linear expression for the Reynolds stress, suitable for the wake behind a high-pressure turbine blade.},
	urldate = {2018-01-01TZ},
	author = {Weatheritt, Jack and Pichler, Richard and Sandberg, Richard D. and Laskowski, Gregory and Michelassi, Vittorio},
	month = jun,
	year = {2017},
	keywords = {priori},
	pages = {V02BT41A015}
}

@article{muldoon_analysis_2006,
	title = {Analysis of k and epsilon {Budgets} for {Film} {Cooling} {Using} {Direct} {Numerical} {Simulation}},
	volume = {44},
	issn = {0001-1452},
	url = {https://doi.org/10.2514/1.20597},
	doi = {10.2514/1.20597},
	number = {12},
	urldate = {2018-04-13},
	journal = {AIAA Journal},
	author = {Muldoon, Frank and Acharya, Sumanta},
	month = dec,
	year = {2006},
	keywords = {priori},
	pages = {3010--3021}
}

@book{wang_quantification_2011,
	title = {Quantification of {Structural} {Uncertainties} in the k -w {Turbulence} {Model}},
	abstract = {We propose a method for building a statistical model for the structural uncertainties in the k − ω turbulence model. An inverse RANS problem is solved for a collection of randomly generated geometries to determine the turbulent viscosity that produces the flow field closest to that predicted by direct numerical simulation (DNS). A statistical model of the uncertainty in the turbulent viscosity calculated using the k − ω model is then developed using the data generated from solving the inverse problem. We present results for turbulent flow in a straight channel, as well as the preliminary results for the collection of randomly generated geometries.},
	author = {Wang, Qiqi and Dow, Eric},
	month = apr,
	year = {2011},
	doi = {10.2514/6.2011-1762}
}

@incollection{dow_uncertainty_2011,
	series = {Fluid {Dynamics} and {Co}-located {Conferences}},
	title = {Uncertainty {Quantification} of {Structural} {Uncertainties} in {RANS} {Simulations} of {Complex} {Flows}},
	url = {https://doi.org/10.2514/6.2011-3865},
	urldate = {2018-04-12},
	booktitle = {20th {AIAA} {Computational} {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Dow, Eric and Wang, Qiqi},
	month = jun,
	year = {2011},
	doi = {10.2514/6.2011-3865},
	keywords = {uncertainty quantification}
}

@incollection{dow_uncertainty_nodate,
	title = {Uncertainty {Quantification} of {Structural} {Uncertainties} in {RANS} {Simulations} of {Complex} {Flows}},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2011-3865},
	urldate = {2018-04-13TZ},
	booktitle = {20th {AIAA} {Computational} {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Dow, Eric and Wang, Qiqi},
	doi = {10.2514/6.2011-3865}
}

@incollection{ray_bayesian_2015,
	series = {{AIAA} {AVIATION} {Forum}},
	title = {Bayesian {Calibration} of a {RANS} {Model} with a {Complex} {Response} {Surface} - {A} {Case} {Study} with {Jet}-in-{Crossflow} {Configuration}},
	url = {https://doi.org/10.2514/6.2015-2784},
	urldate = {2018-04-12},
	booktitle = {45th {AIAA} {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Ray, Jaideep and Lefantzi, Sophia and Arunajatesan, Srinivasan and DeChant, Lawrence J.},
	month = jun,
	year = {2015},
	doi = {10.2514/6.2015-2784},
	keywords = {bayesian, uncertainty quantification}
}

@article{cheung_bayesian_2011,
	series = {Quantification of {Margins} and {Uncertainties}},
	title = {Bayesian uncertainty analysis with applications to turbulence modeling},
	volume = {96},
	issn = {0951-8320},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832011000664},
	doi = {10.1016/j.ress.2010.09.013},
	abstract = {In this paper, we apply Bayesian uncertainty quantification techniques to the processes of calibrating complex mathematical models and predicting quantities of interest (QoI's) with such models. These techniques also enable the systematic comparison of competing model classes. The processes of calibration and comparison constitute the building blocks of a larger validation process, the goal of which is to accept or reject a given mathematical model for the prediction of a particular QoI for a particular scenario. In this work, we take the first step in this process by applying the methodology to the analysis of the Spalart–Allmaras turbulence model in the context of incompressible, boundary layer flows. Three competing model classes based on the Spalart–Allmaras model are formulated, calibrated against experimental data, and used to issue a prediction with quantified uncertainty. The model classes are compared in terms of their posterior probabilities and their prediction of QoI's. The model posterior probability represents the relative plausibility of a model class given the data. Thus, it incorporates the model's ability to fit experimental observations. Alternatively, comparing models using the predicted QoI connects the process to the needs of decision makers that use the results of the model. We show that by using both the model plausibility and predicted QoI, one has the opportunity to reject some model classes after calibration, before subjecting the remaining classes to additional validation challenges.},
	number = {9},
	urldate = {2018-04-13TZ},
	journal = {Reliability Engineering \& System Safety},
	author = {Cheung, Sai Hung and Oliver, Todd A. and Prudencio, Ernesto E. and Prudhomme, Serge and Moser, Robert D.},
	month = sep,
	year = {2011},
	keywords = {bayesian, uncertainty quantification},
	pages = {1137--1149}
}

@inproceedings{yarlanki_estimation_2012,
	title = {Estimation of turbulence closure coefficients for data centers using machine learning algorithms},
	doi = {10.1109/ITHERM.2012.6231411},
	abstract = {CFD models of data centers often use two equation turbulence models such as the k-ε model. These models are based on closure coefficients or turbulence model constants determined from a combination of scaling/dimensional analysis and experimental measurements of flows in simple configurations. The simple configurations used to derive the turbulence model constants are often two dimensional and do not have many of the complex flow characteristics found in engineering flows. Such models perform poorly, especially in flows with large pressure gradients, swirl and strong three dimensionality, as in the case of data centers. This study attempts to use machine learning algorithms to optimize the model constants of the k-ε turbulence model for a data center by comparing simulated data with experimentally measured temperature values. For a given set of turbulence constants, we determine the Root Mean Square `error' in the model, defined as the difference between experimentally measured temperature from a data center test cell and CFD calculations using the k-ε model. An artificial neural network (ANN) based method for parameter identification is then used to find the optimal values for turbulence constants such that the error is minimized. The optimum turbulence model constants obtained by our study results in lowering the RMS error by 25\% and absolute average error by 35\% compared to the error obtained by using standard k-ε model constants.},
	booktitle = {13th {InterSociety} {Conference} on {Thermal} and {Thermomechanical} {Phenomena} in {Electronic} {Systems}},
	author = {Yarlanki, S. and Rajendran, B. and Hamann, H.},
	month = may,
	year = {2012},
	keywords = {uncertainty quantification},
	pages = {38--42}
}

@article{spalart_direct_2015,
	title = {Direct {Simulation} and {RANS} {Modelling} of a {Vortex} {Generator} {Flow}},
	volume = {95},
	issn = {1386-6184, 1573-1987},
	url = {http://link.springer.com/article/10.1007/s10494-015-9610-8},
	doi = {10.1007/s10494-015-9610-8},
	abstract = {An array of co-rotating vortex generators (VG) is placed in a supersonic boundary layer, similar to that on an airliner wing. Direct numerical simulations (DNS) are conducted, with unsteady turbulent content in the incoming boundary layer obtained from the synthetic-turbulence approach of Shur et al. (Flow Turbul. Combust. 93, 63–92, 2014). The RANS models are tested in two ways: with a straightforward application to the problem, but also by solving the turbulence equations in the “frozen” average flow field of the DNS and therefore in “passive” mode, which appears to be a powerful procedure, similar to that of Parneix et al. (J. Fluids Eng. 120(1), 40–47, 1998). Side-by-side comparisons become clearer. The model Reynolds stresses are compared with the Reynolds stresses of the DNS. A plausible definition of an effective scalar eddy viscosity extracted from the DNS is also used for comparison, providing a target value. The models are the k- ω Shear Stress Transport model of Menter (1993) (SST) and the curvature-corrected version of Smirnov and Menter (J. Turbomach. 131(4), 041010, 2009) which we will denote by SST-RC, the eddy-viscosity transport model of Spalart and Allmaras (1992) (SA), and the SA model with Rotation and Curvature correction of Spalart and Shur (Aerosp. Sci. Technol. 1(5), 297–302, 1997) (SARC). As expected, SST and especially SA return an excessive decay of the peak vorticity, and both SST-RC and SARC perform better, but the flow is too complex for RANS to near perfection. This decay is very detrimental in practice, since their persistence is the key property of vortices used for separation control.},
	language = {en},
	number = {2-3},
	urldate = {2018-04-09TZ},
	journal = {Flow, Turbulence and Combustion},
	author = {Spalart, P. R. and Shur, M. L. and Strelets, M. Kh and Travin, A. K.},
	month = oct,
	year = {2015},
	keywords = {uncertainty quantification},
	pages = {335--350}
}

@article{raiesi_evaluation_2011,
	title = {Evaluation of {Turbulence} {Models} {Using} {Direct} {Numerical} and {Large}-{Eddy} {Simulation} {Data}},
	volume = {133},
	issn = {0098-2202},
	url = {http://dx.doi.org/10.1115/1.4003425},
	doi = {10.1115/1.4003425},
	abstract = {The performance of some commonly used eddy-viscosity turbulence models has been evaluated using direct numerical simulation (DNS) and large-eddy simulation (LES) data. Two configurations have been tested, a two-dimensional boundary layer undergoing pressure-driven separation, and a square duct. The DNS and LES were used to assess the k−ε, ζ−f, k−ω, and Spalart–Allmaras models. For the two-dimensional separated boundary layer, anisotropic effects are not significant and the eddy-viscosity assumption works well. However, the near-wall treatment used in k−ε models was found to have a critical effect on the predictive accuracy of the model (and, in particular, of separation and reattachment points). None of the wall treatments tested resulted in accurate prediction of the flow field. Better results were obtained with models that do not require special treatment in the inner layer (ζ−f, k−ω, and Spalart–Allmaras models). For the square duct calculation, only a nonlinear constitutive relation was found to be able to capture the secondary flow, giving results in agreement with the data. Linear models had significant error.},
	number = {2},
	urldate = {2018-04-09TZ},
	journal = {Journal of Fluids Engineering},
	author = {Raiesi, Hassan and Piomelli, Ugo and Pollard, Andrew},
	month = mar,
	year = {2011},
	keywords = {uncertainty quantification},
	pages = {021203--021203--10}
}

@article{parneix_procedure_1998,
	title = {A {Procedure} for {Using} {DNS} {Databases}},
	volume = {120},
	issn = {0098-2202},
	url = {http://dx.doi.org/10.1115/1.2819658},
	doi = {10.1115/1.2819658},
	abstract = {A second moment closure (SMC) computation is compared in detail with the direct numerical simulation (DNS) data of Le et al. (1997) for the backstep flow at Re = 5100 in an attempt to understand why the intensity of the backflow and, consequently, the friction coefficient in the recirculation bubble are under-estimated. The data show that this recirculation bubble is far from being laminar except in the very near wall layer. A novel “differential a priori” procedure was used, in which the full transport equation for one isolated component of the Reynolds stress tensor was solved using DNS data as input. Conclusions are then different from what would have been deduced by comparing a full simulation to a DNS. In particular, the ε-equation, usually blamed for faults in model predictions, has been found to give excellent results in this case. In fact, the main problem comes from the uv  -equation which predicts a too high turbulent force. A modification, by including the gradients of mean flow in the transport model, has then been attempted and has cured 50 percent of the backflow discrepancy.},
	number = {1},
	urldate = {2018-04-09TZ},
	journal = {Journal of Fluids Engineering},
	author = {Parneix, S. and Laurence, D. and Durbin, P. A.},
	month = mar,
	year = {1998},
	keywords = {uncertainty quantification},
	pages = {40--47}
}

@article{schmitt_about_2007,
	series = {Joseph {Boussinesq}, a {Scientist} of bygone days and present times},
	title = {About {Boussinesq}'s turbulent viscosity hypothesis: historical remarks and a direct evaluation of its validity},
	volume = {335},
	issn = {1631-0721},
	shorttitle = {About {Boussinesq}'s turbulent viscosity hypothesis},
	url = {http://www.sciencedirect.com/science/article/pii/S1631072107001386},
	doi = {10.1016/j.crme.2007.08.004},
	abstract = {Boussinesq's hypothesis is at the heart of eddy viscosity models, which are used in many different fields to model turbulent flows. In its present time formulation, this hypothesis corresponds to an alignment between the Reynolds stress and mean strain tensors. We begin with historical remarks on Boussinesq's results and recall that he introduced a local averaging twenty years before Reynolds, but using an approach that prevented him from discovering Reynolds' stress tensor. We then introduce an indicator that characterizes the validity of this hypothesis. For experimental and numerical databases, when the tensors are known, this can be used to directly estimate the validity of this hypothesis. We show, using several different databases, that this hypothesis is almost never verified. We address, in conclusion, the analogy with kinetic theory, and the reason why this analogy cannot be applied, in general, for turbulent flows. To cite this article: F.G. Schmitt, C. R. Mecanique 335 (2007).
Résumé
L'hypothèse de Boussinesq est au coeur des modèles de viscosité, utilisés dans un grand nombre de contextes pour modéliser des écoulements turbulents. Dans sa formulation moderne, cette hypothèse correspond à un alignement entre tenseur de contrainte de Reynolds et tenseur de déformation moyen. Nous rappelons le contexte historique de l'énoncé de cette hypothèse, en soulignant que Boussinesq avait introduit une moyenne locale vingt ans avant Reynolds, mais en effectuant une erreur qui l'a privé de la mise en évidence du tenseur de Reynolds. Nous introduisons ensuite un indicateur, compris entre 0 et 1, indiquant le degré de validité de cette hypothèse. Pour des bases de données expérimentales et numériques, lorsque les différents tenseurs sont connus, ceci permet de tester directement, a priori, cette hypothèse. Nous montrons ainsi, utilisant différentes bases de données d'écoulements turbulents, que l'hypothèse n'est presque jamais vérifiée. Nous discutons en conclusion de la théorie cinétique des gaz et de la raison pour laquelle cette analogie est discutable pour les écoulements turbulents. Pour citer cet article : F.G. Schmitt, C. R. Mecanique 335 (2007).},
	number = {9},
	urldate = {2018-04-09TZ},
	journal = {Comptes Rendus Mécanique},
	author = {Schmitt, François G.},
	month = sep,
	year = {2007},
	keywords = {uncertainty quantification},
	pages = {617--627}
}

@incollection{g.f._hewitt_guidelines_2005,
	address = {Cambridge},
	title = {Guidelines and criteria for the use of turbulence models in complex flows},
	isbn = {0-521-83899-1},
	abstract = {The prediction of turbulent flows is of paramount importance in the development of complex engineering systems involving flow, heat and mass transfer, and chemical reactions. Born out of a major programme held at the Isaac Newton Institute in Cambridge, England, this new volume aims at taking an overview of the current situation on the prediction of such flows through the use of modern computational fluid dynamics techniques. In particular, current approximation methods are reviewed and their applicability to various industrial problems discussed, and the current physical understanding of turbulence is summarised. In addition, the book provides a specific set of guidelines for the choice of model for a given problem. This major work addresses the needs of experienced practitioners and researchers and continues the United Kingdom's strong tradition in fluid dynamics},
	booktitle = {Prediction of turbulent flows},
	publisher = {Cambridge University Press},
	author = {{J. C. R. Hunt} and {A. M. Savill}},
	editor = {{G.F. Hewitt} and {J.C. Vassilicos}},
	year = {2005},
	keywords = {uncertainty quantification}
}

@misc{noauthor_guidelines_nodate,
	title = {Guidelines and criteria for the use of turbulence models in complex flows ({Chapter} 8) - {Prediction} of {Turbulent} {Flows}},
	url = {/core/books/prediction-of-turbulent-flows/guidelines-and-criteria-for-the-use-of-turbulence-models-in-complex-flows/99C9B34AFC59F828E7800E1164C5C9AE},
	abstract = {Prediction of Turbulent Flows - edited by Geoff Hewitt June 2005},
	language = {en},
	urldate = {2018-04-09TZ},
	journal = {Cambridge Core}
}

@article{wang_comprehensive_2017,
	title = {A {Comprehensive} {Physics}-{Informed} {Machine} {Learning} {Framework} for {Predictive} {Turbulence} {Modeling}},
	url = {http://arxiv.org/abs/1701.07102},
	abstract = {Although an increased availability of computational resources has enabled high-fidelity simulations of turbulent flows, the RANS models are still the dominant tools for industrial applications. However, the predictive capabilities of RANS models are limited by potential inaccuracy driven by hypotheses in the Reynolds stress closure. Recently, a Physics-Informed Machine Learning (PIML) approach has been proposed to learn the functional form of Reynolds stress discrepancy in RANS simulations based on available data. It has been demonstrated that the learned discrepancy function can be used to improve Reynolds stresses in different flows where data are not available. However, owing to a number of challenges, the improvements have been demonstrated only in the Reynolds stress prediction but not in the corresponding propagated quantities of interest. In this work, we introduce the procedures toward a complete PIML framework for predictive turbulence modeling, including learning Reynolds stress discrepancy function, predicting Reynolds stresses in different flows, and propagating to mean flow fields. The process of Reynolds stress propagation and predictive accuracy of the propagated velocity field are investigated. To improve the learning-prediction performance, the input features are enriched based on an integrity basis of invariants. The fully developed turbulent flow in a square duct is used as the test case. The discrepancy model is trained on flow fields obtained from several Reynolds numbers and evaluated on a duct flow at a Reynolds number higher than any of the training cases. The predicted Reynolds stresses are propagated to velocity field through RANS equations. Numerical results show excellent predictive performances in both Reynolds stresses and their propagated velocities, demonstrating the merits of the PIML approach in predictive turbulence modeling.},
	urldate = {2017-12-24TZ},
	journal = {arXiv:1701.07102 [physics]},
	author = {Wang, Jian-Xun and Wu, Jinlong and Ling, Julia and Iaccarino, Gianluca and Xiao, Heng},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.07102},
	keywords = {Random forest, reynolds stress discrepency}
}

@article{weatheritt_hybrid_2017,
	title = {Hybrid {Reynolds}-{Averaged}/{Large}-{Eddy} {Simulation} {Methodology} from {Symbolic} {Regression}: {Formulation} and {Application}},
	volume = {55},
	issn = {0001-1452},
	shorttitle = {Hybrid {Reynolds}-{Averaged}/{Large}-{Eddy} {Simulation} {Methodology} from {Symbolic} {Regression}},
	url = {https://doi.org/10.2514/1.J055378},
	doi = {10.2514/1.J055378},
	abstract = {A unified hybrid Reynolds-averaged Navier–Stokes/large-eddy simulation closure is presented that is built from data-driven methods. This is a novel way to construct such models that does not impose constraints. Direct numerical simulation data is filtered, and the ratio of resolved to unresolved energy is used to fit an ideal length scale damping function for the unified framework. This study shows the viability of using high-fidelity data, not just for a priori testing but for the complete creation of lower-fidelity methods. Alongside the physical model, a convection scheme is proposed that marries well to it. This numerical scheme ensures that the damped turbulence model is provided the appropriate ratio of stability to accuracy. Furthermore, an additional function guarantees that the large-eddy simulation mode is only active in vortical flow. This hybrid closure is then applied to two industrially relevant yet very different geometries for which reliable reference data exist. The periodic hills test case is characterized by a confined separation and reattachment, whereas the tandem cylinders exhibits massive separation with wake interference patterns. For the latter, aeroacoustic predictions are of paramount importance. On both geometries, two mesh levels are tested. This a posteriori validation program provides a stern test for the new closure. For both resolutions on both geometries, the new formulation performs extremely well. Each case is also predicted using an established closure, and comparison to this further illustrates the potential of the current framework.},
	number = {11},
	urldate = {2018-01-01TZ},
	journal = {AIAA Journal},
	author = {Weatheritt, Jack and Sandberg, Richard D.},
	year = {2017},
	keywords = {reynolds stress directly},
	pages = {3734--3746}
}

@article{weatheritt_novel_2016,
	title = {A novel evolutionary algorithm applied to algebraic modifications of the {RANS} stress-strain relationship},
	volume = {325},
	url = {https://www-sciencedirect-com.ezproxy1.library.usyd.edu.au/science/article/pii/S0021999116303643},
	doi = {https://doi.org/10.1016/j.jcp.2016.08.015},
	abstract = {This paper presents a novel and promising approach to turbulence model formulation, rather than putting forward a particular new model. Evolutionary computation has brought symbolic regression of scalar fields into the domain of algorithms and this paper describes a novel expansion of Gene Expression Programming for the purpose of tensor modeling. By utilizing high-fidelity data and uncertainty measures, mathematical models for tensors are created. The philosophy behind the framework is to give freedom to the algorithm to produce a constraint-free model; its own functional form that was not previously imposed. Turbulence modeling is the target application, specifically the improvement of separated flow prediction. Models are created by considering the anisotropy of the turbulent stress tensor and formulating non-linear constitutive stress–strain relationships. A previously unseen flow field is computed and compared to the baseline linear model and an established non-linear model of comparable complexity. The results are highly encouraging.},
	journal = {Journal of Computational Physics},
	author = {Weatheritt, Jack and Sandberg, Richard D.},
	month = nov,
	year = {2016},
	keywords = {reynolds stress directly},
	pages = {22--37}
}

@article{weatheritt_development_2015,
	title = {The {Development} of {Data} {Driven} {Approaches} to {Further} {Turbulence} {Closures}},
	abstract = {The closure of turbulence models at all levels of fidelity is addressed, using unconventional
methods that rely on data. The purpose of the thesis is not to present new
models of turbulence per se, but rather the main focus is to develop the methodologies
that created them.
The main tool, Gene Expression Programming, is a versatile evolutionary algorithm.
Implementations of the algorithm allow for symbolic regression of scalar and tensor
 elds and the clustering of data sets. The last two applications are novel algorithms.
Scalar  eld regression is used to construct length scale damping functions for Hybrid
RANS/LES. Direct Numerical Simulation snapshots are  ltered to mimic Hybrid RANS/
LES 
ow  elds and from this new damping functions are created. Two closures are
constructed, one from data in a turbulent pipe and another from slices along the classic
backward facing step geometry. The new closures are tested for a range of separated

ow applications. Tests alongside existing closures of the same class show that both new
methods adapt to the local mesh resolution and turbulence level at least as well as other
hybrid closures.
Tensor  eld regression is used to construct non-linear stress-strain relationships in a
Reynolds-Averaged Navier-Stokes framework. A common two-equation model is modi-
 ed by including a further term that accounts for extra anisotropy with respect to the
Boussinesq approximation. This model term, regressed from time averaged Direct Numerical
Simulation data, turns the linear closure into an Explicit Algebraic Stress Model.
The training data is taken from the reverse 
ow region behind a backward facing step.
When applied to the classic periodic hills case, the subclass of models generated are
found to greatly improve the prediction with respect to the linear model. A subclass of
models is created in order to test the ability of the evolutionary algorithm. The deviation
from the periodic hills reference data is quanti ed and used as a metric for model
performance. The key  nding is that improved performance of the Gene Expression
Programming framework corresponded to improved prediction of the periodic hills.
The  nal application of Gene Expression Programming, the clustering of datasets, is
used to group Reynolds stress structures into distinct types. Firstly, reference Direct
Numerical Simulation data obtained in a turbulent channel is categorised into six distinct
groups. These groups are then compared to structures from Hybrid RANS/LES. These
groups help to show that Hybrid RANS/LES structures do not correctly capture the
near-wall cycle of turbulence. Instead there is an arti cial cycle that is characterised
by an incorrect bu er layer, de ned by tall, long and thin structures. Further, streaky
structures lie on the interface between Reynolds-Averaged Navier-Stokes and Large Eddy
Simulation. These structures are free to move in the vertical direction and seriously
contribute to discrepancies in the second order statistics.},
	author = {Weatheritt, Jack},
	month = nov,
	year = {2015},
	keywords = {reynolds stress directly}
}

@article{weatheritt_development_2017,
	title = {The development of algebraic stress models using a novel evolutionary algorithm},
	volume = {68},
	issn = {0142-727X},
	url = {http://www.sciencedirect.com/science/article/pii/S0142727X17303223},
	doi = {10.1016/j.ijheatfluidflow.2017.09.017},
	abstract = {This work presents developments to a novel evolutionary framework that symbolically regresses algebraic forms of the Reynolds stress anisotropy tensor. This work contributes to the growing trend in machine-learning for modelling physical phenomena. Our framework is shown to be computational inexpensive and produce accurate and robust models that are tangible mathematical expressions. This transparency in the result allows us to diagnose issues with the regressed formulae and appropriately make amendments, as we further understand the regression tools. Such models are created using hybrid RANS/LES flow field data and a passive solving of the RANS transport equations to obtain the modelled time scale. This process shows that models can be regressed from a qualitatively correct flow field and fully resolved DNS is not necessarily required. Models are trained and tested using rectangular ducts, an example flow genus that linear RANS models even qualitatively fail to predict correctly. A priori and a posteriori testing of the new models show that the framework is a viable methodology for RANS closure development. This a posteriori agenda includes testing on an asymmetric diffuser, for which the new models vastly outperform the baseline linear model. Therefore this study presents one of the most rigorous and complete CFD validation of machine learnt turbulent stress models to date.},
	urldate = {2018-03-26TZ},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Weatheritt, J. and Sandberg, R. D.},
	month = dec,
	year = {2017},
	keywords = {reynolds stress directly},
	pages = {298--318}
}

@article{wu_representation_2017,
	title = {Representation of {Reynolds} {Stress} {Perturbations} with {Application} in {Machine}-{Learning}-{Assisted} {Turbulence} {Modeling}},
	abstract = {Numerical simulations based on Reynolds-Averaged Navier--Stokes (RANS) equations are widely used in engineering design and analysis involving turbulent flows. However, RANS simulations are known to be unreliable in many flows of engineering relevance, which is largely caused by model-form uncertainties associated with the Reynolds stresses. Recently, a machine-learning approach has been proposed to assist RANS modeling by building a functional mapping from mean flow features to discrepancies in RANS modeled Reynolds stresses as compared to high-fidelity data. However, it remains a challenge to represent discrepancies in the Reynolds stress eigenvectors in machine learning due to the requirements of spatial smoothness, frame-independence, and realizability. In this work, we propose three schemes for representing perturbations to the eigenvectors of RANS modeled Reynolds stresses: (1) discrepancy-based Euler angles, (2) direct-rotation-based Euler angles, and (3) unit quaternions. We compare these metrics by performing a priori and a posteriori tests on two canonical flows: fully developed turbulent flows in a square duct and massively separated flows over periodic hills. The results demonstrate that the direct-rotation-based Euler angles representation lacks spatial smoothness while the discrepancy-based Euler angles representation lacks frame-independence, making them unsuitable for being used in machine-learning-assisted turbulence modeling. In contrast, the representation based on unit quaternion satisfies all the requirements stated above, and thus it is an ideal choice in representing the perturbations associated with the eigenvectors of Reynolds stress tensors. This finding has clear importance for uncertainty quantification and machine learning in turbulence modeling and for data-driven computational mechanics in general.},
	author = {Wu, Jinlong and Sun, Rui and Laizet, Sylvain and Xiao, Heng},
	month = sep,
	year = {2017},
	keywords = {reynolds stress discrepency}
}

@incollection{kubat_simple_2017,
	title = {A {Simple} {Machine}-{Learning} {Task}},
	isbn = {978-3-319-63912-3 978-3-319-63913-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-63913-0_1},
	abstract = {You will find it difficult to describe your mother’s face accurately enough for your friend to recognize her in a supermarket. But if you show him a few of her photos, he will immediately spot the tell-tale traits he needs. As they say, a picture—an example—is worth a thousand words.},
	language = {en},
	urldate = {2018-04-09TZ},
	booktitle = {An {Introduction} to {Machine} {Learning}},
	publisher = {Springer, Cham},
	author = {Kubat, Miroslav},
	year = {2017},
	doi = {10.1007/978-3-319-63913-0_1},
	pages = {1--18}
}

@incollection{kubat_artificial_2017,
	title = {Artificial {Neural} {Networks}},
	isbn = {978-3-319-63912-3 978-3-319-63913-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-63913-0_5},
	abstract = {Polynomial classifiers can model decision surfaces of any shape; and yet their practical utility is limited because of the easiness with which they overfit noisy training data, and because of the sometimes impractically high number of trainable parameters. Much more popular are artificial neural networks where many simple units, called neurons, are interconnected by weighted links into larger structures of remarkably high performance.},
	language = {en},
	urldate = {2018-04-09TZ},
	booktitle = {An {Introduction} to {Machine} {Learning}},
	publisher = {Springer, Cham},
	author = {Kubat, Miroslav},
	year = {2017},
	doi = {10.1007/978-3-319-63913-0_5},
	pages = {91--111}
}

@incollection{kubat_decision_2017,
	title = {Decision {Trees}},
	isbn = {978-3-319-63912-3 978-3-319-63913-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-63913-0_6},
	abstract = {The classifiers discussed in the previous chapters expect all attribute values to be presented at the same time. Such a scenario, however, has its flaws. Thus a physician seeking to come to grips with the nature of her patient’s condition often has nothing to begin with save a few subjective symptoms. And so, to narrow the field of diagnoses, she prescribes lab tests, and, based on the results, perhaps other tests still. At any given moment, then, the doctor considers only “attributes” that promise to add meaningfully to her current information or understanding. It would be absurd to ask for all possible lab tests (thousands and thousands of them) right from the start.},
	language = {en},
	urldate = {2018-04-09TZ},
	booktitle = {An {Introduction} to {Machine} {Learning}},
	publisher = {Springer, Cham},
	author = {Kubat, Miroslav},
	year = {2017},
	doi = {10.1007/978-3-319-63913-0_6},
	pages = {113--135}
}

@incollection{kubat_genetic_2017,
	title = {The {Genetic} {Algorithm}},
	isbn = {978-3-319-63912-3 978-3-319-63913-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-63913-0_16},
	abstract = {The essence of machine learning is the search for the best solution to our problem: to find a classifier which classifies as correctly as possible not only the training examples, but also future examples. Chapter 1 explained the principle of one of the most popular AI-based search techniques, the so-called hill-climbing, and showed how it can be used in classifier induction.},
	language = {en},
	urldate = {2018-04-09TZ},
	booktitle = {An {Introduction} to {Machine} {Learning}},
	publisher = {Springer, Cham},
	author = {Kubat, Miroslav},
	year = {2017},
	doi = {10.1007/978-3-319-63913-0_16},
	pages = {309--329}
}

@misc{noauthor_university_nodate,
	title = {University of {Sydney} {Library} / {All} {Locations}},
	url = {http://opac.library.usyd.edu.au/record=3142013},
	urldate = {2018-04-09TZ}
}

@misc{noauthor_360_nodate,
	title = {360 {Link}, {University} of {Sydney} {Library}},
	url = {http://dd8gh5yx7k.search.serialssolutions.com/?ctx_ver=Z39.88-2004&ctx_enc=info%3Aofi%2Fenc%3AUTF-8&rfr_id=info%3Asid%2Fsummon.serialssolutions.com&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft.genre=article&rft.atitle=Evaluation+of+Turbulence+Models+Using+Direct+Numerical+and+Large-Eddy+Simulation+Data&rft.jtitle=Journal+of+Fluids+Engineering&rft.au=Raiesi%2C+Hassan&rft.au=Piomelli%2C+Ugo&rft.au=Pollard%2C+Andrew&rft.date=2011&rft.issn=0098-2202&rft.eissn=1528-901X&rft.volume=133&rft.issue=2&rft.spage=21203&rft_id=info:doi/10.1115%2F1.4003425&rft.externalDBID=n%2Fa&rft.externalDocID=10_1115_1_4003425&paramdict=en-AU},
	urldate = {2018-04-09TZ}
}

@article{edeling_return_2017,
	title = {A return to eddy viscosity model for epistemic {UQ} in {RANS} closures},
	url = {http://arxiv.org/abs/1705.05354},
	abstract = {For the purpose of Uncertainty Quantification (UQ) of Reynolds-Averaged Navier-Stokes closures, we introduce a framework in which perturbations in the eigenvalues of the anisotropy tensor are made in order to bound a Quantity-of-Interest based on limiting states of turbulence. To make the perturbations representative of local flow features, we introduce two additional transport equations for linear combinations of these aforementioned eigenvalues. The location, magnitude and direction of the eigenvalue perturbations are now governed by the model transport equations. The general behavior of our discrepancy model is determined by two coefficients, resulting in a low-dimensional UQ problem. We will furthermore show that the behavior of the model is intuitive and rooted in the physical interpretation of misalignment between the mean strain and Reynolds stresses.},
	urldate = {2018-04-09TZ},
	journal = {arXiv:1705.05354 [physics]},
	author = {Edeling, W. N. and Iaccarino, G. and Cinnella, P.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.05354},
	keywords = {Physics - Fluid Dynamics}
}

@article{jakirlic_extending_2015,
	series = {Theme special issue celebrating the 75th birthdays of {Brian} {Launder} and {Kemo} {Hanjalic}},
	title = {Extending the bounds of ‘steady’ {RANS} closures: {Toward} an instability-sensitive {Reynolds} stress model},
	volume = {51},
	issn = {0142-727X},
	shorttitle = {Extending the bounds of ‘steady’ {RANS} closures},
	url = {http://www.sciencedirect.com/science/article/pii/S0142727X14001180},
	doi = {10.1016/j.ijheatfluidflow.2014.09.003},
	abstract = {The incapability of the conventional Unsteady RANS (Reynolds–Averaged Navier Stokes) models to adequately capture turbulence unsteadiness presents the prime motivation of the present work, which focuses on formulating an instability-sensitive, eddy-resolving turbulence model on the Second-Moment Closure level. The model scheme adopted, functioning as a ‘sub-scale’ model in the Unsteady RANS framework, represents a differential near-wall Reynolds stress model formulated in conjunction with the scale-supplying equation governing the homogeneous part of the inverse turbulent time scale ωh (ωh=ɛh/k). The latter equation was straightforwardly obtained from the model equation describing the dynamics of the homogeneous part of the total viscous dissipation rate ɛ, defined as ɛh=ɛ−0.5ν∂2k/(∂xj∂xj) (Jakirlic and Hanjalic, 2002), by applying the derivation rules to the expression for ωh. The model capability to account for vortex length and time scales variability was enabled through an additional term in the corresponding length-scale determining equation, providing a selective enhancement of its production, pertinent particularly to the highly unsteady separated shear layer region, modeled in terms of the von Karman length scale (comprising the second derivative of the velocity field) in line with the SAS (Scale-Adaptive Simulation) proposal (Menter and Egorov, 2010). The present model formulation, termed as SRANS model (Sensitized RANS), does not comprise any parameter depending explicitly on grid spacing. The predictive capabilities of the newly proposed length-scale determining model equation, solved in conjunction with Jakirlic and Hanjalic’s (2002) Reynolds stress model equation, are presently demonstrated by computing the flow configurations of increasing complexity featured by boundary layer separation from sharp-edged and continuous curved surfaces: backward-facing step flow, flow over a wall-mounted fence, flow over smoothly contoured periodically arranged hills and flow in a 3-D diffuser. The model performances are also assessed in capturing the natural decay of the homogeneous isotropic turbulence and the near-wall Reynolds stress anisotropy in a plane channel. In most cases considered the fluctuating velocity field was obtained starting from steady RANS results.},
	urldate = {2018-04-09TZ},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Jakirlić, S. and Maduta, R.},
	month = feb,
	year = {2015},
	keywords = {2D and 3D separating flows, Fluctuating turbulence capturing model, Instability-sensitive, Reynolds stress RANS model, SAS-capable model formulation, Sensitized RANS (SRANS) framework},
	pages = {175--194}
}

@article{craft_development_1996,
	title = {Development and application of a cubic eddy-viscosity model of turbulence},
	volume = {17},
	issn = {0142-727X},
	url = {http://www.sciencedirect.com/science/article/pii/0142727X95000796},
	doi = {10.1016/0142-727X(95)00079-6},
	abstract = {Many quadratic stress-strain relations have been proposed in recent years to extend the applicability of linear eddy-viscosity models at modest computational cost. However, comparison shows that none achieves much greater width of applicability. This paper, therefore, proposes a cubic relation between the strain and vorticity tensor and the stress tensor, which does much better than a conventional eddy-viscosity scheme in capturing effects of streamline curvature over a range of flows. The flows considered range from simple shear at high strain rates and pipe flow, to flows involving strong streamline curvature and stagnation.},
	number = {2},
	urldate = {2018-04-09TZ},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Craft, T. J. and Launder, B. E. and Suga, K.},
	month = apr,
	year = {1996},
	keywords = {impinging flows, nonlinear eddy-viscosity model, streamline curvature, turbulence model},
	pages = {108--115}
}

@article{zhiyin_large-eddy_2015,
	title = {Large-eddy simulation: {Past}, present and the future},
	volume = {28},
	issn = {1000-9361},
	shorttitle = {Large-eddy simulation},
	url = {http://www.sciencedirect.com/science/article/pii/S1000936114002064},
	doi = {10.1016/j.cja.2014.12.007},
	abstract = {Large-eddy simulation (LES) was originally proposed for simulating atmospheric flows in the 1960s and has become one of the most promising and successful methodology for simulating turbulent flows with the improvement of computing power. It is now feasible to simulate complex engineering flows using LES. However, apart from the computing power, significant challenges still remain for LES to reach a level of maturity that brings this approach to the mainstream of engineering and industrial computations. This paper will describe briefly LES formalism first, present a quick glance at its history, review its current state focusing mainly on its applications in transitional flows and gas turbine combustor flows, discuss some major modelling and numerical challenges/issues that we are facing now and in the near future, and finish with the concluding remarks.},
	number = {1},
	urldate = {2018-04-08TZ},
	journal = {Chinese Journal of Aeronautics},
	author = {Zhiyin, Yang},
	month = feb,
	year = {2015},
	keywords = {Gas turbine combustor, Inflow boundary condition generation methods, Large-eddy simulation (LES), Sub-grid scale (SGS) model, Turbulent flows},
	pages = {11--24}
}

@article{smagorinsky_general_1963,
	title = {General circulation experiments with the primitive equations},
	volume = {91},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281963%29091%3C0099%3AGCEWTP%3E2.3.CO%3B2},
	doi = {10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2},
	abstract = {An extended period numerical integration of a baroclinic primitive equation model has been made for the simulation and the study of the dynamics of the atmosphere's general circulation. The solution corresponding to external gravitational propagation is filtered by requiring the vertically integrated divergence to vanish identically. The vertical structure permits as dependent variables the horizontal wind at two internal levels and a single temperature, with the static stability entering as a parameter. The incoming radiation is a function of latitude only corresponding to the annual mean, and the outgoing radiation is taken to be a function of the local temperature. With the requirement for thermal equilibrium, the domain mean temperature is specified as a parameter. The role of condensation is taken into account only as it effectively reduces the static stability. All other external sources and sinks of heat are assumed to balance each other locally, and are thus omitted. The kinematics are that of a fluid on a sphere bounded by smooth zonal walls at the equator and at approximately 64° latitude. The dissipative sinks are provided by: (a) surface stresses proportional through a drag coefficient to the square of the surface wind which is suitably extrapolated from above, (b) internal convective stresses proportional to the vertical wind shear, and (c) lateral diffusion of momentum and heat through an exchange coefficient which depends on the local horizontal rate of strain—a horizontal length scale entering as the governing parameter. For a given specification of the parameters, an integration for 60 days has been made from initial conditions where random temperature disturbances have been superimposed on a zonally symmetric regime which is baroclinically unstable according to linear theory. This experiment not only displays the scale selective character of baroclinic instability, yielding zonal wave number 5 to 6, but also predicts an index or energy cycle. The period of this cycle is 11 to 12 days for the first 40 days of the experiment, then lengthening to 17 days while diminishing in amplitude during the latter part. The resulting mean zonal velocity profile is in good qualitative agreement with observation, but too intense, presumably because the effective static stability parameter is taken too large. Furthermore this profile is found to be no more than 5 percent super-geostrophic poleward of the angular momentum maximum and no more than 2 percent sub-geostrophic equatorward. The total zonal angular momentum remains constant to within 2 percent irrespective of the phase of the index cycle. This balance is controlled by the surface wind distribution which agrees quite well with observation. The poleward transport is mainly accomplished by the large-scale eddies, whereas the internal vertical flux is predominantly a transfer of the earth's angular momentum by the meridional circulation. The poleward heat transport is primarily accomplished by a Hadley circulation at low latitudes but by the large-scale horizontal eddies in mid-latitudes, where a Ferrel circulation tends to compensate through an equatorward flux. This compensation at mid-latitudes by an indirect meridional circulation is also quite evident, in the potential-kinetic energy transformations. Comparison of the momentum and heat transfer with observed data when available shows reasonably good quantitative agreement. The lateral transfer of momentum and heat by the non-linear diffusion, which parametrically is supposed to simulate the action of motions of sub-grid scale, accounts for a significant portion of the total eddy transfer. Although no direct comparison with the corresponding transfer in the real atmosphere is available, intuitively our small-scale diffusion appears to play too large a role. A diagnosis is made of the transformations among the baratropic and baroclinic parts of the kinetic energy as well as the zonal mean and zonal perturbation parts of the available potential and kinetic energy. This reveals the dominant paths that the energy passes through from source to ultimate sinks and the processes responsible for these transformations. It is found that the partitioning of dissipation by the energy components may differ considerably from estimates made from observation.},
	number = {3},
	urldate = {2018-04-08TZ},
	journal = {Monthly Weather Review},
	author = {Smagorinsky, J.},
	month = mar,
	year = {1963},
	pages = {99--164}
}

@article{verstappen_direct_1997,
	title = {Direct {Numerical} {Simulation} of {Turbulence} at {Lower} {Costs}},
	volume = {32},
	issn = {0022-0833, 1573-2703},
	url = {https://link-springer-com.ezproxy1.library.usyd.edu.au/article/10.1023/A:1004255329158},
	doi = {10.1023/A:1004255329158},
	abstract = {Direct Numerical Simulation (DNS) is the most accurate, but also the most expensive, way of computing turbulent flow. To cut the costs of DNS we consider a family of second-order, explicit one-leg time-integration methods and look for the method with the best linear stability properties. It turns out that this method requires about two times less computational effort than Adams–Bashforth. Next, we discuss a fourth-order finite-volume method that is constructed as the Richardson extrapolate of a classical second-order method. We compare the results of this fourth-order method and the underlying second-order method for a DNS of the flow in a cubical driven cavity at Re= 104. Experimental results are available for comparison. For this example, the fourth-order results are clearly superior to the second-order results, whereas their computational effort is about twenty times less. With the improved simulation method, a DNS of a turbulent flow in a cubical lid-driven flow at Re = 50,000 and a DNS of a turbulent flow past a square cylinder at Re = 22,000 are performed.},
	language = {en},
	number = {2-3},
	urldate = {2018-04-08TZ},
	journal = {Journal of Engineering Mathematics},
	author = {Verstappen, R. W. C. P. and Veldman, A. E. P.},
	month = oct,
	year = {1997},
	pages = {143--159}
}

@article{kolmogorov_local_1991,
	title = {The {Local} {Structure} of {Turbulence} in {Incompressible} {Viscous} {Fluid} for {Very} {Large} {Reynolds} {Numbers}},
	volume = {434},
	issn = {0962-8444},
	url = {http://www.jstor.org.ezproxy1.library.usyd.edu.au/stable/51980},
	number = {1890},
	urldate = {2018-04-08TZ},
	journal = {Proceedings: Mathematical and Physical Sciences},
	author = {Kolmogorov, A. N.},
	year = {1991},
	pages = {9--13}
}

@techreport{hedlund_evaluation_2014,
	title = {Evaluation of {RANS} turbulence models for the simulation of channel flow},
	url = {http://www.diva-portal.org/smash/get/diva2:771689/FULLTEXT01.pdf},
	abstract = {The objective of this report is to investigate how
RANS models perform on fully developed channel
flow, for Re = 13 350, and the simulations are made
with the open source software OpenFOAM. The
velocity and turbulent kinetic energy profiles are
compared with previously published DNS results. A
short introduction to turbulence modelling is
presented with focus on channel flow and the
boundary layer. In total eleven models are
evaluated, and the results are of varying quality. A
convergence study is presented for two models,
and reveals that the expected second order
convergence is fulfilled for one of them, whereas the
study for the other model is more ambiguous
without a clear conclusion. The OpenFOAM case
setups for each model and the results gathered
from the simulations are publicly available.},
	institution = {Institutionen för teknikvetenskaper},
	author = {Hedlund, André},
	month = dec,
	year = {2014}
}

@article{hedlund_evaluation_nodate,
	title = {Evaluation of {RANS} turbulence models for the simulation of channel flow},
	abstract = {The objective of this report is to investigate how
RANS models perform on fully developed channel
flow, for Re = 13 350, and the simulations are made
with the open source software OpenFOAM. The
velocity and turbulent kinetic energy profiles are
compared with previously published DNS results. A
short introduction to turbulence modelling is
presented with focus on channel flow and the
boundary layer. In total eleven models are
evaluated, and the results are of varying quality. A
convergence study is presented for two models,
and reveals that the expected second order
convergence is fulfilled for one of them, whereas the
study for the other model is more ambiguous
without a clear conclusion. The OpenFOAM case
setups for each model and the results gathered
from the simulations are publicly available.},
	author = {Hedlund, André}
}

@article{zhou_3-d_2009,
	title = {3-{D} hybrid {LES}-{RANS} model for simulation of open-channel {T}-diversion flows},
	volume = {2},
	issn = {1674-2370},
	url = {http://www.sciencedirect.com/science/article/pii/S1674237015300715},
	doi = {10.3882/j.issn.1674-2370.2009.03.002},
	abstract = {The study of flow diversions in open channels plays an important practical role in the design and management of open-channel networks for irrigation or drainage. To accurately predict the mean flow and turbulence characteristics of open-channel dividing flows, a hybrid LES-RANS model, which combines the large eddy simulation (LES) model with the Reynolds-averaged Navier-Stokes (RANS) model, is proposed in the present study. The unsteady RANS model was used to simulate the upstream and downstream regions of a main channel, as well as the downstream region of a branch channel. The LES model was used to simulate the channel diversion region, where turbulent flow characteristics are complicated. Isotropic velocity fluctuations were added at the inflow interface of the LES region to trigger the generation of resolved turbulence. A method based on the virtual body force is proposed to impose Reynolds-averaged velocity fields near the outlet of the LES region in order to take downstream flow effects computed by the RANS model into account and dissipate the excessive turbulent fluctuations. This hybrid approach saves computational effort and makes it easier to properly specify inlet and outlet boundary conditions. Comparison between computational results and experimental data indicates that this relatively new modeling approach can accurately predict open-channel T -diversion flows.},
	number = {3},
	urldate = {2018-03-30TZ},
	journal = {Water Science and Engineering},
	author = {Zhou, Jie and Zeng, Cheng},
	month = sep,
	year = {2009},
	keywords = {T-diversion, hybrid LES-RANS model, open-channel flow, turbulence modeling},
	pages = {13--26}
}

@article{zhou_3-d_2009-1,
	title = {3-{D} hybrid {LES}-{RANS} model for simulation of open-channel {T}-diversion flows},
	volume = {2},
	issn = {1674-2370},
	url = {http://www.sciencedirect.com/science/article/pii/S1674237015300715},
	doi = {10.3882/j.issn.1674-2370.2009.03.002},
	abstract = {The study of flow diversions in open channels plays an important practical role in the design and management of open-channel networks for irrigation or drainage. To accurately predict the mean flow and turbulence characteristics of open-channel dividing flows, a hybrid LES-RANS model, which combines the large eddy simulation (LES) model with the Reynolds-averaged Navier-Stokes (RANS) model, is proposed in the present study. The unsteady RANS model was used to simulate the upstream and downstream regions of a main channel, as well as the downstream region of a branch channel. The LES model was used to simulate the channel diversion region, where turbulent flow characteristics are complicated. Isotropic velocity fluctuations were added at the inflow interface of the LES region to trigger the generation of resolved turbulence. A method based on the virtual body force is proposed to impose Reynolds-averaged velocity fields near the outlet of the LES region in order to take downstream flow effects computed by the RANS model into account and dissipate the excessive turbulent fluctuations. This hybrid approach saves computational effort and makes it easier to properly specify inlet and outlet boundary conditions. Comparison between computational results and experimental data indicates that this relatively new modeling approach can accurately predict open-channel T -diversion flows.},
	number = {3},
	urldate = {2018-03-30TZ},
	journal = {Water Science and Engineering},
	author = {Zhou, Jie and Zeng, Cheng},
	month = sep,
	year = {2009},
	keywords = {T-diversion, hybrid LES-RANS model, open-channel flow, turbulence modeling},
	pages = {13--26}
}

@article{maulik_neural_2017,
	title = {A neural network approach for the blind deconvolution of turbulent flows},
	volume = {831},
	issn = {0022-1120, 1469-7645},
	url = {http://arxiv.org/abs/1706.00912},
	doi = {10.1017/jfm.2017.637},
	abstract = {We present a single-layer feedforward artificial neural network architecture trained through a supervised learning approach for the deconvolution of flow variables from their coarse grained computations such as those encountered in large eddy simulations. We stress that the deconvolution procedure proposed in this investigation is blind, i.e. the deconvolved field is computed without any pre-existing information about the filtering procedure or kernel. This may be conceptually contrasted to the celebrated approximate deconvolution approaches where a filter shape is predefined for an iterative deconvolution process. We demonstrate that the proposed blind deconvolution network performs exceptionally well in the a-priori testing of both two-dimensional Kraichnan and three-dimensional Kolmogorov turbulence and shows promise in forming the backbone of a physics-augmented data-driven closure for the Navier-Stokes equations.},
	urldate = {2018-03-26TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Maulik, Romit and San, Omer},
	month = nov,
	year = {2017},
	note = {arXiv: 1706.00912},
	pages = {151--181}
}

@article{wang_generic_2017,
	title = {A {Generic} {Test} {Suite} for {Evolutionary} {Multi}-{Fidelity} {Optimization}},
	volume = {PP},
	issn = {1089-778X},
	doi = {10.1109/TEVC.2017.2758360},
	abstract = {Many real-world optimization problems involve computationally intensive numerical simulations to accurately evaluate the quality of solutions. Usually the fidelity of the simulations can be controlled using certain parameters and there is a trade-off between simulation fidelity and computational cost, i.e., the higher the fidelity, the more complex the simulation will be. To reduce the computational time in simulation-driven optimization, it is a common practice to use multiple fidelity levels in search for the optimal solution. So far, not much work has been done in evolutionary optimization that considers multiple fidelity levels in fitness evaluations. In this work, we aim to develop test suites that are able to capture some important characteristics in real-world multi-fidelity optimization, thereby offering a useful benchmark for developing evolutionary algorithms for multi-fidelity optimization. To demonstrate the usefulness of the proposed test suite, three strategies for adapting the fidelity level of the test problems during optimization are suggested and embedded in a particle swarm optimization algorithm. Our simulation results indicate that the use of changing fidelity is able to enhance the performance and reduce the computational cost of the particle swarm optimization, which is desired in solving expensive optimization problems.},
	number = {99},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Wang, H. and Jin, Y. and Doherty, J.},
	year = {2017},
	pages = {1--1}
}

@misc{noauthor_development_nodate,
	title = {The development of algebraic stress models using a novel evolutionary algorithm - {ScienceDirect}},
	url = {https://www-sciencedirect-com.ezproxy1.library.usyd.edu.au/science/article/pii/S0142727X17303223},
	urldate = {2018-01-31TZ}
}

@article{weatheritt_machine_2017-1,
	title = {Machine {Learning} for {Turbulence} {Model} {Development} {Using} a {High}-{Fidelity} {HPT} {Cascade} {Simulation}},
	url = {http://dx.doi.org/10.1115/GT2017-63497},
	doi = {10.1115/GT2017-63497},
	abstract = {The validity of the Boussinesq approximation in the wake behind a high-pressure turbine blade is explored. We probe the mathematical assumptions of such a relationship by employing a least-squares technique. Next, we use an evolutionary algorithm to modify the anisotropy tensor a priori using highly resolved LES data. In the latter case we build a non-linear stress-strain relationship. Results show that the standard eddy-viscosity assumption underpredicts turbulent diffusion and is theoretically invalid. By increasing the coefficient of the linear term, the farwake prediction shows minor improvement. By using additional non-linear terms in the stress-strain coupling relationship, created by the evolutionary algorithm, the near-wake can also be improved upon. Terms created by the algorithm are scrutinized and the discussion is closed by suggesting a tentative non-linear expression for the Reynolds stress, suitable for the wake behind a high-pressure turbine blade.},
	urldate = {2018-01-31TZ},
	author = {Weatheritt, Jack and Pichler, Richard and Sandberg, Richard D. and Laskowski, Gregory and Michelassi, Vittorio},
	month = jun,
	year = {2017},
	pages = {V02BT41A015}
}
@article{durbin_recent_2018,
	title = {Some {Recent} {Developments} in {Turbulence} {Closure} {Modeling}},
	volume = {50},
	url = {https://doi.org/10.1146/annurev-fluid-122316-045020},
	doi = {10.1146/annurev-fluid-122316-045020},
	abstract = {Turbulence closure models are central to a good deal of applied computational fluid dynamical analysis. Closure modeling endures as a productive area of research. This review covers recent developments in elliptic relaxation and elliptic blending models, unified rotation and curvature corrections, transition prediction, hybrid simulation, and data-driven methods. The focus is on closure models in which transport equations are solved for scalar variables, such as the turbulent kinetic energy, a timescale, or a measure of anisotropy. Algebraic constitutive representations are reviewed for their role in relating scalar closures to the Reynolds stress tensor. Seamless and nonzonal methods, which invoke a single closure model, are reviewed, especially detached eddy simulation (DES) and adaptive DES. Other topics surveyed include data-driven modeling and intermittency and laminar fluctuation models for transition prediction. The review concludes with an outlook.},
	number = {1},
	urldate = {2018-01-30TZ},
	journal = {Annual Review of Fluid Mechanics},
	author = {Durbin, Paul A.},
	year = {2018},
	pages = {77--103}
}

@misc{noauthor_notitle_nodate
}

@article{singh_machine-learning-augmented_2017,
	title = {Machine-{Learning}-{Augmented} {Predictive} {Modeling} of {Turbulent} {Separated} {Flows} over {Airfoils}},
	volume = {55},
	issn = {0001-1452},
	url = {https://doi.org/10.2514/1.J055595},
	doi = {10.2514/1.J055595},
	abstract = {A modeling paradigm is developed to augment predictive models of turbulence by effectively using limited data generated from physical experiments. The key components of the current approach involve inverse modeling to infer the spatial distribution of model discrepancies and machine learning to reconstruct discrepancy information from a large number of inverse problems into corrective model forms. The methodology is applied to turbulent flows over airfoils involving flow separation. Model augmentations are developed for the Spalart–Allmaras model using adjoint-based full-field inference on experimentally measured lift coefficient data. When these model forms are reconstructed using neural networks and embedded within a standard solver, it is shown that much improved predictions in lift can be obtained for geometries and flow conditions that were not used to train the model. The neural-network-augmented Spalart–Allmaras model also predicts surface pressures extremely well. Portability of this approach is demonstrated by confirming that predictive improvements are preserved when the augmentation is embedded in a different commercial, finite element solver. The broader vision is that, by incorporating data that can reveal the form of the innate model discrepancy, the applicability of data-driven turbulence models can be extended to more general flows.},
	number = {7},
	urldate = {2017-12-27TZ},
	journal = {AIAA Journal},
	author = {Singh, Anand Pratap and Medida, Shivaji and Duraisamy, Karthik},
	year = {2017},
	pages = {2215--2227}
}

@misc{noauthor_johns_nodate,
	title = {Johns {Hopkins} {Turbulence} {Databases} ({JHTDB})},
	url = {http://turbulence.pha.jhu.edu/},
	urldate = {2017-12-27TZ}
}

@article{xiao_quantifying_2016,
	title = {Quantifying and reducing model-form uncertainties in {Reynolds}-averaged {Navier}–{Stokes} simulations: {A} data-driven, physics-informed {Bayesian} approach},
	volume = {324},
	issn = {0021-9991},
	shorttitle = {Quantifying and reducing model-form uncertainties in {Reynolds}-averaged {Navier}–{Stokes} simulations},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999116303394},
	doi = {10.1016/j.jcp.2016.07.038},
	abstract = {Despite their well-known limitations, Reynolds-Averaged Navier–Stokes (RANS) models are still the workhorse tools for turbulent flow simulations in today's engineering analysis, design and optimization. While the predictive capability of RANS models depends on many factors, for many practical flows the turbulence models are by far the largest source of uncertainty. As RANS models are used in the design and safety evaluation of many mission-critical systems such as airplanes and nuclear power plants, quantifying their model-form uncertainties has significant implications in enabling risk-informed decision-making. In this work we develop a data-driven, physics-informed Bayesian framework for quantifying model-form uncertainties in RANS simulations. Uncertainties are introduced directly to the Reynolds stresses and are represented with compact parameterization accounting for empirical prior knowledge and physical constraints (e.g., realizability, smoothness, and symmetry). An iterative ensemble Kalman method is used to assimilate the prior knowledge and observation data in a Bayesian framework, and to propagate them to posterior distributions of velocities and other Quantities of Interest (QoIs). We use two representative cases, the flow over periodic hills and the flow in a square duct, to evaluate the performance of the proposed framework. Both cases are challenging for standard RANS turbulence models. Simulation results suggest that, even with very sparse observations, the obtained posterior mean velocities and other QoIs have significantly better agreement with the benchmark data compared to the baseline results. At most locations the posterior distribution adequately captures the true model error within the developed model form uncertainty bounds. The framework is a major improvement over existing black-box, physics-neutral methods for model-form uncertainty quantification, where prior knowledge and details of the models are not exploited. This approach has potential implications in many fields in which the governing equations are well understood but the model uncertainty comes from unresolved physical processes.},
	number = {Supplement C},
	urldate = {2017-12-24TZ},
	journal = {Journal of Computational Physics},
	author = {Xiao, H. and Wu, J. -L. and Wang, J. -X. and Sun, R. and Roy, C. J.},
	month = nov,
	year = {2016},
	pages = {115--136}
}

@article{wang_physics_2017,
	title = {A {Physics} {Informed} {Machine} {Learning} {Approach} for {Reconstructing} {Reynolds} {Stress} {Modeling} {Discrepancies} {Based} on {DNS} {Data}},
	volume = {2},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/1606.07987},
	doi = {10.1103/PhysRevFluids.2.034603},
	abstract = {Turbulence modeling is a critical component in numerical simulations of industrial flows based on Reynolds-averaged Navier-Stokes (RANS) equations. However, after decades of efforts in the turbulence modeling community, universally applicable RANS models with predictive capabilities are still lacking. Recently, data-driven methods have been proposed as a promising alternative to the traditional approaches of turbulence model development. In this work we propose a data-driven, physics-informed machine learning approach for predicting discrepancies in RANS modeled Reynolds stresses. The discrepancies are formulated as functions of the mean flow features. By using a modern machine learning technique based on random forests, the discrepancy functions are first trained with benchmark flow data and then used to predict Reynolds stresses discrepancies in new flows. The method is used to predict the Reynolds stresses in the flow over periodic hills by using two training flow scenarios of increasing difficulties: (1) the flow in the same periodic hills geometry yet at a lower Reynolds number, and (2) the flow in a different hill geometry with a similar recirculation zone. Excellent predictive performances were observed in both scenarios, demonstrating the merits of the proposed method. Improvement of RANS modeled Reynolds stresses enabled by the proposed method is an important step towards predictive turbulence modeling, where the ultimate goal is to predict the quantities of interest (e.g., velocity field, drag, lift) more accurately by solving RANS equations with the Reynolds stresses obtained therefrom.},
	number = {3},
	urldate = {2017-12-24TZ},
	journal = {Physical Review Fluids},
	author = {Wang, Jian-Xun and Wu, Jin-Long and Xiao, Heng},
	month = mar,
	year = {2017},
	note = {arXiv: 1606.07987}
}

@misc{hennigh_computational-physics-and-machine-learning-reading-list:_2017,
	title = {Computational-{Physics}-and-{Machine}-{Learning}-{Reading}-{List}: {A} list of papers relating {Computational} {Physics} and {Machine} {Learning}},
	shorttitle = {Computational-{Physics}-and-{Machine}-{Learning}-{Reading}-{List}},
	url = {https://github.com/loliverhennigh/Computational-Physics-and-Machine-Learning-Reading-List},
	urldate = {2017-12-24TZ},
	author = {Hennigh, Oliver},
	month = nov,
	year = {2017},
	note = {original-date: 2017-08-18T19:56:35Z}
}

@article{milani_machine_2017,
	title = {A {Machine} {Learning} {Approach} for {Determining} the {Turbulent} {Diffusivity} in {Film} {Cooling} {Flows}},
	volume = {140},
	issn = {0889-504X},
	url = {http://dx.doi.org/10.1115/1.4038275},
	doi = {10.1115/1.4038275},
	abstract = {In film cooling flows, it is important to know the temperature distribution resulting from the interaction between a hot main flow and a cooler jet. However, current Reynolds-averaged Navier–Stokes (RANS) models yield poor temperature predictions. A novel approach for RANS modeling of the turbulent heat flux is proposed, in which the simple gradient diffusion hypothesis (GDH) is assumed and a machine learning (ML) algorithm is used to infer an improved turbulent diffusivity field. This approach is implemented using three distinct data sets: two are used to train the model and the third is used for validation. The results show that the proposed method produces significant improvement compared to the common RANS closure, especially in the prediction of film cooling effectiveness.},
	number = {2},
	urldate = {2017-12-24TZ},
	journal = {Journal of Turbomachinery},
	author = {Milani, Pedro M. and Ling, Julia and Saez-Mischlich, Gonzalo and Bodart, Julien and Eaton, John K.},
	month = dec,
	year = {2017},
	pages = {021006--021006--8}
}

@book{wu_priori_2017,
	title = {A {Priori} {Assessment} of {Prediction} {Confidence} for {Data}-{Driven} {Turbulence} {Modeling}},
	volume = {99},
	abstract = {Although Reynolds-Averaged Navier–Stokes (RANS) equations are still the dominant tool for engineering design and analysis applications involving turbulent flows, standard RANS models are known to be unreliable in many flows of engineering relevance, including flows with separation, strong pressure gradients or mean flow curvature. With increasing amounts of 3-dimensional experimental data and high fidelity simulation data from Large Eddy Simulation (LES) and Direct Numerical Simulation (DNS), data-driven turbulence modeling has become a promising approach to increase the predictive capability of RANS simulations. However, the prediction performance of data-driven models inevitably depends on the choices of training flows. This work aims to identify a quantitative measure for a priori estimation of prediction confidence in data-driven turbulence modeling. This measure represents the distance in feature space between the training flows and the flow to be predicted. Specifically, the Mahalanobis distance and the kernel density estimation (KDE) technique are used as metrics to quantify the distance between flow data sets in feature space. To examine the relationship between these two extrapolation metrics and the machine learning model prediction performance, the flow over periodic hills at Re = 10595 is used as test set and seven flows with different configurations are individually used as training sets. The results show that the prediction error of the Reynolds stress anisotropy is positively correlated with Mahalanobis distance and KDE distance, demonstrating that both extrapolation metrics can be used to estimate the prediction confidence a priori. A quantitative comparison using correlation coefficients shows that the Mahalanobis distance is less accurate in estimating the prediction confidence than KDE distance. The extrapolation metrics introduced in this work and the corresponding analysis provide an approach to aid in the choice of data source and to assess the prediction performance for data-driven turbulence modeling.},
	author = {Wu, Jinlong and Wang, Jianxun and Xiao, Heng and Ling, Julia},
	month = mar,
	year = {2017},
	doi = {10.1007/s10494-017-9807-0}
}

@article{p._miyanawala_efficient_2017,
	title = {An {Efficient} {Deep} {Learning} {Technique} for the {Navier}-{Stokes} {Equations}: {Application} to {Unsteady} {Wake} {Flow} {Dynamics}},
	shorttitle = {An {Efficient} {Deep} {Learning} {Technique} for the {Navier}-{Stokes} {Equations}},
	abstract = {We present an efficient deep learning technique for the model reduction of the Navier-Stokes equations for unsteady flow problems. The proposed technique relies on the Convolutional Neural Network (CNN) and the stochastic gradient decent method.Of particular interest is to predict the unsteady fluid forces for different bluff body shapes at low Reynolds number. The discrete convolution process with a non-linear rectification is employed to approximate the mapping between the bluff-body shape and the fluid forces. The deep neural network is fed by the Euclidean distance function as the input and the target data generated by the full-order Navier-Stokes computations for primitive bluff body shapes. The convolutional networks are iteratively trained using the stochastic gradient descent method with the momentum term to predict the fluid force coefficients of different geometries and the results are compared with the full-order computations. We also attempt to provide a physical analogy of the stochastic gradient method with the momentum term with the simplified form of the incompressible Navier-Stokes momentum equation. A systematic convergence and sensitivity study is performed to identify the effective dimensions of the deep-learned CNN process such as the convolution kernel size, the number of kernels and the convolution layers. Within the error threshold, the prediction based on our deep convolutional network has a speed-up nearly three orders of magnitude compared to the full-order results and consumes an insignificant fraction of computational resources. The proposed CNN-based approximation procedure has a profound impact on the parametric design of bluff bodies and the feedback control of separated flows.},
	author = {P. Miyanawala, Tharindu and Jaiman, R.K.},
	month = oct,
	year = {2017}
}

@article{maulik_neural_2017,
	title = {A neural network approach for the blind deconvolution of turbulent flows},
	volume = {831},
	issn = {0022-1120, 1469-7645},
	url = {http://arxiv.org/abs/1706.00912},
	doi = {10.1017/jfm.2017.637},
	abstract = {We present a single-layer feedforward artificial neural network architecture trained through a supervised learning approach for the deconvolution of flow variables from their coarse grained computations such as those encountered in large eddy simulations. We stress that the deconvolution procedure proposed in this investigation is blind, i.e. the deconvolved field is computed without any pre-existing information about the filtering procedure or kernel. This may be conceptually contrasted to the celebrated approximate deconvolution approaches where a filter shape is predefined for an iterative deconvolution process. We demonstrate that the proposed blind deconvolution network performs exceptionally well in the a-priori testing of both two-dimensional Kraichnan and three-dimensional Kolmogorov turbulence and shows promise in forming the backbone of a physics-augmented data-driven closure for the Navier-Stokes equations.},
	urldate = {2017-12-24TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Maulik, Romit and San, Omer},
	month = nov,
	year = {2017},
	note = {arXiv: 1706.00912},
	pages = {151--181}
}

@incollection{zhang_machine_nodate,
	title = {Machine {Learning} {Methods} for {Data}-{Driven} {Turbulence} {Modeling}},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2015-2460},
	urldate = {2017-12-23TZ},
	booktitle = {22nd {AIAA} {Computational} {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Zhang, Ze Jia and Duraisamy, Karthikeyan},
	doi = {10.2514/6.2015-2460}
}

@article{hanna_coarse-grid_2017,
	title = {Coarse-{Grid} {Computational} {Fluid} {Dynamic} ({CG}-{CFD}) {Error} {Prediction} using {Machine} {Learning}},
	url = {https://arxiv.org/abs/1710.09105},
	urldate = {2017-12-23TZ},
	author = {Hanna, Botros N. and Dinh, Nam T. and Youngblood, Robert W. and Bolotnov, Igor A.},
	month = oct,
	year = {2017}
}

@article{kasiviswanathan_quantification_2013,
	title = {Quantification of the predictive uncertainty of artificial neural network based river flow forecast models},
	volume = {27},
	issn = {1436-3240, 1436-3259},
	url = {https://link.springer.com/article/10.1007/s00477-012-0600-2},
	doi = {10.1007/s00477-012-0600-2},
	abstract = {The meaningful quantification of uncertainty in hydrological model outputs is a challenging task since complete knowledge about the hydrologic system is still lacking. Owing to the nonlinearity and complexity associated with the hydrological processes, Artificial neural network (ANN) based models have gained lot of attention for its effectiveness in function approximation characteristics. However, only a few studies have been reported for assessment of uncertainty associated with ANN outputs. This study uses a simple method for quantifying predictive uncertainty of ANN model output through first order Taylor series expansion. The first order partial differential equations of non-linear function approximated by the ANN with respect to weights and biases of the ANN model are derived. A bootstrap technique is employed in estimating the values of the mean and the standard deviation of ANN parameters, and is used to quantify the predictive uncertainty. The method is demonstrated through the case study of Upper White watershed located in the United States. The quantitative assessment of uncertainty is carried out with two measures such as percentage of coverage and average width. In order to show the magnitude of uncertainty in different flow domains, the values are statistically categorized into low-, medium- and high-flow series. The results suggest that the uncertainty bounds of ANN outputs can be effectively quantified using the proposed method. It is observed that the level of uncertainty is directly proportional to the magnitude of the flow and hence varies along time. A comparison of the uncertainty assessment shows that the proposed method effectively quantifies the uncertainty than bootstrap method.},
	language = {en},
	number = {1},
	urldate = {2017-12-23TZ},
	journal = {Stochastic Environmental Research and Risk Assessment},
	author = {Kasiviswanathan, K. S. and Sudheer, K. P.},
	month = jan,
	year = {2013},
	pages = {137--146}
}

@article{huo_integrated_2012,
	title = {Integrated neural networks for monthly river flow estimation in arid inland basin of {Northwest} {China}},
	volume = {420-421},
	issn = {0022-1694},
	url = {http://www.sciencedirect.com/science/article/pii/S0022169411008390},
	doi = {10.1016/j.jhydrol.2011.11.054},
	abstract = {Streamflow model including rainfall–runoff and river flow models play an important role in water resources management, especially in arid inland area. Traditional conceptual models have the disadvantage of requirement of spatial variation parameters about the physical characteristics of the catchments. To overcome this difficulty, in this study, several integrated Artificial Neural Networks (ANNs) were presented to estimate monthly river flow, and the models include the semi-distributed forms of ANNs that can explore spatial variation in hydrological process (such as rainfall distribution and evaporation distribution) and no requirement of physical characteristic parameters of the catchments. In an arid inland basin of Northwest, integrated ANNs were developed using hydrological and agricultural data, and its performance was compared with that of lumped ANN and local linear regression model (LLR). Results showed that the integrated ANNs perform well to estimate the monthly streamflow at outlet of mountain with Root Mean Square Error (RMSE) of 0.36×107m3 and Relative Error (RE) of 9\%. Similarly, the integrated ANNs can also accurately estimate the monthly river flow downstream of the basin with RMSE of 0.35–0.38×107m3 and RE of 22–27\%. When compared with integrated ANNs, the lumped ANN and LLR models have lower precision to simulate monthly streamflow in arid inland basin. Presented integrated ANN models retain the advantages of the semi-distributed models considering the heterogeneity and spatial variation of hydrological factors and the physical characteristics in the catchment, while taking advantage of the potential of ANNs as an effective tool in nonlinear mapping or functional relationship establishment. In contrast to traditional models either in the lumped ANN or in empirical regression forms, the new approach of integration of Artificial Neural Networks has shown great potential in streamflow modeling.},
	number = {Supplement C},
	urldate = {2017-12-23TZ},
	journal = {Journal of Hydrology},
	author = {Huo, Zailin and Feng, Shaoyuan and Kang, Shaozhong and Huang, Guanhua and Wang, Fengxin and Guo, Ping},
	month = feb,
	year = {2012},
	pages = {159--170}
}

@article{anupindi_implementation_2017,
	title = {Implementation and {Evaluation} of an {Embedded} {LES}-{RANS} {Solver}},
	volume = {98},
	issn = {1386-6184, 1573-1987},
	url = {https://link.springer.com/article/10.1007/s10494-016-9787-5},
	doi = {10.1007/s10494-016-9787-5},
	abstract = {In the current work, we present the development and application of an embedded large-eddy simulation (LES) - Reynolds-averaged Navier Stokes (RANS) solver. The novelty of the present work lies in fully embedding the LES region inside a global RANS region through an explicit coupling at the arbitrary mesh interfaces, exchanging flow and turbulence quantities. In particular, a digital filter method (DFM) extracting mean flow, turbulent kinetic energy and Reynolds stress profiles from the RANS region is used to provide meaningful turbulent fluctuations to the LES region. The framework is developed in the open-source computational fluid dynamics software OpenFOAM. The embedding approach is developed and validated by simulating a spatially developing turbulent channel flow. Thereafter, flow over a surface mounted spanwise-periodic vertical fence is simulated to demonstrate the importance of the DFM and the effect of the location of the RANS-LES interface. Mean and second-order statistics are compared with direct numerical simulation (DNS) data from the literature. Results indicate that feeding synthetic turbulence at the LES interface is essential to achieve good agreement for the mean flow quantities. However, in order to obtain a good match for the Reynolds stresses, the LES interface needs to be placed sufficiently far upstream, which in the present case was six spoiler heights before the fence. Further, a realistic spoiler configuration with finite-width in the spanwise direction and inclined at 30 degrees was simulated using the embedding approach. As opposed to the vertical fence case this is a genuinely (statistically) three-dimensional case and a very good match with mean and second-order statistics was obtained with the experimental data. Finally, in order to test the present solver for high sub-sonic speed flows the flow over an open cavity was simulated. A good match with reference data is obtained for mean and turbulence profile comparisons. Tones in the pressure spectra were predicted reasonably well and an overall sound pressure level with a maximum deviation of 2.6 dB was obtained with the present solver when compared with the experimental data.},
	language = {en},
	number = {3},
	urldate = {2017-12-23TZ},
	journal = {Flow, Turbulence and Combustion},
	author = {Anupindi, Kameswararao and Sandberg, Richard D.},
	month = apr,
	year = {2017},
	pages = {697--724}
}

@article{weatheritt_comparative_2017,
	title = {A {Comparative} {Study} of {Contrasting} {Machine} {Learning} {Frameworks} {Applied} to {RANS} {Modeling} of {Jets} in {Crossflow}},
	url = {http://dx.doi.org/10.1115/GT2017-63403},
	doi = {10.1115/GT2017-63403},
	abstract = {Classical RANS turbulence models have known deficiencies when applied to jets in crossflow. Identifying the linear Boussinesq stress-strain hypothesis as a major contribution to erroneous prediction, we consider and contrast two machine learning frameworks for turbulence model development. Gene Expression Programming, an evolutionary algorithm that employs a survival of the fittest analogy, and a Deep Neural Network, based on neurological processing, add non-linear terms to the stress-strain relationship. The results are Explicit Algebraic Stress Model-like closures. High fidelity data from an inline jet in crossflow study is used to regress new closures. These models are then tested on a skewed jet to ascertain their predictive efficacy. For both methodologies, a vast improvement over the linear relationship is observed.},
	urldate = {2017-12-23TZ},
	author = {Weatheritt, Jack and Sandberg, Richard D. and Ling, Julia and Saez, Gonzalo and Bodart, Julien},
	month = jun,
	year = {2017},
	pages = {V02BT41A012}
}

@article{weatheritt_development_2017,
	title = {The development of algebraic stress models using a novel evolutionary algorithm},
	volume = {68},
	issn = {0142-727X},
	url = {http://www.sciencedirect.com/science/article/pii/S0142727X17303223},
	doi = {10.1016/j.ijheatfluidflow.2017.09.017},
	abstract = {This work presents developments to a novel evolutionary framework that symbolically regresses algebraic forms of the Reynolds stress anisotropy tensor. This work contributes to the growing trend in machine-learning for modelling physical phenomena. Our framework is shown to be computational inexpensive and produce accurate and robust models that are tangible mathematical expressions. This transparency in the result allows us to diagnose issues with the regressed formulae and appropriately make amendments, as we further understand the regression tools. Such models are created using hybrid RANS/LES flow field data and a passive solving of the RANS transport equations to obtain the modelled time scale. This process shows that models can be regressed from a qualitatively correct flow field and fully resolved DNS is not necessarily required. Models are trained and tested using rectangular ducts, an example flow genus that linear RANS models even qualitatively fail to predict correctly. A priori and a posteriori testing of the new models show that the framework is a viable methodology for RANS closure development. This a posteriori agenda includes testing on an asymmetric diffuser, for which the new models vastly outperform the baseline linear model. Therefore this study presents one of the most rigorous and complete CFD validation of machine learnt turbulent stress models to date.},
	number = {Supplement C},
	urldate = {2017-12-23TZ},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Weatheritt, J. and Sandberg, R. D.},
	month = dec,
	year = {2017},
	pages = {298--318}
}

@incollection{sandberg_large-scale_2018,
	series = {{ERCOFTAC} {Series}},
	title = {Large-{Scale} {Compressible}-{Flow} {Direct} {Numerical} {Simulations}},
	isbn = {978-3-319-63211-7 978-3-319-63212-4},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-63212-4_3},
	abstract = {Direct numerical simulation (DNS) of turbulent flows began in the early 1970s with the study of incompressible isotropic turbulence by Orszag and Patterson (Phys Rev Lett 28(2), 76–79, 1972) [8], and compressible DNS were not conducted until the 1980s.},
	language = {en},
	urldate = {2017-12-23TZ},
	booktitle = {Direct and {Large}-{Eddy} {Simulation} {X}},
	publisher = {Springer, Cham},
	author = {Sandberg, R. D.},
	year = {2018},
	doi = {10.1007/978-3-319-63212-4_3},
	pages = {25--33}
}

@article{williamson_transition_2015,
	title = {Transition to stably stratified states in open channel flow with radiative surface heating},
	volume = {766},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/transition-to-stably-stratified-states-in-open-channel-flow-with-radiative-surface-heating/01DA699EAC6884E413574D04C38D97AA},
	doi = {10.1017/jfm.2014.711},
	abstract = {Abstract
Direct numerical simulations (DNS) of turbulent stratified flow in an open channel with an internal heat source following the Beer–Lambert law from the surface are used to investigate the transition from neutral to strongly stable flow. Our buoyancy bulk parameter is defined through the ratio of the domain height 


\$\{{\textbackslash}it{\textbackslash}delta\}\$

 to 


\${\textbackslash}mathscr\{L\}\$

, a bulk Obukhov length scale for the flow. We cover the range 


\$\{{\textbackslash}it{\textbackslash}lambda\}=\{{\textbackslash}it{\textbackslash}delta\}/{\textbackslash}mathscr\{L\}=0\{-\}2.0\$

, from neutral conditions to the onset of the stable regime, with the Reynolds number range 


\$Re\_\{\{{\textbackslash}it{\textbackslash}tau\}\}=200\{-\}800\$

, at a Prandtl number of 0.71. The result is a boundary layer flow where the effects of stratification are weak in the wall region but progressively stronger in the outer layer up to the free surface. At 


\$\{{\textbackslash}it{\textbackslash}lambda\}{\textbackslash}simeq 1\$

 the turbulent kinetic energy (TKE) budget is in local equilibrium over a region extending from the near-wall region to a free-surface affected region a distance 


\$l\_\{\{{\textbackslash}it{\textbackslash}nu\}\}\$

 from the surface, with 


\$l\_\{\{{\textbackslash}it{\textbackslash}nu\}\}/\{{\textbackslash}it{\textbackslash}delta\}{\textbackslash}sim Re{\textasciicircum}\{-1/2\}\$

. In this equilibrium region the flow can be characterised by the flux Richardson number 


\$R\_\{f\}\$

 and the local Obukhov length scale 


\$\{{\textbackslash}it{\textbackslash}Lambda\}\$

. At higher 


\$\{{\textbackslash}it{\textbackslash}lambda\}\$

 local mixing limit conditions are observed over an extended region. At 


\$\{{\textbackslash}it{\textbackslash}lambda\}=2\$

 the flux Richardson number approaches critical limit values of 

 
\$R\_\{f,c\}{\textbackslash}simeq 0.18\$

 and gradient Richardson number 


\$Ri\_\{c\}{\textbackslash}simeq 0.2\$

. At high 


\$\{{\textbackslash}it{\textbackslash}lambda\}\$

, we obtain a flow field where buoyancy interacts with the smallest scales of motion and the turbulent shear stress and buoyancy flux are suppressed to molecular levels. We find that this regime can be identified in terms of the parameter 


\$Re\_\{{\textbackslash}mathscr\{L\},c\}={\textbackslash}mathscr\{L\}u\_\{\{{\textbackslash}it{\textbackslash}tau\}\}/\{{\textbackslash}it{\textbackslash}nu\}{\textbackslash}lesssim 200\{-\}400\$

 (where 


\$u\_\{\{{\textbackslash}it{\textbackslash}tau\}\}\$

 is the friction velocity and 


\$\{{\textbackslash}it{\textbackslash}nu\}\$

  the kinematic viscosity), which is related to the 


\$L\_\{{\textbackslash}ast \}\$

 parameter of Flores and Riley (Boundary-Layer Meteorol., vol. 139 (2), 2011, pp. 241–259) and buoyancy Reynolds number 


\${\textbackslash}mathscr\{R\}\$

. With energetic equilibrium attained, the local buoyancy Reynolds number, 


\$Re\_\{\{{\textbackslash}it{\textbackslash}Lambda\}\}=\{{\textbackslash}it{\textbackslash}Lambda\}{\textbackslash}langle u{\textasciicircum}\{{\textbackslash}prime \}w{\textasciicircum}\{{\textbackslash}prime \}{\textbackslash}rangle {\textasciicircum}\{1/2\}/\{{\textbackslash}it{\textbackslash}nu\}\$

, is directly related to the separation of the Ozmidov (


\$l\_\{O\}\$

) and Kolmogorov (


\$\{{\textbackslash}it{\textbackslash}eta\}\$

) length scales in the outer boundary layer by 


\$Re\_\{\{{\textbackslash}it{\textbackslash}Lambda\}\}{\textbackslash}simeq {\textbackslash}mathscr\{R\}{\textbackslash}equiv (l\_\{O\}/\{{\textbackslash}it{\textbackslash}eta\}){\textasciicircum}\{4/3\}\$

. The inner wall region has the behaviour 


\${\textbackslash}mathscr\{R\}{\textbackslash}sim Re\_\{{\textbackslash}mathscr\{L\}\}Re\_\{\{{\textbackslash}it{\textbackslash}tau\}\}\$

, in contrast to stratified boundary layer flows where the buoyancy flux is non-zero at the wall and 


\${\textbackslash}mathscr\{R\}{\textbackslash}sim Re\_\{{\textbackslash}mathscr\{L\}\}\$

.},
	urldate = {2017-12-23TZ},
	journal = {Journal of Fluid Mechanics},
	author = {Williamson, N. and Armfield, S. W. and Kirkpatrick, M. P. and Norris, S. E.},
	month = mar,
	year = {2015},
	pages = {528--555}
}

@article{williamson_convectively_2016,
	title = {Convectively unstable turbulent open channel flow with stable surface stratification},
	volume = {56},
	copyright = {Copyright (c) 2016 ANZIAM Journal},
	issn = {1445-8810},
	url = {https://journal.austms.org.au/ojs/index.php/ANZIAMJ/article/view/9312},
	doi = {10.21914/anziamj.v56i0.9312},
	abstract = {We use direct numerical simulations to examine fully developed turbulent open channel flow where the near wall region is unstably stratified and the outer boundary layer is stably stratified. The simulations are a model for flow in shallow turbid river channels with incident solar radiation. The aim is to determine under what conditions and by what mechanism the stably stratified layer is overturned. The flow is attained by applying a radiative heat flux at the free surface of the open channel. The absorption and transmission of the radiation follows the Beer--Lambert law with a constant absorption coefficient. We examine conditions where approximately 20\% of the incident radiative heat flux penetrates through to the wall, releasing heat at the wall as a heat flux. The problem is specified by our buoyancy parameter which is analogous to the bulk Obukhov length scale. In the stable outer boundary layer we observe that the flux Richardson number reaches the limiting value, as was observed in the atmospheric boundary layer under sheared convective conditions.

  References    S. M. Mitrovic, L. Hardwick, and F. Dorani.   Use of flow management to mitigate cyanobacterial blooms in the  Lower Darling River, Australia.   J. Plankton Res., 33(2):229–241, 2011.   doi:10.1093/plankt/fbq094       J. R. Taylor, S. Sarkar, and V. Armenio.   Large eddy simulation of stably stratified open channel flow.   Phys. Fluids, 17(11):116602, 2005.   doi:10.1063/1.2130747       M. Garcia-Villalba and J. C. del Alamo.   Turbulence modification by stable stratification in channel flow.   Phys. Fluids, 23(4):045104, 2011.   doi:10.1063/1.3560359       N. Williamson, S. W Armfield, M. P. Kirkpatrick, and S Norris.   A canonical model for stratified flow in estuaries and rivers.   ANZIAM J., 54:C88–C101, 2012.   http://journal.austms.org.au/ojs/index.php/ANZIAMJ/article/view/6429       S. W. Armfield, S. E. Norris, P. Morgan, and R. Street.   A parallel non-staggered Navier-Stokes solver implemented on a  workstation cluster.   In S. Armfield, P. Morgan, and K. Srinvas (Eds.) Computational Fluid Dynamics 2002: Proceedings of the Second International Conference on Computational Fluid Dynamics, Sydney, Australia, 15–19 July 2002,  pages 30–45. Springer, 2003.  doi:10.1007/978-3-642-59334-5       R. J. Conzemius and E. Fedorovich.   Dynamics of Sheared Convective Boundary Layer Entrainment. Part I: Methodological Background and Large-Eddy Simulations.   J. Atmos. Sci., 63(4):1151–1178, 2006.   doi:10.1175/JAS3691.1},
	language = {en},
	number = {0},
	urldate = {2017-12-23TZ},
	journal = {ANZIAM Journal},
	author = {Williamson, Nicholas John and Kirkpatrick, Michael and Armfield, Steven and Norris, Stuart},
	month = jan,
	year = {2016},
	pages = {246--261}
}

@misc{noauthor_turbulence_2017,
	title = {Turbulence modeling},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Turbulence_modeling&oldid=788652646},
	abstract = {Turbulence modeling is the construction and use of a model to predict the effects of turbulence. A turbulent fluid flow has features on many different length scales, which all interact with each other. A common approach is to average the governing equations of the flow, in order to focus on large-scale and non-fluctuating features of the flow. However, the effects of the small scales and fluctuating parts must be modelled.},
	language = {en},
	urldate = {2017-12-23TZ},
	journal = {Wikipedia},
	month = jul,
	year = {2017},
	note = {Page Version ID: 788652646}
}

@misc{noauthor_stratified_2017,
	title = {Stratified flows},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Stratified_flows&oldid=810346748},
	abstract = {The flow in many fluids varies with density and depends upon the gravity. Due to which the fluid with lower density is always above the fluid with higher density. Stratified flows are very common such as the Earth's ocean and its atmosphere.},
	language = {en},
	urldate = {2017-12-23TZ},
	journal = {Wikipedia},
	month = nov,
	year = {2017},
	note = {Page Version ID: 810346748}
}

@misc{noauthor_entrainment_nodate,
	title = {Entrainment across a sheared density interface in a cavity flow {\textbar} {Journal} of {Fluid} {Mechanics} {\textbar} {Cambridge} {Core}},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/entrainment-across-a-sheared-density-interface-in-a-cavity-flow/1D1F97C7F2488360B72F11F58A9F1612},
	urldate = {2017-12-23TZ}
}

@article{kisi_ozgur_river_2004,
	title = {River {Flow} {Modeling} {Using} {Artificial} {Neural} {Networks}},
	volume = {9},
	url = {https://ascelibrary-org.ezproxy1.library.usyd.edu.au/doi/abs/10.1061/(ASCE)1084-0699(2004)9:1(60)},
	doi = {10.1061/(ASCE)1084-0699(2004)9:1(60)},
	number = {1},
	urldate = {2017-12-23TZ},
	journal = {Journal of Hydrologic Engineering},
	author = {{Kişi Özgür}},
	month = jan,
	year = {2004},
	pages = {60--63}
}

@article{noauthor_fluid_2016,
	address = {Atlanta, United States},
	title = {Fluid {Mechanics}; {Researchers} at {Sandia} {National} {Laboratories} {Release} {New} {Data} on {Fluid} {Mechanics} ({Reynolds} averaged turbulence modelling using deep neural networks with embedded invariance)},
	copyright = {Copyright 2016, NewsRx LLC},
	issn = {1945-8398},
	url = {https://search.proquest.com/docview/1840710993/abstract/62F5FADD9B1341A7PQ/1},
	language = {English},
	urldate = {2017-12-23TZ},
	journal = {Technology \& Business Journal; Atlanta},
	month = nov,
	year = {2016},
	pages = {492}
}

@article{ling_machine_2016,
	title = {Machine learning strategies for systems with invariance properties},
	volume = {318},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999116301309},
	doi = {10.1016/j.jcp.2016.05.003},
	abstract = {In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using data-driven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.},
	number = {Supplement C},
	urldate = {2017-12-23TZ},
	journal = {Journal of Computational Physics},
	author = {Ling, Julia and Jones, Reese and Templeton, Jeremy},
	month = aug,
	year = {2016},
	pages = {22--35}
}

@article{nowruzi_performance_2017,
	title = {Performance predicting of 2D and 3D submerged hydrofoils using {CFD} and {ANNs}},
	volume = {22},
	issn = {0948-4280, 1437-8213},
	url = {https://link.springer.com/article/10.1007/s00773-017-0443-0},
	doi = {10.1007/s00773-017-0443-0},
	abstract = {In the present study, hydrodynamic performance of 2D and 3D submerged hydrofoils in terms of various geometries were simulated by computational fluid dynamic (CFD). Then, by selecting optimal artificial neural networks (ANN) hydrodynamic performance of hydrofoils are predicted. For this purpose, a finite volume method based on Navier–Stokes equation solver available in OpenFOAM, open-source CFD software, was used. After mesh size analyzing, to verify computational procedure, numerical results were compared with experimental ones which appropriate accuracy was observed. In this simulation, environmental and geometrical conditions such as, angle of attack, Reynolds number (Re), aspect ratio (AR) and taper ratio (TR) of hydrofoils are relevant on performance criteria of lift to drag ratio (LDR). To select a proper feed-forward ANNs to predict the performance of 2D and 3D hydrofoils under considered conditions based on the iterative algorithm, ANN architecture analysis was conducted. According to CFD results, larger value of AR and lower TR lead to greater LDR for 3D hydrofoils. Meanwhile, ANNs output showed that the maximum mean square error in predicting the LDR of 2D and 3D submerged hydrofoils are 0.0043 and 0.0035, respectively. In addition, based on the ANN weights and bias, two set of equations for predicting LDR of considered 2D and 3D submerged hydrofoils were proposed.},
	language = {en},
	number = {4},
	urldate = {2017-12-23TZ},
	journal = {Journal of Marine Science and Technology},
	author = {Nowruzi, Hashem and Ghassemi, Hassan and Ghiasi, Mahmoud},
	month = dec,
	year = {2017},
	pages = {710--733}
}

@article{lopez_pena_surrogate_2012,
	title = {A surrogate method based on the enhancement of low fidelity computational fluid dynamics approximations by artificial neural networks},
	volume = {58},
	issn = {0045-7930},
	url = {http://www.sciencedirect.com/science/article/pii/S0045793012000175},
	doi = {10.1016/j.compfluid.2012.01.008},
	abstract = {Current needs in design, optimization, and design space exploration or sensitivity analysis of fluid dynamic problems are pushing towards the search for Computational Fluid Dynamics (CFDs) simulation tools that present both low cost and high accuracy. In this line, the methodology presented here makes use of Artificial Neural Networks (ANNs) for enhancing the results obtained by low level fluid dynamic approximations in such a way that an accuracy level comparable to that obtained with more advanced CFD simulations is achieved while maintaining much lower computational costs. Contrasting with other traditional surrogate methods where the whole physical model is replaced by a soft computing estimator acting as a black box, in the proposed approach the ANNs are trained to generate an estimation of the error produced by the low cost simulation in order to correct its results. To demonstrate the applicability of the proposed method, and after establishing it, this paper discusses its application to three different fluid dynamic problems. The first one deals with the determination of airfoil characteristics; the low level approximation is achieved here by a traditional combination of panel methods and integral boundary layer codes, while the training of the ANNs is performed by using the abundant experimental data on airfoils that can be found in the literature. In the second case, an analysis of the effects of cavitation on a hydrofoil’s performance is presented; the low level approximation is the lift and drag of the hydrofoil computed using a simple barotropic model for cavitation and a RANS turbulence model, while the data needed for training the ANNs is generated using the a more advanced cavitation model coupled with Large Eddy Simulation and the Volume of Fluid (VOF) method. The last application presents the determination of forces produced by yacht sails when working in a downwind condition; in this case the low-level fluid dynamics approximation is obtained using an Euler code for inviscid fluids and the training of the ANN is carried out considering the results obtained from wind tunnel experiments.},
	number = {Supplement C},
	urldate = {2017-12-21TZ},
	journal = {Computers \& Fluids},
	author = {Lopez Peña, F. and Díaz Casás, V. and Gosset, A. and Duro, R. J.},
	month = apr,
	year = {2012},
	pages = {112--119}
}

@misc{noauthor_simulation_nodate,
	title = {Simulation of open channel bend characteristics using computational fluid dynamics and artificial neural networks: {Engineering} {Applications} of {Computational} {Fluid} {Mechanics}: {Vol} 9, {No} 1},
	url = {http://www.tandfonline.com/doi/abs/10.1080/19942060.2015.1033808},
	urldate = {2017-12-21TZ}
}

@article{pandya_computational_2017,
	title = {A computational fluid dynamics based artificial neural network model to predict solid particle erosion},
	volume = {378-379},
	issn = {0043-1648},
	url = {http://www.sciencedirect.com/science/article/pii/S0043164816303702},
	doi = {10.1016/j.wear.2017.02.028},
	abstract = {Solid particle erosion plays a critical role in the design and reliability of equipment employed in the oil and gas industry. Significant erosion occurs due to solid particle loading, especially in applications involving sand production. Low particle loading in drilling fluids ({\textless}10\%) is also a source of erosion inside downhole tools and in rig equipment at the surface. Accurate prediction of erosion rates can save money and lives by predicting failure accurately and helping to maintain the safety of the equipment. Empirical and mechanistic models to predict erosion were primarily developed based on observations of extensive experiments and field studies. Computational fluid dynamics (CFD) has emerged as an alternative tool to predict erosion in recent years. The ability to simulate multiphase flows in complex geometries using CFD makes it a valuable and less-expensive method to predict erosion flow loop experimentations and field trials. Various empirical relations have been established to predict erosion using CFD. These methods often predict erosion regions accurately, but typically are highly inaccurate in predicting an erosion rate. An order-of-magnitude error is observed in many cases. This study employs machine learning approach along with CFD-based methodology to develop robust erosion models. A generalized model is developed based on experiments conducted on 90-degree elbows of 1-in. diameter and made from Inconel 718, Nickel Alloy 825, 25\% Cr, Nickel Alloy 925, and 13\% Cr L-80 materials. The Baker Hughes erosion model developed in 2008 is studied as a baseline. Statistical analysis was performed on CFD output parameters to identify those that most affect erosion rates. A correlation analysis and non-parametric statistical analysis is performed resulting in the development of two new regression models based on turbulent kinetic energy, and surface shear stress was developed. A 25-\% improvement is observed in the predictions of cumulative erosion rate error compared to baseline. An artificial neural network with multilayer feed-forward model with the back-propagation algorithm and Levenberg-Marquardt training was developed. This model, along with Bayesian regularization, reduced cumulative error to less than 10\%, compared to more than 40\% in the baseline Baker Hughes model.},
	number = {Supplement C},
	urldate = {2017-12-21TZ},
	journal = {Wear},
	author = {Pandya, D. A. and Dennis, B. H. and Russell, R. D.},
	month = may,
	year = {2017},
	pages = {198--210}
}

@misc{hennigh_phy-net:_2017,
	title = {Phy-{Net}: compressing physics with neural networks},
	copyright = {Apache-2.0},
	shorttitle = {Phy-{Net}},
	url = {https://github.com/loliverhennigh/Phy-Net},
	urldate = {2017-12-05TZ},
	author = {Hennigh, Oliver},
	month = nov,
	year = {2017},
	note = {original-date: 2016-11-05T16:12:09Z}
}

@article{hennigh_lat-net:_2017,
	title = {Lat-{Net}: {Compressing} {Lattice} {Boltzmann} {Flow} {Simulations} using {Deep} {Neural} {Networks}},
	shorttitle = {Lat-{Net}},
	url = {http://arxiv.org/abs/1705.09036},
	abstract = {Computational Fluid Dynamics (CFD) is a hugely important subject with applications in almost every engineering field, however, fluid simulations are extremely computationally and memory demanding. Towards this end, we present Lat-Net, a method for compressing both the computation time and memory usage of Lattice Boltzmann flow simulations using deep neural networks. Lat-Net employs convolutional autoencoders and residual connections in a fully differentiable scheme to compress the state size of a simulation and learn the dynamics on this compressed form. The result is a computationally and memory efficient neural network that can be iterated and queried to reproduce a fluid simulation. We show that once Lat-Net is trained, it can generalize to large grid sizes and complex geometries while maintaining accuracy. We also show that Lat-Net is a general method for compressing other Lattice Boltzmann based simulations such as Electromagnetism.},
	urldate = {2017-12-05TZ},
	journal = {arXiv:1705.09036 [physics, stat]},
	author = {Hennigh, Oliver},
	month = may,
	year = {2017},
	note = {arXiv: 1705.09036}
}